//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: CL-22867594
// Driver 384.90
// Based on LLVM 3.4svn
//

.version 6.0
.target sm_52, texmode_independent
.address_size 64

	// .globl	amp

.entry amp(
	.param .u64 .ptr .global .align 4 amp_param_0,
	.param .u64 .ptr .global .align 4 amp_param_1,
	.param .u64 .ptr .global .align 4 amp_param_2,
	.param .u64 .ptr .global .align 4 amp_param_3,
	.param .u64 .ptr .global .align 4 amp_param_4,
	.param .u32 amp_param_5,
	.param .u32 amp_param_6
)
{
	.local .align 16 .b8 	__local_depot0[64];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<1032>;
	.reg .b16 	%rs<441>;
	.reg .b32 	%r<8863>;
	.reg .b64 	%rd<44>;


	mov.u64 	%rd43, __local_depot0;
	cvta.local.u64 	%SP, %rd43;
	ld.param.u64 	%rd8, [amp_param_0];
	ld.param.u64 	%rd9, [amp_param_1];
	ld.param.u64 	%rd10, [amp_param_2];
	ld.param.u32 	%r1779, [amp_param_6];
	mov.u32 	%r1780, %ctaid.x;
	mov.u32 	%r1781, %ntid.x;
	mov.b32	%r1782, %envreg3;
	mad.lo.s32 	%r1783, %r1780, %r1781, %r1782;
	mov.u32 	%r1784, %tid.x;
	add.s32 	%r1, %r1783, %r1784;
	setp.ge.u32	%p1, %r1, %r1779;
	@%p1 bra 	BB0_1557;

	mul.wide.u32 	%rd11, %r1, 80;
	add.s64 	%rd12, %rd8, %rd11;
	add.s64 	%rd1, %rd12, 64;
	ld.global.u32 	%r8853, [%rd12+64];
	ld.global.u32 	%r8677, [%rd10];
	add.s64 	%rd3, %rd9, %rd11;
	setp.ne.s32	%p2, %r8677, 58;
	@%p2 bra 	BB0_3;

	ld.global.u32 	%r1785, [%rd10+4];
	setp.eq.s32	%p3, %r1785, 0;
	@%p3 bra 	BB0_1556;

BB0_3:
	ld.global.u32 	%r8848, [%rd1+-64];
	ld.global.u32 	%r8847, [%rd1+-60];
	ld.global.u32 	%r8846, [%rd1+-56];
	ld.global.u32 	%r8845, [%rd1+-52];
	ld.global.u32 	%r8852, [%rd1+-48];
	ld.global.u32 	%r8851, [%rd1+-44];
	ld.global.u32 	%r8850, [%rd1+-40];
	ld.global.u32 	%r8849, [%rd1+-36];
	setp.eq.s32	%p4, %r8677, 0;
	@%p4 bra 	BB0_1555;

	add.u64 	%rd13, %SP, 0;
	cvta.to.local.u64 	%rd7, %rd13;
	add.u64 	%rd14, %SP, 32;
	cvta.to.local.u64 	%rd6, %rd14;
	mov.u32 	%r8678, 0;
	bra.uni 	BB0_5;

BB0_1556:
	ld.global.u32 	%r8655, [%rd1+-64];
	st.global.u32 	[%rd3], %r8655;
	ld.global.u32 	%r8656, [%rd1+-60];
	st.global.u32 	[%rd3+4], %r8656;
	ld.global.u32 	%r8657, [%rd1+-56];
	st.global.u32 	[%rd3+8], %r8657;
	ld.global.u32 	%r8658, [%rd1+-52];
	st.global.u32 	[%rd3+12], %r8658;
	ld.global.u32 	%r8659, [%rd1+-48];
	st.global.u32 	[%rd3+16], %r8659;
	ld.global.u32 	%r8660, [%rd1+-44];
	st.global.u32 	[%rd3+20], %r8660;
	ld.global.u32 	%r8661, [%rd1+-40];
	st.global.u32 	[%rd3+24], %r8661;
	ld.global.u32 	%r8662, [%rd1+-36];
	st.global.u32 	[%rd3+28], %r8662;
	ld.global.u32 	%r8663, [%rd1+-32];
	st.global.u32 	[%rd3+32], %r8663;
	ld.global.u32 	%r8664, [%rd1+-28];
	st.global.u32 	[%rd3+36], %r8664;
	ld.global.u32 	%r8665, [%rd1+-24];
	st.global.u32 	[%rd3+40], %r8665;
	ld.global.u32 	%r8666, [%rd1+-20];
	st.global.u32 	[%rd3+44], %r8666;
	ld.global.u32 	%r8667, [%rd1+-16];
	st.global.u32 	[%rd3+48], %r8667;
	ld.global.u32 	%r8668, [%rd1+-12];
	st.global.u32 	[%rd3+52], %r8668;
	ld.global.u32 	%r8669, [%rd1+-8];
	st.global.u32 	[%rd3+56], %r8669;
	ld.global.u32 	%r8670, [%rd1+-4];
	st.global.u32 	[%rd3+60], %r8670;
	ld.global.u32 	%r8671, [%rd1];
	st.global.u32 	[%rd3+64], %r8671;
	bra.uni 	BB0_1557;

BB0_196:
	setp.ne.s32	%p132, %r24, 31;
	mov.u32 	%r8688, %r8691;
	mov.u32 	%r8689, %r8691;
	mov.u32 	%r8690, %r8691;
	mov.u32 	%r8692, %r8691;
	mov.u32 	%r8693, %r8691;
	mov.u32 	%r8694, %r8691;
	mov.u32 	%r8695, %r8691;
	@%p132 bra 	BB0_215;

	mov.u32 	%r8688, 0;
	mov.u32 	%r2267, 8;
	// inline asm
	shf.r.wrap.b32 %r8692, %r8688, %r19, %r2267;
	// inline asm

BB0_198:
	mov.u32 	%r8689, %r8688;
	mov.u32 	%r8690, %r8688;
	mov.u32 	%r8691, %r8688;
	mov.u32 	%r8693, %r8688;

BB0_190:
	mov.u32 	%r8694, %r8688;
	mov.u32 	%r8695, %r8688;

BB0_215:
	and.b32  	%r2809, %r14, 3;
	shl.b32 	%r2810, %r2809, 3;
	mov.u32 	%r2811, -1;
	shl.b32 	%r160, %r2811, %r2810;
	shr.u32 	%r2808, %r14, 2;
	setp.gt.s32	%p174, %r2808, 3;
	@%p174 bra 	BB0_223;

	setp.gt.s32	%p180, %r2808, 1;
	@%p180 bra 	BB0_220;

	setp.eq.s32	%p183, %r2808, 0;
	@%p183 bra 	BB0_234;
	bra.uni 	BB0_218;

BB0_234:
	and.b32  	%r8691, %r8691, %r160;
	bra.uni 	BB0_235;

BB0_223:
	setp.gt.s32	%p175, %r2808, 5;
	@%p175 bra 	BB0_227;

	setp.eq.s32	%p178, %r2808, 4;
	@%p178 bra 	BB0_232;
	bra.uni 	BB0_225;

BB0_232:
	and.b32  	%r8695, %r8695, %r160;
	mov.u32 	%r8688, 0;
	mov.u32 	%r8689, %r8688;
	mov.u32 	%r8690, %r8688;
	mov.u32 	%r8691, %r8688;
	bra.uni 	BB0_235;

BB0_220:
	setp.eq.s32	%p181, %r2808, 2;
	@%p181 bra 	BB0_233;
	bra.uni 	BB0_221;

BB0_233:
	and.b32  	%r8689, %r8689, %r160;
	mov.u32 	%r8690, 0;
	mov.u32 	%r8691, %r8690;
	bra.uni 	BB0_235;

BB0_227:
	setp.eq.s32	%p176, %r2808, 6;
	@%p176 bra 	BB0_230;
	bra.uni 	BB0_228;

BB0_230:
	and.b32  	%r8693, %r8693, %r160;
	mov.u32 	%r8688, 0;
	mov.u32 	%r8689, %r8688;
	mov.u32 	%r8690, %r8688;
	mov.u32 	%r8691, %r8688;
	bra.uni 	BB0_231;

BB0_218:
	setp.eq.s32	%p184, %r2808, 1;
	@%p184 bra 	BB0_219;
	bra.uni 	BB0_235;

BB0_219:
	and.b32  	%r8690, %r8690, %r160;
	mov.u32 	%r8691, 0;
	bra.uni 	BB0_235;

BB0_225:
	setp.eq.s32	%p179, %r2808, 5;
	@%p179 bra 	BB0_226;
	bra.uni 	BB0_235;

BB0_226:
	and.b32  	%r8694, %r8694, %r160;
	mov.u32 	%r8688, 0;
	mov.u32 	%r8689, %r8688;
	mov.u32 	%r8690, %r8688;
	mov.u32 	%r8691, %r8688;
	mov.u32 	%r8695, %r8688;
	bra.uni 	BB0_235;

BB0_221:
	setp.eq.s32	%p182, %r2808, 3;
	@%p182 bra 	BB0_222;
	bra.uni 	BB0_235;

BB0_222:
	and.b32  	%r8688, %r8688, %r160;
	mov.u32 	%r8689, 0;
	mov.u32 	%r8690, %r8689;
	mov.u32 	%r8691, %r8689;
	bra.uni 	BB0_235;

BB0_228:
	setp.ne.s32	%p177, %r2808, 7;
	@%p177 bra 	BB0_235;

	and.b32  	%r8692, %r8692, %r160;
	mov.u32 	%r8688, 0;
	mov.u32 	%r8689, %r8688;
	mov.u32 	%r8690, %r8688;
	mov.u32 	%r8691, %r8688;
	mov.u32 	%r8693, %r8688;

BB0_231:
	mov.u32 	%r8694, %r8688;
	mov.u32 	%r8695, %r8688;

BB0_235:
	or.b32  	%r8848, %r8691, %r19;
	or.b32  	%r8847, %r8690, %r20;
	or.b32  	%r8846, %r8689, %r21;
	or.b32  	%r8845, %r8688, %r22;
	or.b32  	%r8852, %r8695, %r15;
	or.b32  	%r8851, %r8694, %r16;
	or.b32  	%r8850, %r8693, %r17;
	or.b32  	%r8849, %r8692, %r18;
	bra.uni 	BB0_1554;

BB0_290:
	setp.eq.s32	%p220, %r24, 19;
	@%p220 bra 	BB0_321;
	bra.uni 	BB0_291;

BB0_321:
	mov.u32 	%r3021, 8;
	// inline asm
	shf.r.wrap.b32 %r18, %r21, %r22, %r3021;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r17, %r20, %r21, %r3021;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r16, %r19, %r20, %r3021;
	// inline asm
	mov.u32 	%r8712, 0;
	// inline asm
	shf.r.wrap.b32 %r19, %r8712, %r19, %r3021;
	// inline asm

BB0_322:
	mov.u32 	%r8713, %r8712;
	mov.u32 	%r8714, %r8712;
	mov.u32 	%r8715, %r8712;
	bra.uni 	BB0_338;

BB0_274:
	setp.eq.s32	%p232, %r24, 11;
	@%p232 bra 	BB0_275;
	bra.uni 	BB0_291;

BB0_275:
	mov.u32 	%r3165, 8;
	// inline asm
	shf.r.wrap.b32 %r18, %r15, %r16, %r3165;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r17, %r22, %r15, %r3165;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r16, %r21, %r22, %r3165;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r3154, %r20, %r21, %r3165;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8712, %r19, %r20, %r3165;
	// inline asm
	mov.u32 	%r8714, 0;
	// inline asm
	shf.r.wrap.b32 %r8713, %r8714, %r19, %r3165;
	// inline asm
	mov.u32 	%r8715, %r8714;
	mov.u32 	%r19, %r3154;
	bra.uni 	BB0_338;

BB0_306:
	setp.eq.s32	%p209, %r24, 27;
	@%p209 bra 	BB0_307;
	bra.uni 	BB0_291;

BB0_307:
	mov.u32 	%r2909, 8;
	// inline asm
	shf.r.wrap.b32 %r18, %r19, %r20, %r2909;
	// inline asm
	mov.u32 	%r8712, 0;
	// inline asm
	shf.r.wrap.b32 %r17, %r8712, %r19, %r2909;
	// inline asm

BB0_308:
	mov.u32 	%r8713, %r8712;
	mov.u32 	%r8714, %r8712;
	mov.u32 	%r8715, %r8712;
	bra.uni 	BB0_336;

BB0_266:
	setp.eq.s32	%p238, %r24, 7;
	@%p238 bra 	BB0_267;
	bra.uni 	BB0_291;

BB0_267:
	mov.u32 	%r3249, 8;
	// inline asm
	shf.r.wrap.b32 %r18, %r16, %r17, %r3249;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r17, %r15, %r16, %r3249;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r16, %r22, %r15, %r3249;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r3234, %r21, %r22, %r3249;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8712, %r20, %r21, %r3249;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8713, %r19, %r20, %r3249;
	// inline asm
	mov.u32 	%r8715, 0;
	// inline asm
	shf.r.wrap.b32 %r8714, %r8715, %r19, %r3249;
	// inline asm
	mov.u32 	%r19, %r3234;
	bra.uni 	BB0_338;

BB0_297:
	setp.eq.s32	%p215, %r24, 23;
	@%p215 bra 	BB0_298;
	bra.uni 	BB0_291;

BB0_298:
	mov.u32 	%r2961, 8;
	// inline asm
	shf.r.wrap.b32 %r18, %r20, %r21, %r2961;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r17, %r19, %r20, %r2961;
	// inline asm
	mov.u32 	%r8712, 0;
	// inline asm
	shf.r.wrap.b32 %r16, %r8712, %r19, %r2961;
	// inline asm

BB0_299:
	mov.u32 	%r8713, %r8712;
	mov.u32 	%r8714, %r8712;
	mov.u32 	%r8715, %r8712;
	bra.uni 	BB0_337;

BB0_281:
	setp.eq.s32	%p227, %r24, 15;
	@%p227 bra 	BB0_282;
	bra.uni 	BB0_291;

BB0_282:
	mov.u32 	%r3089, 8;
	// inline asm
	shf.r.wrap.b32 %r18, %r22, %r15, %r3089;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r17, %r21, %r22, %r3089;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r16, %r20, %r21, %r3089;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r3082, %r19, %r20, %r3089;
	// inline asm
	mov.u32 	%r8713, 0;
	// inline asm
	shf.r.wrap.b32 %r8712, %r8713, %r19, %r3089;
	// inline asm
	mov.u32 	%r8714, %r8713;
	mov.u32 	%r8715, %r8713;
	mov.u32 	%r19, %r3082;
	bra.uni 	BB0_338;

BB0_314:
	setp.ne.s32	%p204, %r24, 30;
	@%p204 bra 	BB0_291;

	mov.u32 	%r8712, 0;
	mov.u32 	%r2876, 16;
	// inline asm
	shf.r.wrap.b32 %r18, %r8712, %r19, %r2876;
	// inline asm

BB0_334:
	mov.u32 	%r8713, %r8712;
	mov.u32 	%r8714, %r8712;
	mov.u32 	%r8715, %r8712;

BB0_335:
	mov.u32 	%r17, %r8712;

BB0_336:
	mov.u32 	%r16, %r8712;

BB0_337:
	mov.u32 	%r19, %r8712;
	bra.uni 	BB0_338;

BB0_291:
	mov.u32 	%r8712, %r22;
	mov.u32 	%r8713, %r21;
	mov.u32 	%r8714, %r20;
	mov.u32 	%r8715, %r19;
	mov.u32 	%r19, %r15;

BB0_338:
	or.b32  	%r8848, %r8715, %r8707;
	or.b32  	%r8847, %r8714, %r8706;
	or.b32  	%r8846, %r8713, %r8705;
	or.b32  	%r8845, %r8712, %r8704;
	or.b32  	%r8852, %r19, %r8711;
	or.b32  	%r8851, %r16, %r8710;
	or.b32  	%r8850, %r17, %r8709;
	or.b32  	%r8849, %r18, %r8708;
	bra.uni 	BB0_1554;

BB0_1314:
	setp.eq.s32	%p935, %r6374, 1;
	mov.u32 	%r8795, %r8803;
	mov.u32 	%r8796, %r8803;
	mov.u32 	%r8797, %r8803;
	mov.u32 	%r8798, %r8803;
	mov.u32 	%r8799, %r8803;
	mov.u32 	%r8800, %r8803;
	mov.u32 	%r8801, %r8803;
	mov.u32 	%r8802, %r8803;
	@%p935 bra 	BB0_1315;
	bra.uni 	BB0_1394;

BB0_1315:
	mov.u32 	%r6919, 24;
	// inline asm
	shf.r.wrap.b32 %r8799, %r17, %r18, %r6919;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8800, %r16, %r17, %r6919;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8801, %r15, %r16, %r6919;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8802, %r22, %r15, %r6919;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8795, %r21, %r22, %r6919;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8796, %r20, %r21, %r6919;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8797, %r19, %r20, %r6919;
	// inline asm
	mov.u32 	%r6917, 0;
	// inline asm
	shf.r.wrap.b32 %r8798, %r6917, %r19, %r6919;
	// inline asm
	bra.uni 	BB0_1394;

BB0_1346:
	setp.eq.s32	%p912, %r6374, 17;
	mov.u32 	%r8795, %r8803;
	mov.u32 	%r8796, %r8803;
	mov.u32 	%r8797, %r8803;
	mov.u32 	%r8798, %r8803;
	mov.u32 	%r8799, %r8803;
	mov.u32 	%r8800, %r8803;
	mov.u32 	%r8801, %r8803;
	mov.u32 	%r8802, %r8803;
	@%p912 bra 	BB0_1347;
	bra.uni 	BB0_1394;

BB0_1347:
	mov.u32 	%r6575, 24;
	// inline asm
	shf.r.wrap.b32 %r8799, %r21, %r22, %r6575;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8800, %r20, %r21, %r6575;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8801, %r19, %r20, %r6575;
	// inline asm
	mov.u32 	%r8795, 0;
	// inline asm
	shf.r.wrap.b32 %r8802, %r8795, %r19, %r6575;
	// inline asm
	bra.uni 	BB0_1351;

BB0_1329:
	setp.eq.s32	%p924, %r6374, 9;
	mov.u32 	%r8795, %r8803;
	mov.u32 	%r8796, %r8803;
	mov.u32 	%r8797, %r8803;
	mov.u32 	%r8798, %r8803;
	mov.u32 	%r8799, %r8803;
	mov.u32 	%r8800, %r8803;
	mov.u32 	%r8801, %r8803;
	mov.u32 	%r8802, %r8803;
	@%p924 bra 	BB0_1330;
	bra.uni 	BB0_1394;

BB0_1330:
	mov.u32 	%r6731, 24;
	// inline asm
	shf.r.wrap.b32 %r8799, %r15, %r16, %r6731;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8800, %r22, %r15, %r6731;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8801, %r21, %r22, %r6731;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8802, %r20, %r21, %r6731;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8795, %r19, %r20, %r6731;
	// inline asm
	mov.u32 	%r8797, 0;
	// inline asm
	shf.r.wrap.b32 %r8796, %r8797, %r19, %r6731;
	// inline asm
	mov.u32 	%r8798, %r8797;
	bra.uni 	BB0_1394;

BB0_1363:
	setp.eq.s32	%p901, %r6374, 25;
	mov.u32 	%r8795, %r8803;
	mov.u32 	%r8796, %r8803;
	mov.u32 	%r8797, %r8803;
	mov.u32 	%r8798, %r8803;
	mov.u32 	%r8799, %r8803;
	mov.u32 	%r8800, %r8803;
	mov.u32 	%r8801, %r8803;
	mov.u32 	%r8802, %r8803;
	@%p901 bra 	BB0_1364;
	bra.uni 	BB0_1394;

BB0_1364:
	mov.u32 	%r6451, 24;
	// inline asm
	shf.r.wrap.b32 %r8799, %r19, %r20, %r6451;
	// inline asm
	mov.u32 	%r8795, 0;
	// inline asm
	shf.r.wrap.b32 %r8800, %r8795, %r19, %r6451;
	// inline asm
	bra.uni 	BB0_1368;

BB0_1321:
	setp.eq.s32	%p930, %r6374, 5;
	mov.u32 	%r8795, %r8803;
	mov.u32 	%r8796, %r8803;
	mov.u32 	%r8797, %r8803;
	mov.u32 	%r8798, %r8803;
	mov.u32 	%r8799, %r8803;
	mov.u32 	%r8800, %r8803;
	mov.u32 	%r8801, %r8803;
	mov.u32 	%r8802, %r8803;
	@%p930 bra 	BB0_1322;
	bra.uni 	BB0_1394;

BB0_1322:
	mov.u32 	%r6821, 24;
	// inline asm
	shf.r.wrap.b32 %r8799, %r16, %r17, %r6821;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8800, %r15, %r16, %r6821;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8801, %r22, %r15, %r6821;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8802, %r21, %r22, %r6821;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8795, %r20, %r21, %r6821;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8796, %r19, %r20, %r6821;
	// inline asm
	mov.u32 	%r8798, 0;
	// inline asm
	shf.r.wrap.b32 %r8797, %r8798, %r19, %r6821;
	// inline asm
	bra.uni 	BB0_1394;

BB0_1354:
	setp.eq.s32	%p907, %r6374, 21;
	mov.u32 	%r8795, %r8803;
	mov.u32 	%r8796, %r8803;
	mov.u32 	%r8797, %r8803;
	mov.u32 	%r8798, %r8803;
	mov.u32 	%r8799, %r8803;
	mov.u32 	%r8800, %r8803;
	mov.u32 	%r8801, %r8803;
	mov.u32 	%r8802, %r8803;
	@%p907 bra 	BB0_1355;
	bra.uni 	BB0_1394;

BB0_1355:
	mov.u32 	%r6509, 24;
	// inline asm
	shf.r.wrap.b32 %r8799, %r20, %r21, %r6509;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8800, %r19, %r20, %r6509;
	// inline asm
	mov.u32 	%r8795, 0;
	// inline asm
	shf.r.wrap.b32 %r8801, %r8795, %r19, %r6509;
	// inline asm
	bra.uni 	BB0_1359;

BB0_1336:
	setp.eq.s32	%p919, %r6374, 13;
	mov.u32 	%r8795, %r8803;
	mov.u32 	%r8796, %r8803;
	mov.u32 	%r8797, %r8803;
	mov.u32 	%r8798, %r8803;
	mov.u32 	%r8799, %r8803;
	mov.u32 	%r8800, %r8803;
	mov.u32 	%r8801, %r8803;
	mov.u32 	%r8802, %r8803;
	@%p919 bra 	BB0_1337;
	bra.uni 	BB0_1394;

BB0_1337:
	mov.u32 	%r6649, 24;
	// inline asm
	shf.r.wrap.b32 %r8799, %r22, %r15, %r6649;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8800, %r21, %r22, %r6649;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8801, %r20, %r21, %r6649;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8802, %r19, %r20, %r6649;
	// inline asm
	mov.u32 	%r8796, 0;
	// inline asm
	shf.r.wrap.b32 %r8795, %r8796, %r19, %r6649;
	// inline asm
	bra.uni 	BB0_1341;

BB0_1372:
	setp.eq.s32	%p896, %r6374, 29;
	mov.u32 	%r8795, %r8803;
	mov.u32 	%r8796, %r8803;
	mov.u32 	%r8797, %r8803;
	mov.u32 	%r8798, %r8803;
	mov.u32 	%r8799, %r8803;
	mov.u32 	%r8800, %r8803;
	mov.u32 	%r8801, %r8803;
	mov.u32 	%r8802, %r8803;
	@%p896 bra 	BB0_1373;
	bra.uni 	BB0_1394;

BB0_1373:
	mov.u32 	%r8795, 0;
	mov.u32 	%r6401, 24;
	// inline asm
	shf.r.wrap.b32 %r8799, %r8795, %r19, %r6401;
	// inline asm
	bra.uni 	BB0_1377;

BB0_1317:
	setp.eq.s32	%p933, %r6374, 3;
	mov.u32 	%r8795, %r8803;
	mov.u32 	%r8796, %r8803;
	mov.u32 	%r8797, %r8803;
	mov.u32 	%r8798, %r8803;
	mov.u32 	%r8799, %r8803;
	mov.u32 	%r8800, %r8803;
	mov.u32 	%r8801, %r8803;
	mov.u32 	%r8802, %r8803;
	@%p933 bra 	BB0_1318;
	bra.uni 	BB0_1394;

BB0_1318:
	mov.u32 	%r6855, 8;
	// inline asm
	shf.r.wrap.b32 %r8799, %r17, %r18, %r6855;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8800, %r16, %r17, %r6855;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8801, %r15, %r16, %r6855;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8802, %r22, %r15, %r6855;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8795, %r21, %r22, %r6855;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8796, %r20, %r21, %r6855;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8797, %r19, %r20, %r6855;
	// inline asm
	mov.u32 	%r6853, 0;
	// inline asm
	shf.r.wrap.b32 %r8798, %r6853, %r19, %r6855;
	// inline asm
	bra.uni 	BB0_1394;

BB0_1349:
	setp.eq.s32	%p910, %r6374, 19;
	mov.u32 	%r8795, %r8803;
	mov.u32 	%r8796, %r8803;
	mov.u32 	%r8797, %r8803;
	mov.u32 	%r8798, %r8803;
	mov.u32 	%r8799, %r8803;
	mov.u32 	%r8800, %r8803;
	mov.u32 	%r8801, %r8803;
	mov.u32 	%r8802, %r8803;
	@%p910 bra 	BB0_1350;
	bra.uni 	BB0_1394;

BB0_1350:
	mov.u32 	%r6535, 8;
	// inline asm
	shf.r.wrap.b32 %r8799, %r21, %r22, %r6535;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8800, %r20, %r21, %r6535;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8801, %r19, %r20, %r6535;
	// inline asm
	mov.u32 	%r8795, 0;
	// inline asm
	shf.r.wrap.b32 %r8802, %r8795, %r19, %r6535;
	// inline asm

BB0_1351:
	mov.u32 	%r8796, %r8795;
	mov.u32 	%r8797, %r8795;
	mov.u32 	%r8798, %r8795;
	bra.uni 	BB0_1394;

BB0_1332:
	setp.eq.s32	%p922, %r6374, 11;
	mov.u32 	%r8795, %r8803;
	mov.u32 	%r8796, %r8803;
	mov.u32 	%r8797, %r8803;
	mov.u32 	%r8798, %r8803;
	mov.u32 	%r8799, %r8803;
	mov.u32 	%r8800, %r8803;
	mov.u32 	%r8801, %r8803;
	mov.u32 	%r8802, %r8803;
	@%p922 bra 	BB0_1333;
	bra.uni 	BB0_1394;

BB0_1333:
	mov.u32 	%r6679, 8;
	// inline asm
	shf.r.wrap.b32 %r8799, %r15, %r16, %r6679;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8800, %r22, %r15, %r6679;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8801, %r21, %r22, %r6679;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8802, %r20, %r21, %r6679;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8795, %r19, %r20, %r6679;
	// inline asm
	mov.u32 	%r8797, 0;
	// inline asm
	shf.r.wrap.b32 %r8796, %r8797, %r19, %r6679;
	// inline asm
	mov.u32 	%r8798, %r8797;
	bra.uni 	BB0_1394;

BB0_1366:
	setp.eq.s32	%p899, %r6374, 27;
	mov.u32 	%r8795, %r8803;
	mov.u32 	%r8796, %r8803;
	mov.u32 	%r8797, %r8803;
	mov.u32 	%r8798, %r8803;
	mov.u32 	%r8799, %r8803;
	mov.u32 	%r8800, %r8803;
	mov.u32 	%r8801, %r8803;
	mov.u32 	%r8802, %r8803;
	@%p899 bra 	BB0_1367;
	bra.uni 	BB0_1394;

BB0_1367:
	mov.u32 	%r6423, 8;
	// inline asm
	shf.r.wrap.b32 %r8799, %r19, %r20, %r6423;
	// inline asm
	mov.u32 	%r8795, 0;
	// inline asm
	shf.r.wrap.b32 %r8800, %r8795, %r19, %r6423;
	// inline asm

BB0_1368:
	mov.u32 	%r8796, %r8795;
	mov.u32 	%r8797, %r8795;
	mov.u32 	%r8798, %r8795;
	bra.uni 	BB0_1369;

BB0_1324:
	setp.eq.s32	%p928, %r6374, 7;
	mov.u32 	%r8795, %r8803;
	mov.u32 	%r8796, %r8803;
	mov.u32 	%r8797, %r8803;
	mov.u32 	%r8798, %r8803;
	mov.u32 	%r8799, %r8803;
	mov.u32 	%r8800, %r8803;
	mov.u32 	%r8801, %r8803;
	mov.u32 	%r8802, %r8803;
	@%p928 bra 	BB0_1325;
	bra.uni 	BB0_1394;

BB0_1325:
	mov.u32 	%r6763, 8;
	// inline asm
	shf.r.wrap.b32 %r8799, %r16, %r17, %r6763;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8800, %r15, %r16, %r6763;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8801, %r22, %r15, %r6763;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8802, %r21, %r22, %r6763;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8795, %r20, %r21, %r6763;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8796, %r19, %r20, %r6763;
	// inline asm
	mov.u32 	%r8798, 0;
	// inline asm
	shf.r.wrap.b32 %r8797, %r8798, %r19, %r6763;
	// inline asm
	bra.uni 	BB0_1394;

BB0_1357:
	setp.eq.s32	%p905, %r6374, 23;
	mov.u32 	%r8795, %r8803;
	mov.u32 	%r8796, %r8803;
	mov.u32 	%r8797, %r8803;
	mov.u32 	%r8798, %r8803;
	mov.u32 	%r8799, %r8803;
	mov.u32 	%r8800, %r8803;
	mov.u32 	%r8801, %r8803;
	mov.u32 	%r8802, %r8803;
	@%p905 bra 	BB0_1358;
	bra.uni 	BB0_1394;

BB0_1358:
	mov.u32 	%r6475, 8;
	// inline asm
	shf.r.wrap.b32 %r8799, %r20, %r21, %r6475;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8800, %r19, %r20, %r6475;
	// inline asm
	mov.u32 	%r8795, 0;
	// inline asm
	shf.r.wrap.b32 %r8801, %r8795, %r19, %r6475;
	// inline asm

BB0_1359:
	mov.u32 	%r8796, %r8795;
	mov.u32 	%r8797, %r8795;
	mov.u32 	%r8798, %r8795;
	mov.u32 	%r8802, %r8795;
	bra.uni 	BB0_1394;

BB0_1339:
	setp.eq.s32	%p917, %r6374, 15;
	mov.u32 	%r8795, %r8803;
	mov.u32 	%r8796, %r8803;
	mov.u32 	%r8797, %r8803;
	mov.u32 	%r8798, %r8803;
	mov.u32 	%r8799, %r8803;
	mov.u32 	%r8800, %r8803;
	mov.u32 	%r8801, %r8803;
	mov.u32 	%r8802, %r8803;
	@%p917 bra 	BB0_1340;
	bra.uni 	BB0_1394;

BB0_1340:
	mov.u32 	%r6603, 8;
	// inline asm
	shf.r.wrap.b32 %r8799, %r22, %r15, %r6603;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8800, %r21, %r22, %r6603;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8801, %r20, %r21, %r6603;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8802, %r19, %r20, %r6603;
	// inline asm
	mov.u32 	%r8796, 0;
	// inline asm
	shf.r.wrap.b32 %r8795, %r8796, %r19, %r6603;
	// inline asm

BB0_1341:
	mov.u32 	%r8797, %r8796;
	mov.u32 	%r8798, %r8796;
	bra.uni 	BB0_1394;

BB0_1375:
	setp.ne.s32	%p894, %r6374, 31;
	mov.u32 	%r8795, %r8803;
	mov.u32 	%r8796, %r8803;
	mov.u32 	%r8797, %r8803;
	mov.u32 	%r8798, %r8803;
	mov.u32 	%r8799, %r8803;
	mov.u32 	%r8800, %r8803;
	mov.u32 	%r8801, %r8803;
	mov.u32 	%r8802, %r8803;
	@%p894 bra 	BB0_1394;

	mov.u32 	%r8795, 0;
	mov.u32 	%r6379, 8;
	// inline asm
	shf.r.wrap.b32 %r8799, %r8795, %r19, %r6379;
	// inline asm

BB0_1377:
	mov.u32 	%r8796, %r8795;
	mov.u32 	%r8797, %r8795;
	mov.u32 	%r8798, %r8795;
	mov.u32 	%r8800, %r8795;

BB0_1369:
	mov.u32 	%r8801, %r8795;
	mov.u32 	%r8802, %r8795;

BB0_1394:
	// inline asm
	prmt.b32 %r6920, %r8799, 0, 0x0123;
	// inline asm
	// inline asm
	prmt.b32 %r6922, %r8800, 0, 0x0123;
	// inline asm
	// inline asm
	prmt.b32 %r6924, %r8801, 0, 0x0123;
	// inline asm
	// inline asm
	prmt.b32 %r6926, %r8802, 0, 0x0123;
	// inline asm
	// inline asm
	prmt.b32 %r6928, %r8795, 0, 0x0123;
	// inline asm
	// inline asm
	prmt.b32 %r6930, %r8796, 0, 0x0123;
	// inline asm
	// inline asm
	prmt.b32 %r6932, %r8797, 0, 0x0123;
	// inline asm
	and.b32  	%r6943, %r14, 3;
	mov.u32 	%r6944, 4;
	sub.s32 	%r6945, %r6944, %r6943;
	shl.b32 	%r6946, %r6945, 2;
	mov.u32 	%r6947, 1985229328;
	shr.u32 	%r6948, %r6947, %r6946;
	and.b32  	%r1414, %r6948, 65535;
	shr.u32 	%r6942, %r14, 2;
	setp.gt.s32	%p936, %r6942, 3;
	@%p936 bra 	BB0_1402;

	setp.gt.s32	%p942, %r6942, 1;
	@%p942 bra 	BB0_1399;

	setp.eq.s32	%p945, %r6942, 0;
	@%p945 bra 	BB0_1412;
	bra.uni 	BB0_1397;

BB0_1412:
	// inline asm
	prmt.b32 %r7089, %r8798, 0, 0x0123;
	// inline asm
	// inline asm
	prmt.b32 %r8810, %r6932, %r7089, %r1414;
	// inline asm
	// inline asm
	prmt.b32 %r8809, %r6930, %r6932, %r1414;
	// inline asm
	// inline asm
	prmt.b32 %r8808, %r6928, %r6930, %r1414;
	// inline asm
	// inline asm
	prmt.b32 %r8807, %r6926, %r6928, %r1414;
	// inline asm
	// inline asm
	prmt.b32 %r8806, %r6924, %r6926, %r1414;
	// inline asm
	// inline asm
	prmt.b32 %r8805, %r6922, %r6924, %r1414;
	// inline asm
	// inline asm
	prmt.b32 %r8804, %r6920, %r6922, %r1414;
	// inline asm
	mov.u32 	%r7120, 0;
	// inline asm
	prmt.b32 %r8803, %r7120, %r6920, %r1414;
	// inline asm
	bra.uni 	BB0_1413;

BB0_1402:
	setp.gt.s32	%p937, %r6942, 5;
	@%p937 bra 	BB0_1406;

	setp.eq.s32	%p940, %r6942, 4;
	@%p940 bra 	BB0_1410;
	bra.uni 	BB0_1404;

BB0_1410:
	// inline asm
	prmt.b32 %r8810, %r6924, %r6926, %r1414;
	// inline asm
	// inline asm
	prmt.b32 %r8809, %r6922, %r6924, %r1414;
	// inline asm
	// inline asm
	prmt.b32 %r8808, %r6920, %r6922, %r1414;
	// inline asm
	mov.u32 	%r8803, 0;
	// inline asm
	prmt.b32 %r8807, %r8803, %r6920, %r1414;
	// inline asm
	mov.u32 	%r8804, %r8803;
	mov.u32 	%r8805, %r8803;
	mov.u32 	%r8806, %r8803;
	bra.uni 	BB0_1413;

BB0_1399:
	setp.eq.s32	%p943, %r6942, 2;
	@%p943 bra 	BB0_1411;
	bra.uni 	BB0_1400;

BB0_1411:
	// inline asm
	prmt.b32 %r8810, %r6928, %r6930, %r1414;
	// inline asm
	// inline asm
	prmt.b32 %r8809, %r6926, %r6928, %r1414;
	// inline asm
	// inline asm
	prmt.b32 %r8808, %r6924, %r6926, %r1414;
	// inline asm
	// inline asm
	prmt.b32 %r8807, %r6922, %r6924, %r1414;
	// inline asm
	// inline asm
	prmt.b32 %r8806, %r6920, %r6922, %r1414;
	// inline asm
	mov.u32 	%r8803, 0;
	// inline asm
	prmt.b32 %r8805, %r8803, %r6920, %r1414;
	// inline asm
	mov.u32 	%r8804, %r8803;
	bra.uni 	BB0_1413;

BB0_1406:
	setp.eq.s32	%p938, %r6942, 6;
	@%p938 bra 	BB0_1409;
	bra.uni 	BB0_1407;

BB0_1409:
	// inline asm
	prmt.b32 %r8810, %r6920, %r6922, %r1414;
	// inline asm
	mov.u32 	%r8803, 0;
	// inline asm
	prmt.b32 %r8809, %r8803, %r6920, %r1414;
	// inline asm
	mov.u32 	%r8804, %r8803;
	mov.u32 	%r8805, %r8803;
	mov.u32 	%r8806, %r8803;
	mov.u32 	%r8807, %r8803;
	mov.u32 	%r8808, %r8803;
	bra.uni 	BB0_1413;

BB0_1397:
	setp.eq.s32	%p946, %r6942, 1;
	mov.u32 	%r8804, %r8803;
	mov.u32 	%r8805, %r8803;
	mov.u32 	%r8806, %r8803;
	mov.u32 	%r8807, %r8803;
	mov.u32 	%r8808, %r8803;
	mov.u32 	%r8809, %r8803;
	mov.u32 	%r8810, %r8803;
	@%p946 bra 	BB0_1398;
	bra.uni 	BB0_1413;

BB0_1398:
	// inline asm
	prmt.b32 %r8810, %r6930, %r6932, %r1414;
	// inline asm
	// inline asm
	prmt.b32 %r8809, %r6928, %r6930, %r1414;
	// inline asm
	// inline asm
	prmt.b32 %r8808, %r6926, %r6928, %r1414;
	// inline asm
	// inline asm
	prmt.b32 %r8807, %r6924, %r6926, %r1414;
	// inline asm
	// inline asm
	prmt.b32 %r8806, %r6922, %r6924, %r1414;
	// inline asm
	// inline asm
	prmt.b32 %r8805, %r6920, %r6922, %r1414;
	// inline asm
	mov.u32 	%r8803, 0;
	// inline asm
	prmt.b32 %r8804, %r8803, %r6920, %r1414;
	// inline asm
	bra.uni 	BB0_1413;

BB0_1404:
	setp.eq.s32	%p941, %r6942, 5;
	mov.u32 	%r8804, %r8803;
	mov.u32 	%r8805, %r8803;
	mov.u32 	%r8806, %r8803;
	mov.u32 	%r8807, %r8803;
	mov.u32 	%r8808, %r8803;
	mov.u32 	%r8809, %r8803;
	mov.u32 	%r8810, %r8803;
	@%p941 bra 	BB0_1405;
	bra.uni 	BB0_1413;

BB0_1405:
	// inline asm
	prmt.b32 %r8810, %r6922, %r6924, %r1414;
	// inline asm
	// inline asm
	prmt.b32 %r8809, %r6920, %r6922, %r1414;
	// inline asm
	mov.u32 	%r8803, 0;
	// inline asm
	prmt.b32 %r8808, %r8803, %r6920, %r1414;
	// inline asm
	mov.u32 	%r8804, %r8803;
	mov.u32 	%r8805, %r8803;
	mov.u32 	%r8806, %r8803;
	mov.u32 	%r8807, %r8803;
	bra.uni 	BB0_1413;

BB0_1400:
	setp.eq.s32	%p944, %r6942, 3;
	mov.u32 	%r8804, %r8803;
	mov.u32 	%r8805, %r8803;
	mov.u32 	%r8806, %r8803;
	mov.u32 	%r8807, %r8803;
	mov.u32 	%r8808, %r8803;
	mov.u32 	%r8809, %r8803;
	mov.u32 	%r8810, %r8803;
	@%p944 bra 	BB0_1401;
	bra.uni 	BB0_1413;

BB0_1401:
	// inline asm
	prmt.b32 %r8810, %r6926, %r6928, %r1414;
	// inline asm
	// inline asm
	prmt.b32 %r8809, %r6924, %r6926, %r1414;
	// inline asm
	// inline asm
	prmt.b32 %r8808, %r6922, %r6924, %r1414;
	// inline asm
	// inline asm
	prmt.b32 %r8807, %r6920, %r6922, %r1414;
	// inline asm
	mov.u32 	%r8803, 0;
	// inline asm
	prmt.b32 %r8806, %r8803, %r6920, %r1414;
	// inline asm
	mov.u32 	%r8804, %r8803;
	mov.u32 	%r8805, %r8803;
	bra.uni 	BB0_1413;

BB0_1407:
	setp.ne.s32	%p939, %r6942, 7;
	mov.u32 	%r8804, %r8803;
	mov.u32 	%r8805, %r8803;
	mov.u32 	%r8806, %r8803;
	mov.u32 	%r8807, %r8803;
	mov.u32 	%r8808, %r8803;
	mov.u32 	%r8809, %r8803;
	mov.u32 	%r8810, %r8803;
	@%p939 bra 	BB0_1413;

	mov.u32 	%r8803, 0;
	// inline asm
	prmt.b32 %r8810, %r8803, %r6920, %r1414;
	// inline asm
	mov.u32 	%r8804, %r8803;
	mov.u32 	%r8805, %r8803;
	mov.u32 	%r8806, %r8803;
	mov.u32 	%r8807, %r8803;
	mov.u32 	%r8808, %r8803;
	mov.u32 	%r8809, %r8803;

BB0_1413:
	or.b32  	%r8848, %r8803, %r19;
	or.b32  	%r8847, %r8804, %r20;
	or.b32  	%r8846, %r8805, %r21;
	or.b32  	%r8845, %r8806, %r22;
	or.b32  	%r8852, %r8807, %r15;
	or.b32  	%r8851, %r8808, %r16;
	or.b32  	%r8850, %r8809, %r17;
	or.b32  	%r8849, %r8810, %r18;
	bra.uni 	BB0_1554;

BB0_5:
	mov.u32 	%r22, %r8845;
	mov.u32 	%r21, %r8846;
	mov.u32 	%r20, %r8847;
	mov.u32 	%r19, %r8848;
	mov.u32 	%r18, %r8849;
	mov.u32 	%r17, %r8850;
	mov.u32 	%r16, %r8851;
	mov.u32 	%r15, %r8852;
	mov.u32 	%r14, %r8853;
	shr.u32 	%r23, %r8677, 8;
	bfe.u32 	%r24, %r8677, 8, 8;
	shr.u32 	%r25, %r8677, 16;
	bfe.u32 	%r26, %r8677, 16, 8;
	and.b32  	%r1787, %r8677, 255;
	setp.gt.s32	%p5, %r1787, 93;
	@%p5 bra 	BB0_73;

	setp.gt.s32	%p33, %r1787, 68;
	@%p33 bra 	BB0_39;

	setp.gt.s32	%p47, %r1787, 44;
	@%p47 bra 	BB0_23;

	setp.gt.s32	%p54, %r1787, 41;
	@%p54 bra 	BB0_19;

	setp.eq.s32	%p58, %r1787, 36;
	@%p58 bra 	BB0_1312;
	bra.uni 	BB0_10;

BB0_1312:
	add.s32 	%r8853, %r14, 1;
	setp.gt.u32	%p879, %r8853, 31;
	@%p879 bra 	BB0_978;

	and.b32  	%r6354, %r14, 3;
	shl.b32 	%r6355, %r6354, 3;
	shl.b32 	%r6356, %r24, %r6355;
	setp.lt.u32	%p880, %r14, 4;
	selp.b32	%r6357, %r6356, 0, %p880;
	or.b32  	%r8848, %r6357, %r19;
	and.b32  	%r6358, %r14, -4;
	setp.eq.s32	%p881, %r6358, 4;
	selp.b32	%r6359, %r6356, 0, %p881;
	or.b32  	%r8847, %r6359, %r20;
	setp.eq.s32	%p882, %r6358, 8;
	selp.b32	%r6360, %r6356, 0, %p882;
	or.b32  	%r8846, %r6360, %r21;
	setp.eq.s32	%p883, %r6358, 12;
	selp.b32	%r6361, %r6356, 0, %p883;
	or.b32  	%r8845, %r6361, %r22;
	setp.eq.s32	%p884, %r6358, 16;
	selp.b32	%r6362, %r6356, 0, %p884;
	or.b32  	%r8852, %r6362, %r15;
	setp.eq.s32	%p885, %r6358, 20;
	selp.b32	%r6363, %r6356, 0, %p885;
	or.b32  	%r8851, %r6363, %r16;
	setp.eq.s32	%p886, %r6358, 24;
	selp.b32	%r6364, %r6356, 0, %p886;
	or.b32  	%r8850, %r6364, %r17;
	setp.gt.u32	%p887, %r14, 27;
	selp.b32	%r6365, %r6356, 0, %p887;
	or.b32  	%r8849, %r6365, %r18;
	bra.uni 	BB0_1554;

BB0_73:
	setp.gt.s32	%p6, %r1787, 112;
	@%p6 bra 	BB0_102;

	setp.gt.s32	%p20, %r1787, 104;
	@%p20 bra 	BB0_89;

	setp.gt.s32	%p27, %r1787, 99;
	@%p27 bra 	BB0_79;

	setp.eq.s32	%p31, %r1787, 94;
	@%p31 bra 	BB0_1310;
	bra.uni 	BB0_77;

BB0_1310:
	add.s32 	%r8853, %r14, 1;
	setp.gt.u32	%p878, %r8853, 31;
	@%p878 bra 	BB0_978;

	mov.u32 	%r6353, 24;
	// inline asm
	shf.r.wrap.b32 %r8849, %r17, %r18, %r6353;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8850, %r16, %r17, %r6353;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8851, %r15, %r16, %r6353;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8852, %r22, %r15, %r6353;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8845, %r21, %r22, %r6353;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8846, %r20, %r21, %r6353;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8847, %r19, %r20, %r6353;
	// inline asm
	mov.u32 	%r6351, 0;
	// inline asm
	shf.r.wrap.b32 %r6350, %r6351, %r19, %r6353;
	// inline asm
	or.b32  	%r8848, %r6350, %r24;
	bra.uni 	BB0_1554;

BB0_39:
	setp.gt.s32	%p34, %r1787, 83;
	@%p34 bra 	BB0_58;

	setp.gt.s32	%p41, %r1787, 75;
	@%p41 bra 	BB0_50;

	setp.eq.s32	%p45, %r1787, 69;
	@%p45 bra 	BB0_133;
	bra.uni 	BB0_42;

BB0_133:
	and.b32  	%r1820, %r19, 1077952576;
	shr.u32 	%r1821, %r1820, 1;
	and.b32  	%r1822, %r19, -2139062144;
	shr.u32 	%r1823, %r1822, 2;
	not.b32 	%r1824, %r1823;
	and.b32  	%r1825, %r1821, %r1824;
	and.b32  	%r1826, %r19, 522133279;
	add.s32 	%r1827, %r1826, 522133279;
	mov.u32 	%r1828, -84215046;
	sub.s32 	%r1829, %r1828, %r1826;
	and.b32  	%r1830, %r1825, %r1829;
	and.b32  	%r1831, %r1830, %r1827;
	or.b32  	%r1832, %r1831, %r19;
	and.b32  	%r1833, %r20, 1077952576;
	shr.u32 	%r1834, %r1833, 1;
	and.b32  	%r1835, %r20, -2139062144;
	shr.u32 	%r1836, %r1835, 2;
	not.b32 	%r1837, %r1836;
	and.b32  	%r1838, %r1834, %r1837;
	and.b32  	%r1839, %r20, 522133279;
	add.s32 	%r1840, %r1839, 522133279;
	sub.s32 	%r1841, %r1828, %r1839;
	and.b32  	%r1842, %r1838, %r1841;
	and.b32  	%r1843, %r1842, %r1840;
	or.b32  	%r1844, %r1843, %r20;
	and.b32  	%r1845, %r21, 1077952576;
	shr.u32 	%r1846, %r1845, 1;
	and.b32  	%r1847, %r21, -2139062144;
	shr.u32 	%r1848, %r1847, 2;
	not.b32 	%r1849, %r1848;
	and.b32  	%r1850, %r1846, %r1849;
	and.b32  	%r1851, %r21, 522133279;
	add.s32 	%r1852, %r1851, 522133279;
	sub.s32 	%r1853, %r1828, %r1851;
	and.b32  	%r1854, %r1850, %r1853;
	and.b32  	%r1855, %r1854, %r1852;
	or.b32  	%r1856, %r1855, %r21;
	and.b32  	%r1857, %r22, 1077952576;
	shr.u32 	%r1858, %r1857, 1;
	and.b32  	%r1859, %r22, -2139062144;
	shr.u32 	%r1860, %r1859, 2;
	not.b32 	%r1861, %r1860;
	and.b32  	%r1862, %r1858, %r1861;
	and.b32  	%r1863, %r22, 522133279;
	add.s32 	%r1864, %r1863, 522133279;
	sub.s32 	%r1865, %r1828, %r1863;
	and.b32  	%r1866, %r1862, %r1865;
	and.b32  	%r1867, %r1866, %r1864;
	or.b32  	%r1868, %r1867, %r22;
	and.b32  	%r1869, %r15, 1077952576;
	shr.u32 	%r1870, %r1869, 1;
	and.b32  	%r1871, %r15, -2139062144;
	shr.u32 	%r1872, %r1871, 2;
	not.b32 	%r1873, %r1872;
	and.b32  	%r1874, %r1870, %r1873;
	and.b32  	%r1875, %r15, 522133279;
	add.s32 	%r1876, %r1875, 522133279;
	sub.s32 	%r1877, %r1828, %r1875;
	and.b32  	%r1878, %r1874, %r1877;
	and.b32  	%r1879, %r1878, %r1876;
	or.b32  	%r1880, %r1879, %r15;
	and.b32  	%r1881, %r16, 1077952576;
	shr.u32 	%r1882, %r1881, 1;
	and.b32  	%r1883, %r16, -2139062144;
	shr.u32 	%r1884, %r1883, 2;
	not.b32 	%r1885, %r1884;
	and.b32  	%r1886, %r1882, %r1885;
	and.b32  	%r1887, %r16, 522133279;
	add.s32 	%r1888, %r1887, 522133279;
	sub.s32 	%r1889, %r1828, %r1887;
	and.b32  	%r1890, %r1886, %r1889;
	and.b32  	%r1891, %r1890, %r1888;
	or.b32  	%r1892, %r1891, %r16;
	and.b32  	%r1893, %r17, 1077952576;
	shr.u32 	%r1894, %r1893, 1;
	and.b32  	%r1895, %r17, -2139062144;
	shr.u32 	%r1896, %r1895, 2;
	not.b32 	%r1897, %r1896;
	and.b32  	%r1898, %r1894, %r1897;
	and.b32  	%r1899, %r17, 522133279;
	add.s32 	%r1900, %r1899, 522133279;
	sub.s32 	%r1901, %r1828, %r1899;
	and.b32  	%r1902, %r1898, %r1901;
	and.b32  	%r1903, %r1902, %r1900;
	or.b32  	%r1904, %r1903, %r17;
	and.b32  	%r1905, %r18, 1077952576;
	shr.u32 	%r1906, %r1905, 1;
	and.b32  	%r1907, %r18, -2139062144;
	shr.u32 	%r1908, %r1907, 2;
	not.b32 	%r1909, %r1908;
	and.b32  	%r1910, %r1906, %r1909;
	and.b32  	%r1911, %r18, 522133279;
	add.s32 	%r1912, %r1911, 522133279;
	sub.s32 	%r1913, %r1828, %r1911;
	and.b32  	%r1914, %r1910, %r1913;
	and.b32  	%r1915, %r1914, %r1912;
	or.b32  	%r1916, %r1915, %r18;
	mov.b32	{%rs10, %rs11}, %r1832;
	shr.u16 	%rs12, %rs11, 8;
	setp.eq.s16	%p60, %rs12, 32;
	and.b16  	%rs13, %rs11, 255;
	setp.eq.s16	%p61, %rs13, 32;
	shr.u16 	%rs14, %rs10, 8;
	setp.eq.s16	%p62, %rs14, 32;
	and.b16  	%rs15, %rs10, 255;
	setp.eq.s16	%p63, %rs15, 32;
	selp.b16	%rs16, -1, 0, %p63;
	selp.b16	%rs17, -1, 0, %p62;
	selp.b16	%rs18, -1, 0, %p61;
	selp.b16	%rs19, -1, 0, %p60;
	shl.b16 	%rs20, %rs19, 1;
	and.b16  	%rs21, %rs20, -256;
	shr.u16 	%rs22, %rs18, 7;
	and.b16  	%rs23, %rs22, 255;
	or.b16  	%rs24, %rs23, %rs21;
	shl.b16 	%rs25, %rs17, 1;
	and.b16  	%rs26, %rs25, -256;
	shr.u16 	%rs27, %rs16, 7;
	and.b16  	%rs28, %rs27, 255;
	or.b16  	%rs29, %rs28, %rs26;
	mov.b32	%r1818, {%rs29, %rs24};
	mov.b32	{%rs30, %rs31}, %r1844;
	shr.u16 	%rs32, %rs31, 8;
	setp.eq.s16	%p64, %rs32, 32;
	and.b16  	%rs33, %rs31, 255;
	setp.eq.s16	%p65, %rs33, 32;
	shr.u16 	%rs34, %rs30, 8;
	setp.eq.s16	%p66, %rs34, 32;
	and.b16  	%rs35, %rs30, 255;
	setp.eq.s16	%p67, %rs35, 32;
	selp.b16	%rs36, -1, 0, %p67;
	selp.b16	%rs37, -1, 0, %p66;
	selp.b16	%rs38, -1, 0, %p65;
	selp.b16	%rs39, -1, 0, %p64;
	shl.b16 	%rs40, %rs39, 1;
	and.b16  	%rs41, %rs40, -256;
	shr.u16 	%rs42, %rs38, 7;
	and.b16  	%rs43, %rs42, 255;
	or.b16  	%rs44, %rs43, %rs41;
	shl.b16 	%rs45, %rs37, 1;
	and.b16  	%rs46, %rs45, -256;
	shr.u16 	%rs47, %rs36, 7;
	and.b16  	%rs48, %rs47, 255;
	or.b16  	%rs49, %rs48, %rs46;
	mov.b32	%r1814, {%rs49, %rs44};
	mov.b32	{%rs50, %rs51}, %r1856;
	shr.u16 	%rs52, %rs51, 8;
	setp.eq.s16	%p68, %rs52, 32;
	and.b16  	%rs53, %rs51, 255;
	setp.eq.s16	%p69, %rs53, 32;
	shr.u16 	%rs54, %rs50, 8;
	setp.eq.s16	%p70, %rs54, 32;
	and.b16  	%rs55, %rs50, 255;
	setp.eq.s16	%p71, %rs55, 32;
	selp.b16	%rs56, -1, 0, %p71;
	selp.b16	%rs57, -1, 0, %p70;
	selp.b16	%rs58, -1, 0, %p69;
	selp.b16	%rs59, -1, 0, %p68;
	shl.b16 	%rs60, %rs59, 1;
	and.b16  	%rs61, %rs60, -256;
	shr.u16 	%rs62, %rs58, 7;
	and.b16  	%rs63, %rs62, 255;
	or.b16  	%rs64, %rs63, %rs61;
	shl.b16 	%rs65, %rs57, 1;
	and.b16  	%rs66, %rs65, -256;
	shr.u16 	%rs67, %rs56, 7;
	and.b16  	%rs68, %rs67, 255;
	or.b16  	%rs69, %rs68, %rs66;
	mov.b32	%r1810, {%rs69, %rs64};
	mov.b32	{%rs70, %rs71}, %r1868;
	shr.u16 	%rs72, %rs71, 8;
	setp.eq.s16	%p72, %rs72, 32;
	and.b16  	%rs73, %rs71, 255;
	setp.eq.s16	%p73, %rs73, 32;
	shr.u16 	%rs74, %rs70, 8;
	setp.eq.s16	%p74, %rs74, 32;
	and.b16  	%rs75, %rs70, 255;
	setp.eq.s16	%p75, %rs75, 32;
	selp.b16	%rs76, -1, 0, %p75;
	selp.b16	%rs77, -1, 0, %p74;
	selp.b16	%rs78, -1, 0, %p73;
	selp.b16	%rs79, -1, 0, %p72;
	shl.b16 	%rs80, %rs79, 1;
	and.b16  	%rs81, %rs80, -256;
	shr.u16 	%rs82, %rs78, 7;
	and.b16  	%rs83, %rs82, 255;
	or.b16  	%rs84, %rs83, %rs81;
	shl.b16 	%rs85, %rs77, 1;
	and.b16  	%rs86, %rs85, -256;
	shr.u16 	%rs87, %rs76, 7;
	and.b16  	%rs88, %rs87, 255;
	or.b16  	%rs89, %rs88, %rs86;
	mov.b32	%r1806, {%rs89, %rs84};
	mov.b32	{%rs90, %rs91}, %r1880;
	shr.u16 	%rs92, %rs91, 8;
	setp.eq.s16	%p76, %rs92, 32;
	and.b16  	%rs93, %rs91, 255;
	setp.eq.s16	%p77, %rs93, 32;
	shr.u16 	%rs94, %rs90, 8;
	setp.eq.s16	%p78, %rs94, 32;
	and.b16  	%rs95, %rs90, 255;
	setp.eq.s16	%p79, %rs95, 32;
	selp.b16	%rs96, -1, 0, %p79;
	selp.b16	%rs97, -1, 0, %p78;
	selp.b16	%rs98, -1, 0, %p77;
	selp.b16	%rs99, -1, 0, %p76;
	shl.b16 	%rs100, %rs99, 1;
	and.b16  	%rs101, %rs100, -256;
	shr.u16 	%rs102, %rs98, 7;
	and.b16  	%rs103, %rs102, 255;
	or.b16  	%rs104, %rs103, %rs101;
	shl.b16 	%rs105, %rs97, 1;
	and.b16  	%rs106, %rs105, -256;
	shr.u16 	%rs107, %rs96, 7;
	and.b16  	%rs108, %rs107, 255;
	or.b16  	%rs109, %rs108, %rs106;
	mov.b32	%r1802, {%rs109, %rs104};
	mov.b32	{%rs110, %rs111}, %r1892;
	shr.u16 	%rs112, %rs111, 8;
	setp.eq.s16	%p80, %rs112, 32;
	and.b16  	%rs113, %rs111, 255;
	setp.eq.s16	%p81, %rs113, 32;
	shr.u16 	%rs114, %rs110, 8;
	setp.eq.s16	%p82, %rs114, 32;
	and.b16  	%rs115, %rs110, 255;
	setp.eq.s16	%p83, %rs115, 32;
	selp.b16	%rs116, -1, 0, %p83;
	selp.b16	%rs117, -1, 0, %p82;
	selp.b16	%rs118, -1, 0, %p81;
	selp.b16	%rs119, -1, 0, %p80;
	shl.b16 	%rs120, %rs119, 1;
	and.b16  	%rs121, %rs120, -256;
	shr.u16 	%rs122, %rs118, 7;
	and.b16  	%rs123, %rs122, 255;
	or.b16  	%rs124, %rs123, %rs121;
	shl.b16 	%rs125, %rs117, 1;
	and.b16  	%rs126, %rs125, -256;
	shr.u16 	%rs127, %rs116, 7;
	and.b16  	%rs128, %rs127, 255;
	or.b16  	%rs129, %rs128, %rs126;
	mov.b32	%r1798, {%rs129, %rs124};
	mov.b32	{%rs130, %rs131}, %r1904;
	shr.u16 	%rs132, %rs131, 8;
	setp.eq.s16	%p84, %rs132, 32;
	and.b16  	%rs133, %rs131, 255;
	setp.eq.s16	%p85, %rs133, 32;
	shr.u16 	%rs134, %rs130, 8;
	setp.eq.s16	%p86, %rs134, 32;
	and.b16  	%rs135, %rs130, 255;
	setp.eq.s16	%p87, %rs135, 32;
	selp.b16	%rs136, -1, 0, %p87;
	selp.b16	%rs137, -1, 0, %p86;
	selp.b16	%rs138, -1, 0, %p85;
	selp.b16	%rs139, -1, 0, %p84;
	shl.b16 	%rs140, %rs139, 1;
	and.b16  	%rs141, %rs140, -256;
	shr.u16 	%rs142, %rs138, 7;
	and.b16  	%rs143, %rs142, 255;
	or.b16  	%rs144, %rs143, %rs141;
	shl.b16 	%rs145, %rs137, 1;
	and.b16  	%rs146, %rs145, -256;
	shr.u16 	%rs147, %rs136, 7;
	and.b16  	%rs148, %rs147, 255;
	or.b16  	%rs149, %rs148, %rs146;
	mov.b32	%r1794, {%rs149, %rs144};
	mov.b32	{%rs150, %rs151}, %r1916;
	shr.u16 	%rs152, %rs151, 8;
	setp.eq.s16	%p88, %rs152, 32;
	and.b16  	%rs153, %rs151, 255;
	setp.eq.s16	%p89, %rs153, 32;
	shr.u16 	%rs154, %rs150, 8;
	setp.eq.s16	%p90, %rs154, 32;
	and.b16  	%rs155, %rs150, 255;
	setp.eq.s16	%p91, %rs155, 32;
	selp.b16	%rs156, -1, 0, %p91;
	selp.b16	%rs157, -1, 0, %p90;
	selp.b16	%rs158, -1, 0, %p89;
	selp.b16	%rs159, -1, 0, %p88;
	shl.b16 	%rs160, %rs159, 1;
	and.b16  	%rs161, %rs160, -256;
	shr.u16 	%rs162, %rs158, 7;
	and.b16  	%rs163, %rs162, 255;
	or.b16  	%rs164, %rs163, %rs161;
	shl.b16 	%rs165, %rs157, 1;
	and.b16  	%rs166, %rs165, -256;
	shr.u16 	%rs167, %rs156, 7;
	and.b16  	%rs168, %rs167, 255;
	or.b16  	%rs169, %rs168, %rs166;
	mov.b32	%r1790, {%rs169, %rs164};
	mov.u32 	%r1819, 24;
	// inline asm
	shf.r.wrap.b32 %r1788, %r1794, %r1790, %r1819;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r1792, %r1798, %r1794, %r1819;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r1796, %r1802, %r1798, %r1819;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r1800, %r1806, %r1802, %r1819;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r1804, %r1810, %r1806, %r1819;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r1808, %r1814, %r1810, %r1819;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r1812, %r1818, %r1814, %r1819;
	// inline asm
	mov.u32 	%r1817, 0;
	// inline asm
	shf.r.wrap.b32 %r1816, %r1817, %r1818, %r1819;
	// inline asm
	or.b32  	%r1917, %r1816, 255;
	and.b32  	%r1918, %r1832, 1077952576;
	shr.u32 	%r1919, %r1918, 1;
	and.b32  	%r1920, %r1832, -2139062144;
	shr.u32 	%r1921, %r1920, 2;
	not.b32 	%r1922, %r1921;
	and.b32  	%r1923, %r1919, %r1922;
	and.b32  	%r1924, %r1832, 522133279;
	add.s32 	%r1925, %r1924, 522133279;
	sub.s32 	%r1926, %r1828, %r1924;
	and.b32  	%r1927, %r1923, %r1926;
	and.b32  	%r1928, %r1927, %r1925;
	and.b32  	%r1929, %r1928, %r1917;
	not.b32 	%r1930, %r1929;
	and.b32  	%r8848, %r1832, %r1930;
	and.b32  	%r1931, %r1844, 1077952576;
	shr.u32 	%r1932, %r1931, 1;
	and.b32  	%r1933, %r1844, -2139062144;
	shr.u32 	%r1934, %r1933, 2;
	not.b32 	%r1935, %r1934;
	and.b32  	%r1936, %r1932, %r1935;
	and.b32  	%r1937, %r1844, 522133279;
	add.s32 	%r1938, %r1937, 522133279;
	sub.s32 	%r1939, %r1828, %r1937;
	and.b32  	%r1940, %r1936, %r1939;
	and.b32  	%r1941, %r1940, %r1938;
	and.b32  	%r1942, %r1941, %r1812;
	not.b32 	%r1943, %r1942;
	and.b32  	%r8847, %r1844, %r1943;
	and.b32  	%r1944, %r1856, 1077952576;
	shr.u32 	%r1945, %r1944, 1;
	and.b32  	%r1946, %r1856, -2139062144;
	shr.u32 	%r1947, %r1946, 2;
	not.b32 	%r1948, %r1947;
	and.b32  	%r1949, %r1945, %r1948;
	and.b32  	%r1950, %r1856, 522133279;
	add.s32 	%r1951, %r1950, 522133279;
	sub.s32 	%r1952, %r1828, %r1950;
	and.b32  	%r1953, %r1949, %r1952;
	and.b32  	%r1954, %r1953, %r1951;
	and.b32  	%r1955, %r1954, %r1808;
	not.b32 	%r1956, %r1955;
	and.b32  	%r8846, %r1856, %r1956;
	and.b32  	%r1957, %r1868, 1077952576;
	shr.u32 	%r1958, %r1957, 1;
	and.b32  	%r1959, %r1868, -2139062144;
	shr.u32 	%r1960, %r1959, 2;
	not.b32 	%r1961, %r1960;
	and.b32  	%r1962, %r1958, %r1961;
	and.b32  	%r1963, %r1868, 522133279;
	add.s32 	%r1964, %r1963, 522133279;
	sub.s32 	%r1965, %r1828, %r1963;
	and.b32  	%r1966, %r1962, %r1965;
	and.b32  	%r1967, %r1966, %r1964;
	and.b32  	%r1968, %r1967, %r1804;
	not.b32 	%r1969, %r1968;
	and.b32  	%r8845, %r1868, %r1969;
	and.b32  	%r1970, %r1880, 1077952576;
	shr.u32 	%r1971, %r1970, 1;
	and.b32  	%r1972, %r1880, -2139062144;
	shr.u32 	%r1973, %r1972, 2;
	not.b32 	%r1974, %r1973;
	and.b32  	%r1975, %r1971, %r1974;
	and.b32  	%r1976, %r1880, 522133279;
	add.s32 	%r1977, %r1976, 522133279;
	sub.s32 	%r1978, %r1828, %r1976;
	and.b32  	%r1979, %r1975, %r1978;
	and.b32  	%r1980, %r1979, %r1977;
	and.b32  	%r1981, %r1980, %r1800;
	not.b32 	%r1982, %r1981;
	and.b32  	%r8852, %r1880, %r1982;
	and.b32  	%r1983, %r1892, 1077952576;
	shr.u32 	%r1984, %r1983, 1;
	and.b32  	%r1985, %r1892, -2139062144;
	shr.u32 	%r1986, %r1985, 2;
	not.b32 	%r1987, %r1986;
	and.b32  	%r1988, %r1984, %r1987;
	and.b32  	%r1989, %r1892, 522133279;
	add.s32 	%r1990, %r1989, 522133279;
	sub.s32 	%r1991, %r1828, %r1989;
	and.b32  	%r1992, %r1988, %r1991;
	and.b32  	%r1993, %r1992, %r1990;
	and.b32  	%r1994, %r1993, %r1796;
	not.b32 	%r1995, %r1994;
	and.b32  	%r8851, %r1892, %r1995;
	and.b32  	%r1996, %r1904, 1077952576;
	shr.u32 	%r1997, %r1996, 1;
	and.b32  	%r1998, %r1904, -2139062144;
	shr.u32 	%r1999, %r1998, 2;
	not.b32 	%r2000, %r1999;
	and.b32  	%r2001, %r1997, %r2000;
	and.b32  	%r2002, %r1904, 522133279;
	add.s32 	%r2003, %r2002, 522133279;
	sub.s32 	%r2004, %r1828, %r2002;
	and.b32  	%r2005, %r2001, %r2004;
	and.b32  	%r2006, %r2005, %r2003;
	and.b32  	%r2007, %r2006, %r1792;
	not.b32 	%r2008, %r2007;
	and.b32  	%r8850, %r1904, %r2008;
	and.b32  	%r2009, %r1916, 1077952576;
	shr.u32 	%r2010, %r2009, 1;
	and.b32  	%r2011, %r1916, -2139062144;
	shr.u32 	%r2012, %r2011, 2;
	not.b32 	%r2013, %r2012;
	and.b32  	%r2014, %r2010, %r2013;
	and.b32  	%r2015, %r1916, 522133279;
	add.s32 	%r2016, %r2015, 522133279;
	sub.s32 	%r2017, %r1828, %r2015;
	and.b32  	%r2018, %r2014, %r2017;
	and.b32  	%r2019, %r2018, %r2016;
	and.b32  	%r2020, %r2019, %r1788;
	not.b32 	%r2021, %r2020;
	and.b32  	%r8849, %r1916, %r2021;
	mov.u32 	%r8853, %r14;
	bra.uni 	BB0_1554;

BB0_102:
	setp.gt.s32	%p7, %r1787, 119;
	@%p7 bra 	BB0_116;

	setp.gt.s32	%p14, %r1787, 114;
	@%p14 bra 	BB0_112;

	setp.eq.s32	%p18, %r1787, 113;
	@%p18 bra 	BB0_783;
	bra.uni 	BB0_105;

BB0_783:
	setp.eq.s32	%p507, %r14, 0;
	add.s32 	%r8853, %r14, %r14;
	setp.gt.u32	%p508, %r8853, 31;
	or.pred  	%p509, %p507, %p508;
	@%p509 bra 	BB0_11;

	and.b32  	%r3927, %r19, 255;
	and.b32  	%r3928, %r19, 65280;
	prmt.b32 	%r3929, %r3928, %r3927, 8452;
	bfe.u32 	%r3930, %r19, 16, 8;
	and.b32  	%r3931, %r19, -16777216;
	shr.u32 	%r3932, %r3931, 8;
	or.b32  	%r3933, %r3930, %r3932;
	and.b32  	%r3934, %r20, 65280;
	and.b32  	%r3935, %r20, 255;
	prmt.b32 	%r3936, %r3934, %r3935, 8452;
	bfe.u32 	%r3937, %r20, 16, 8;
	and.b32  	%r3938, %r20, -16777216;
	shr.u32 	%r3939, %r3938, 8;
	or.b32  	%r3940, %r3937, %r3939;
	and.b32  	%r3941, %r21, 65280;
	and.b32  	%r3942, %r21, 255;
	prmt.b32 	%r3943, %r3941, %r3942, 8452;
	bfe.u32 	%r3944, %r21, 16, 8;
	and.b32  	%r3945, %r21, -16777216;
	shr.u32 	%r3946, %r3945, 8;
	or.b32  	%r3947, %r3944, %r3946;
	and.b32  	%r3948, %r22, 65280;
	and.b32  	%r3949, %r22, 255;
	prmt.b32 	%r3950, %r3948, %r3949, 8452;
	bfe.u32 	%r3951, %r22, 16, 8;
	and.b32  	%r3952, %r22, -16777216;
	shr.u32 	%r3953, %r3952, 8;
	or.b32  	%r3954, %r3951, %r3953;
	shl.b32 	%r3955, %r3929, 8;
	or.b32  	%r8848, %r3955, %r3929;
	shl.b32 	%r3956, %r3933, 8;
	or.b32  	%r8847, %r3956, %r3933;
	shl.b32 	%r3957, %r3936, 8;
	or.b32  	%r8846, %r3957, %r3936;
	shl.b32 	%r3958, %r3940, 8;
	or.b32  	%r8845, %r3958, %r3940;
	shl.b32 	%r3959, %r3943, 8;
	or.b32  	%r8852, %r3959, %r3943;
	shl.b32 	%r3960, %r3947, 8;
	or.b32  	%r8851, %r3960, %r3947;
	shl.b32 	%r3961, %r3950, 8;
	or.b32  	%r8850, %r3961, %r3950;
	shl.b32 	%r3962, %r3954, 8;
	or.b32  	%r8849, %r3962, %r3954;
	bra.uni 	BB0_1554;

BB0_23:
	setp.gt.s32	%p48, %r1787, 63;
	@%p48 bra 	BB0_31;

	setp.eq.s32	%p52, %r1787, 45;
	@%p52 bra 	BB0_373;
	bra.uni 	BB0_25;

BB0_373:
	setp.ge.u32	%p270, %r24, %r14;
	@%p270 bra 	BB0_11;

	and.b32  	%r3523, %r23, 3;
	shl.b32 	%r3524, %r3523, 3;
	mov.u32 	%r3525, 255;
	shl.b32 	%r361, %r3525, %r3524;
	not.b32 	%r362, %r361;
	and.b32  	%r363, %r361, 16843009;
	shr.u32 	%r3522, %r24, 2;
	setp.gt.s32	%p271, %r3522, 3;
	@%p271 bra 	BB0_382;

	setp.gt.s32	%p277, %r3522, 1;
	@%p277 bra 	BB0_379;

	setp.eq.s32	%p280, %r3522, 0;
	@%p280 bra 	BB0_392;
	bra.uni 	BB0_377;

BB0_392:
	and.b32  	%r3554, %r19, %r362;
	and.b32  	%r3555, %r361, %r19;
	sub.s32 	%r3556, %r3555, %r363;
	and.b32  	%r3557, %r3556, %r361;
	or.b32  	%r8848, %r3557, %r3554;
	bra.uni 	BB0_617;

BB0_89:
	setp.gt.s32	%p21, %r1787, 107;
	@%p21 bra 	BB0_94;

	setp.eq.s32	%p25, %r1787, 105;
	@%p25 bra 	BB0_1029;
	bra.uni 	BB0_91;

BB0_1029:
	setp.gt.u32	%p693, %r24, %r14;
	add.s32 	%r8853, %r14, 1;
	setp.gt.u32	%p694, %r8853, 31;
	or.pred  	%p695, %p693, %p694;
	@%p695 bra 	BB0_978;

	mov.u32 	%r4900, 24;
	// inline asm
	shf.r.wrap.b32 %r8849, %r17, %r18, %r4900;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8850, %r16, %r17, %r4900;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8851, %r15, %r16, %r4900;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8852, %r22, %r15, %r4900;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8845, %r21, %r22, %r4900;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8846, %r20, %r21, %r4900;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8847, %r19, %r20, %r4900;
	// inline asm
	and.b32  	%r4902, %r23, 3;
	shl.b32 	%r4903, %r4902, 3;
	shl.b32 	%r931, %r26, %r4903;
	mov.u32 	%r4904, 1;
	shl.b32 	%r4905, %r4904, %r4903;
	add.s32 	%r932, %r4905, -1;
	mov.u32 	%r4906, -256;
	shl.b32 	%r933, %r4906, %r4903;
	shr.u32 	%r4901, %r24, 2;
	setp.gt.s32	%p696, %r4901, 3;
	@%p696 bra 	BB0_1038;

	setp.gt.s32	%p702, %r4901, 1;
	@%p702 bra 	BB0_1035;

	setp.eq.s32	%p705, %r4901, 0;
	@%p705 bra 	BB0_1051;
	bra.uni 	BB0_1033;

BB0_1051:
	mov.u32 	%r8676, 24;
	mov.u32 	%r4929, 0;
	// inline asm
	shf.r.wrap.b32 %r4928, %r4929, %r19, %r8676;
	// inline asm
	and.b32  	%r4932, %r932, %r19;
	or.b32  	%r4933, %r4932, %r931;
	and.b32  	%r4934, %r4928, %r933;
	or.b32  	%r8848, %r4933, %r4934;
	bra.uni 	BB0_1554;

BB0_58:
	setp.gt.s32	%p35, %r1787, 89;
	@%p35 bra 	BB0_68;

	setp.eq.s32	%p39, %r1787, 84;
	@%p39 bra 	BB0_1530;
	bra.uni 	BB0_60;

BB0_1530:
	setp.ge.u32	%p1019, %r24, %r14;
	@%p1019 bra 	BB0_978;

	and.b32  	%r8062, %r23, 3;
	shl.b32 	%r8063, %r8062, 3;
	mov.u32 	%r8064, 32;
	shl.b32 	%r1710, %r8064, %r8063;
	shr.u32 	%r8061, %r24, 2;
	setp.gt.s32	%p1020, %r8061, 3;
	@%p1020 bra 	BB0_1539;

	setp.gt.s32	%p1026, %r8061, 1;
	@%p1026 bra 	BB0_1536;

	setp.eq.s32	%p1029, %r8061, 0;
	@%p1029 bra 	BB0_1549;
	bra.uni 	BB0_1534;

BB0_1549:
	and.b32  	%r8156, %r19, 1077952576;
	shr.u32 	%r8157, %r8156, 1;
	and.b32  	%r8158, %r19, -2139062144;
	shr.u32 	%r8159, %r8158, 2;
	not.b32 	%r8160, %r8159;
	and.b32  	%r8161, %r8157, %r8160;
	and.b32  	%r8162, %r19, 522133279;
	add.s32 	%r8163, %r8162, 522133279;
	mov.u32 	%r8164, -84215046;
	sub.s32 	%r8165, %r8164, %r8162;
	and.b32  	%r8166, %r8161, %r8165;
	and.b32  	%r8167, %r8166, %r8163;
	and.b32  	%r8168, %r8167, %r1710;
	xor.b32  	%r8848, %r8168, %r19;
	bra.uni 	BB0_1028;

BB0_116:
	setp.gt.s32	%p8, %r1787, 121;
	@%p8 bra 	BB0_124;

	setp.eq.s32	%p12, %r1787, 120;
	@%p12 bra 	BB0_1162;
	bra.uni 	BB0_118;

BB0_1162:
	setp.ge.u32	%p768, %r24, %r14;
	add.s32 	%r5509, %r24, %r26;
	setp.gt.u32	%p769, %r5509, %r14;
	or.pred  	%p770, %p768, %p769;
	@%p770 bra 	BB0_978;

	setp.gt.s32	%p771, %r24, 15;
	@%p771 bra 	BB0_1192;

	setp.gt.s32	%p795, %r24, 7;
	@%p795 bra 	BB0_1177;

	setp.gt.s32	%p807, %r24, 3;
	@%p807 bra 	BB0_1170;

	setp.eq.s32	%p813, %r24, 1;
	@%p813 bra 	BB0_1241;

	setp.eq.s32	%p814, %r24, 2;
	@%p814 bra 	BB0_1240;
	bra.uni 	BB0_1168;

BB0_1240:
	mov.u32 	%r6010, 16;
	// inline asm
	shf.r.wrap.b32 %r5979, %r19, %r20, %r6010;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8847, %r20, %r21, %r6010;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8846, %r21, %r22, %r6010;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8845, %r22, %r15, %r6010;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5995, %r15, %r16, %r6010;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8851, %r16, %r17, %r6010;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8850, %r17, %r18, %r6010;
	// inline asm
	mov.u32 	%r6009, 0;
	// inline asm
	shf.r.wrap.b32 %r8849, %r18, %r6009, %r6010;
	// inline asm
	mov.u32 	%r22, %r5979;
	mov.u32 	%r18, %r5995;
	bra.uni 	BB0_1245;

BB0_19:
	setp.eq.s32	%p55, %r1787, 42;
	@%p55 bra 	BB0_448;

	setp.eq.s32	%p56, %r1787, 43;
	@%p56 bra 	BB0_393;
	bra.uni 	BB0_21;

BB0_393:
	setp.ge.u32	%p282, %r24, %r14;
	@%p282 bra 	BB0_11;

	and.b32  	%r3559, %r23, 3;
	shl.b32 	%r3560, %r3559, 3;
	mov.u32 	%r3561, 255;
	shl.b32 	%r372, %r3561, %r3560;
	not.b32 	%r373, %r372;
	and.b32  	%r374, %r372, 16843009;
	shr.u32 	%r3558, %r24, 2;
	setp.gt.s32	%p283, %r3558, 3;
	@%p283 bra 	BB0_402;

	setp.gt.s32	%p289, %r3558, 1;
	@%p289 bra 	BB0_399;

	setp.eq.s32	%p292, %r3558, 0;
	@%p292 bra 	BB0_412;
	bra.uni 	BB0_397;

BB0_412:
	and.b32  	%r3590, %r19, %r373;
	and.b32  	%r3591, %r372, %r19;
	add.s32 	%r3592, %r3591, %r374;
	and.b32  	%r3593, %r3592, %r372;
	or.b32  	%r8848, %r3593, %r3590;
	bra.uni 	BB0_617;

BB0_79:
	setp.eq.s32	%p28, %r1787, 100;
	@%p28 bra 	BB0_1430;

	setp.eq.s32	%p29, %r1787, 101;
	@%p29 bra 	BB0_134;
	bra.uni 	BB0_81;

BB0_134:
	and.b32  	%r2054, %r19, 1077952576;
	shr.u32 	%r2055, %r2054, 1;
	and.b32  	%r2056, %r19, -2139062144;
	shr.u32 	%r2057, %r2056, 2;
	not.b32 	%r2058, %r2057;
	and.b32  	%r2059, %r2055, %r2058;
	and.b32  	%r2060, %r19, 522133279;
	add.s32 	%r2061, %r2060, 522133279;
	mov.u32 	%r2062, -84215046;
	sub.s32 	%r2063, %r2062, %r2060;
	and.b32  	%r2064, %r2059, %r2063;
	and.b32  	%r2065, %r2064, %r2061;
	or.b32  	%r2066, %r2065, %r19;
	and.b32  	%r2067, %r20, 1077952576;
	shr.u32 	%r2068, %r2067, 1;
	and.b32  	%r2069, %r20, -2139062144;
	shr.u32 	%r2070, %r2069, 2;
	not.b32 	%r2071, %r2070;
	and.b32  	%r2072, %r2068, %r2071;
	and.b32  	%r2073, %r20, 522133279;
	add.s32 	%r2074, %r2073, 522133279;
	sub.s32 	%r2075, %r2062, %r2073;
	and.b32  	%r2076, %r2072, %r2075;
	and.b32  	%r2077, %r2076, %r2074;
	or.b32  	%r2078, %r2077, %r20;
	and.b32  	%r2079, %r21, 1077952576;
	shr.u32 	%r2080, %r2079, 1;
	and.b32  	%r2081, %r21, -2139062144;
	shr.u32 	%r2082, %r2081, 2;
	not.b32 	%r2083, %r2082;
	and.b32  	%r2084, %r2080, %r2083;
	and.b32  	%r2085, %r21, 522133279;
	add.s32 	%r2086, %r2085, 522133279;
	sub.s32 	%r2087, %r2062, %r2085;
	and.b32  	%r2088, %r2084, %r2087;
	and.b32  	%r2089, %r2088, %r2086;
	or.b32  	%r2090, %r2089, %r21;
	and.b32  	%r2091, %r22, 1077952576;
	shr.u32 	%r2092, %r2091, 1;
	and.b32  	%r2093, %r22, -2139062144;
	shr.u32 	%r2094, %r2093, 2;
	not.b32 	%r2095, %r2094;
	and.b32  	%r2096, %r2092, %r2095;
	and.b32  	%r2097, %r22, 522133279;
	add.s32 	%r2098, %r2097, 522133279;
	sub.s32 	%r2099, %r2062, %r2097;
	and.b32  	%r2100, %r2096, %r2099;
	and.b32  	%r2101, %r2100, %r2098;
	or.b32  	%r2102, %r2101, %r22;
	and.b32  	%r2103, %r15, 1077952576;
	shr.u32 	%r2104, %r2103, 1;
	and.b32  	%r2105, %r15, -2139062144;
	shr.u32 	%r2106, %r2105, 2;
	not.b32 	%r2107, %r2106;
	and.b32  	%r2108, %r2104, %r2107;
	and.b32  	%r2109, %r15, 522133279;
	add.s32 	%r2110, %r2109, 522133279;
	sub.s32 	%r2111, %r2062, %r2109;
	and.b32  	%r2112, %r2108, %r2111;
	and.b32  	%r2113, %r2112, %r2110;
	or.b32  	%r2114, %r2113, %r15;
	and.b32  	%r2115, %r16, 1077952576;
	shr.u32 	%r2116, %r2115, 1;
	and.b32  	%r2117, %r16, -2139062144;
	shr.u32 	%r2118, %r2117, 2;
	not.b32 	%r2119, %r2118;
	and.b32  	%r2120, %r2116, %r2119;
	and.b32  	%r2121, %r16, 522133279;
	add.s32 	%r2122, %r2121, 522133279;
	sub.s32 	%r2123, %r2062, %r2121;
	and.b32  	%r2124, %r2120, %r2123;
	and.b32  	%r2125, %r2124, %r2122;
	or.b32  	%r2126, %r2125, %r16;
	and.b32  	%r2127, %r17, 1077952576;
	shr.u32 	%r2128, %r2127, 1;
	and.b32  	%r2129, %r17, -2139062144;
	shr.u32 	%r2130, %r2129, 2;
	not.b32 	%r2131, %r2130;
	and.b32  	%r2132, %r2128, %r2131;
	and.b32  	%r2133, %r17, 522133279;
	add.s32 	%r2134, %r2133, 522133279;
	sub.s32 	%r2135, %r2062, %r2133;
	and.b32  	%r2136, %r2132, %r2135;
	and.b32  	%r2137, %r2136, %r2134;
	or.b32  	%r2138, %r2137, %r17;
	and.b32  	%r2139, %r18, 1077952576;
	shr.u32 	%r2140, %r2139, 1;
	and.b32  	%r2141, %r18, -2139062144;
	shr.u32 	%r2142, %r2141, 2;
	not.b32 	%r2143, %r2142;
	and.b32  	%r2144, %r2140, %r2143;
	and.b32  	%r2145, %r18, 522133279;
	add.s32 	%r2146, %r2145, 522133279;
	sub.s32 	%r2147, %r2062, %r2145;
	and.b32  	%r2148, %r2144, %r2147;
	and.b32  	%r2149, %r2148, %r2146;
	or.b32  	%r2150, %r2149, %r18;
	mov.b32	{%rs170, %rs171}, %r2066;
	shr.u16 	%rs172, %rs171, 8;
	cvt.u16.u32	%rs173, %r23;
	and.b16  	%rs174, %rs173, 255;
	setp.eq.s16	%p92, %rs172, %rs174;
	and.b16  	%rs175, %rs171, 255;
	setp.eq.s16	%p93, %rs175, %rs174;
	shr.u16 	%rs176, %rs170, 8;
	setp.eq.s16	%p94, %rs176, %rs174;
	and.b16  	%rs177, %rs170, 255;
	setp.eq.s16	%p95, %rs177, %rs174;
	selp.b16	%rs178, -1, 0, %p95;
	selp.b16	%rs179, -1, 0, %p94;
	selp.b16	%rs180, -1, 0, %p93;
	selp.b16	%rs181, -1, 0, %p92;
	shl.b16 	%rs182, %rs181, 1;
	and.b16  	%rs183, %rs182, -256;
	shr.u16 	%rs184, %rs180, 7;
	and.b16  	%rs185, %rs184, 255;
	or.b16  	%rs186, %rs185, %rs183;
	shl.b16 	%rs187, %rs179, 1;
	and.b16  	%rs188, %rs187, -256;
	shr.u16 	%rs189, %rs178, 7;
	and.b16  	%rs190, %rs189, 255;
	or.b16  	%rs191, %rs190, %rs188;
	mov.b32	%r2052, {%rs191, %rs186};
	mov.b32	{%rs192, %rs193}, %r2078;
	shr.u16 	%rs194, %rs193, 8;
	setp.eq.s16	%p96, %rs194, %rs174;
	and.b16  	%rs195, %rs193, 255;
	setp.eq.s16	%p97, %rs195, %rs174;
	shr.u16 	%rs196, %rs192, 8;
	setp.eq.s16	%p98, %rs196, %rs174;
	and.b16  	%rs197, %rs192, 255;
	setp.eq.s16	%p99, %rs197, %rs174;
	selp.b16	%rs198, -1, 0, %p99;
	selp.b16	%rs199, -1, 0, %p98;
	selp.b16	%rs200, -1, 0, %p97;
	selp.b16	%rs201, -1, 0, %p96;
	shl.b16 	%rs202, %rs201, 1;
	and.b16  	%rs203, %rs202, -256;
	shr.u16 	%rs204, %rs200, 7;
	and.b16  	%rs205, %rs204, 255;
	or.b16  	%rs206, %rs205, %rs203;
	shl.b16 	%rs207, %rs199, 1;
	and.b16  	%rs208, %rs207, -256;
	shr.u16 	%rs209, %rs198, 7;
	and.b16  	%rs210, %rs209, 255;
	or.b16  	%rs211, %rs210, %rs208;
	mov.b32	%r2048, {%rs211, %rs206};
	mov.b32	{%rs212, %rs213}, %r2090;
	shr.u16 	%rs214, %rs213, 8;
	setp.eq.s16	%p100, %rs214, %rs174;
	and.b16  	%rs215, %rs213, 255;
	setp.eq.s16	%p101, %rs215, %rs174;
	shr.u16 	%rs216, %rs212, 8;
	setp.eq.s16	%p102, %rs216, %rs174;
	and.b16  	%rs217, %rs212, 255;
	setp.eq.s16	%p103, %rs217, %rs174;
	selp.b16	%rs218, -1, 0, %p103;
	selp.b16	%rs219, -1, 0, %p102;
	selp.b16	%rs220, -1, 0, %p101;
	selp.b16	%rs221, -1, 0, %p100;
	shl.b16 	%rs222, %rs221, 1;
	and.b16  	%rs223, %rs222, -256;
	shr.u16 	%rs224, %rs220, 7;
	and.b16  	%rs225, %rs224, 255;
	or.b16  	%rs226, %rs225, %rs223;
	shl.b16 	%rs227, %rs219, 1;
	and.b16  	%rs228, %rs227, -256;
	shr.u16 	%rs229, %rs218, 7;
	and.b16  	%rs230, %rs229, 255;
	or.b16  	%rs231, %rs230, %rs228;
	mov.b32	%r2044, {%rs231, %rs226};
	mov.b32	{%rs232, %rs233}, %r2102;
	shr.u16 	%rs234, %rs233, 8;
	setp.eq.s16	%p104, %rs234, %rs174;
	and.b16  	%rs235, %rs233, 255;
	setp.eq.s16	%p105, %rs235, %rs174;
	shr.u16 	%rs236, %rs232, 8;
	setp.eq.s16	%p106, %rs236, %rs174;
	and.b16  	%rs237, %rs232, 255;
	setp.eq.s16	%p107, %rs237, %rs174;
	selp.b16	%rs238, -1, 0, %p107;
	selp.b16	%rs239, -1, 0, %p106;
	selp.b16	%rs240, -1, 0, %p105;
	selp.b16	%rs241, -1, 0, %p104;
	shl.b16 	%rs242, %rs241, 1;
	and.b16  	%rs243, %rs242, -256;
	shr.u16 	%rs244, %rs240, 7;
	and.b16  	%rs245, %rs244, 255;
	or.b16  	%rs246, %rs245, %rs243;
	shl.b16 	%rs247, %rs239, 1;
	and.b16  	%rs248, %rs247, -256;
	shr.u16 	%rs249, %rs238, 7;
	and.b16  	%rs250, %rs249, 255;
	or.b16  	%rs251, %rs250, %rs248;
	mov.b32	%r2040, {%rs251, %rs246};
	mov.b32	{%rs252, %rs253}, %r2114;
	shr.u16 	%rs254, %rs253, 8;
	setp.eq.s16	%p108, %rs254, %rs174;
	and.b16  	%rs255, %rs253, 255;
	setp.eq.s16	%p109, %rs255, %rs174;
	shr.u16 	%rs256, %rs252, 8;
	setp.eq.s16	%p110, %rs256, %rs174;
	and.b16  	%rs257, %rs252, 255;
	setp.eq.s16	%p111, %rs257, %rs174;
	selp.b16	%rs258, -1, 0, %p111;
	selp.b16	%rs259, -1, 0, %p110;
	selp.b16	%rs260, -1, 0, %p109;
	selp.b16	%rs261, -1, 0, %p108;
	shl.b16 	%rs262, %rs261, 1;
	and.b16  	%rs263, %rs262, -256;
	shr.u16 	%rs264, %rs260, 7;
	and.b16  	%rs265, %rs264, 255;
	or.b16  	%rs266, %rs265, %rs263;
	shl.b16 	%rs267, %rs259, 1;
	and.b16  	%rs268, %rs267, -256;
	shr.u16 	%rs269, %rs258, 7;
	and.b16  	%rs270, %rs269, 255;
	or.b16  	%rs271, %rs270, %rs268;
	mov.b32	%r2036, {%rs271, %rs266};
	mov.b32	{%rs272, %rs273}, %r2126;
	shr.u16 	%rs274, %rs273, 8;
	setp.eq.s16	%p112, %rs274, %rs174;
	and.b16  	%rs275, %rs273, 255;
	setp.eq.s16	%p113, %rs275, %rs174;
	shr.u16 	%rs276, %rs272, 8;
	setp.eq.s16	%p114, %rs276, %rs174;
	and.b16  	%rs277, %rs272, 255;
	setp.eq.s16	%p115, %rs277, %rs174;
	selp.b16	%rs278, -1, 0, %p115;
	selp.b16	%rs279, -1, 0, %p114;
	selp.b16	%rs280, -1, 0, %p113;
	selp.b16	%rs281, -1, 0, %p112;
	shl.b16 	%rs282, %rs281, 1;
	and.b16  	%rs283, %rs282, -256;
	shr.u16 	%rs284, %rs280, 7;
	and.b16  	%rs285, %rs284, 255;
	or.b16  	%rs286, %rs285, %rs283;
	shl.b16 	%rs287, %rs279, 1;
	and.b16  	%rs288, %rs287, -256;
	shr.u16 	%rs289, %rs278, 7;
	and.b16  	%rs290, %rs289, 255;
	or.b16  	%rs291, %rs290, %rs288;
	mov.b32	%r2032, {%rs291, %rs286};
	mov.b32	{%rs292, %rs293}, %r2138;
	shr.u16 	%rs294, %rs293, 8;
	setp.eq.s16	%p116, %rs294, %rs174;
	and.b16  	%rs295, %rs293, 255;
	setp.eq.s16	%p117, %rs295, %rs174;
	shr.u16 	%rs296, %rs292, 8;
	setp.eq.s16	%p118, %rs296, %rs174;
	and.b16  	%rs297, %rs292, 255;
	setp.eq.s16	%p119, %rs297, %rs174;
	selp.b16	%rs298, -1, 0, %p119;
	selp.b16	%rs299, -1, 0, %p118;
	selp.b16	%rs300, -1, 0, %p117;
	selp.b16	%rs301, -1, 0, %p116;
	shl.b16 	%rs302, %rs301, 1;
	and.b16  	%rs303, %rs302, -256;
	shr.u16 	%rs304, %rs300, 7;
	and.b16  	%rs305, %rs304, 255;
	or.b16  	%rs306, %rs305, %rs303;
	shl.b16 	%rs307, %rs299, 1;
	and.b16  	%rs308, %rs307, -256;
	shr.u16 	%rs309, %rs298, 7;
	and.b16  	%rs310, %rs309, 255;
	or.b16  	%rs311, %rs310, %rs308;
	mov.b32	%r2028, {%rs311, %rs306};
	mov.b32	{%rs312, %rs313}, %r2150;
	shr.u16 	%rs314, %rs313, 8;
	setp.eq.s16	%p120, %rs314, %rs174;
	and.b16  	%rs315, %rs313, 255;
	setp.eq.s16	%p121, %rs315, %rs174;
	shr.u16 	%rs316, %rs312, 8;
	setp.eq.s16	%p122, %rs316, %rs174;
	and.b16  	%rs317, %rs312, 255;
	setp.eq.s16	%p123, %rs317, %rs174;
	selp.b16	%rs318, -1, 0, %p123;
	selp.b16	%rs319, -1, 0, %p122;
	selp.b16	%rs320, -1, 0, %p121;
	selp.b16	%rs321, -1, 0, %p120;
	shl.b16 	%rs322, %rs321, 1;
	and.b16  	%rs323, %rs322, -256;
	shr.u16 	%rs324, %rs320, 7;
	and.b16  	%rs325, %rs324, 255;
	or.b16  	%rs326, %rs325, %rs323;
	shl.b16 	%rs327, %rs319, 1;
	and.b16  	%rs328, %rs327, -256;
	shr.u16 	%rs329, %rs318, 7;
	and.b16  	%rs330, %rs329, 255;
	or.b16  	%rs331, %rs330, %rs328;
	mov.b32	%r2024, {%rs331, %rs326};
	mov.u32 	%r2053, 24;
	// inline asm
	shf.r.wrap.b32 %r2022, %r2028, %r2024, %r2053;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2026, %r2032, %r2028, %r2053;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2030, %r2036, %r2032, %r2053;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2034, %r2040, %r2036, %r2053;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2038, %r2044, %r2040, %r2053;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2042, %r2048, %r2044, %r2053;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2046, %r2052, %r2048, %r2053;
	// inline asm
	mov.u32 	%r2051, 0;
	// inline asm
	shf.r.wrap.b32 %r2050, %r2051, %r2052, %r2053;
	// inline asm
	or.b32  	%r2151, %r2050, 255;
	and.b32  	%r2152, %r2066, 1077952576;
	shr.u32 	%r2153, %r2152, 1;
	and.b32  	%r2154, %r2066, -2139062144;
	shr.u32 	%r2155, %r2154, 2;
	not.b32 	%r2156, %r2155;
	and.b32  	%r2157, %r2153, %r2156;
	and.b32  	%r2158, %r2066, 522133279;
	add.s32 	%r2159, %r2158, 522133279;
	sub.s32 	%r2160, %r2062, %r2158;
	and.b32  	%r2161, %r2157, %r2160;
	and.b32  	%r2162, %r2161, %r2159;
	and.b32  	%r2163, %r2162, %r2151;
	not.b32 	%r2164, %r2163;
	and.b32  	%r8848, %r2066, %r2164;
	and.b32  	%r2165, %r2078, 1077952576;
	shr.u32 	%r2166, %r2165, 1;
	and.b32  	%r2167, %r2078, -2139062144;
	shr.u32 	%r2168, %r2167, 2;
	not.b32 	%r2169, %r2168;
	and.b32  	%r2170, %r2166, %r2169;
	and.b32  	%r2171, %r2078, 522133279;
	add.s32 	%r2172, %r2171, 522133279;
	sub.s32 	%r2173, %r2062, %r2171;
	and.b32  	%r2174, %r2170, %r2173;
	and.b32  	%r2175, %r2174, %r2172;
	and.b32  	%r2176, %r2175, %r2046;
	not.b32 	%r2177, %r2176;
	and.b32  	%r8847, %r2078, %r2177;
	and.b32  	%r2178, %r2090, 1077952576;
	shr.u32 	%r2179, %r2178, 1;
	and.b32  	%r2180, %r2090, -2139062144;
	shr.u32 	%r2181, %r2180, 2;
	not.b32 	%r2182, %r2181;
	and.b32  	%r2183, %r2179, %r2182;
	and.b32  	%r2184, %r2090, 522133279;
	add.s32 	%r2185, %r2184, 522133279;
	sub.s32 	%r2186, %r2062, %r2184;
	and.b32  	%r2187, %r2183, %r2186;
	and.b32  	%r2188, %r2187, %r2185;
	and.b32  	%r2189, %r2188, %r2042;
	not.b32 	%r2190, %r2189;
	and.b32  	%r8846, %r2090, %r2190;
	and.b32  	%r2191, %r2102, 1077952576;
	shr.u32 	%r2192, %r2191, 1;
	and.b32  	%r2193, %r2102, -2139062144;
	shr.u32 	%r2194, %r2193, 2;
	not.b32 	%r2195, %r2194;
	and.b32  	%r2196, %r2192, %r2195;
	and.b32  	%r2197, %r2102, 522133279;
	add.s32 	%r2198, %r2197, 522133279;
	sub.s32 	%r2199, %r2062, %r2197;
	and.b32  	%r2200, %r2196, %r2199;
	and.b32  	%r2201, %r2200, %r2198;
	and.b32  	%r2202, %r2201, %r2038;
	not.b32 	%r2203, %r2202;
	and.b32  	%r8845, %r2102, %r2203;
	and.b32  	%r2204, %r2114, 1077952576;
	shr.u32 	%r2205, %r2204, 1;
	and.b32  	%r2206, %r2114, -2139062144;
	shr.u32 	%r2207, %r2206, 2;
	not.b32 	%r2208, %r2207;
	and.b32  	%r2209, %r2205, %r2208;
	and.b32  	%r2210, %r2114, 522133279;
	add.s32 	%r2211, %r2210, 522133279;
	sub.s32 	%r2212, %r2062, %r2210;
	and.b32  	%r2213, %r2209, %r2212;
	and.b32  	%r2214, %r2213, %r2211;
	and.b32  	%r2215, %r2214, %r2034;
	not.b32 	%r2216, %r2215;
	and.b32  	%r8852, %r2114, %r2216;
	and.b32  	%r2217, %r2126, 1077952576;
	shr.u32 	%r2218, %r2217, 1;
	and.b32  	%r2219, %r2126, -2139062144;
	shr.u32 	%r2220, %r2219, 2;
	not.b32 	%r2221, %r2220;
	and.b32  	%r2222, %r2218, %r2221;
	and.b32  	%r2223, %r2126, 522133279;
	add.s32 	%r2224, %r2223, 522133279;
	sub.s32 	%r2225, %r2062, %r2223;
	and.b32  	%r2226, %r2222, %r2225;
	and.b32  	%r2227, %r2226, %r2224;
	and.b32  	%r2228, %r2227, %r2030;
	not.b32 	%r2229, %r2228;
	and.b32  	%r8851, %r2126, %r2229;
	and.b32  	%r2230, %r2138, 1077952576;
	shr.u32 	%r2231, %r2230, 1;
	and.b32  	%r2232, %r2138, -2139062144;
	shr.u32 	%r2233, %r2232, 2;
	not.b32 	%r2234, %r2233;
	and.b32  	%r2235, %r2231, %r2234;
	and.b32  	%r2236, %r2138, 522133279;
	add.s32 	%r2237, %r2236, 522133279;
	sub.s32 	%r2238, %r2062, %r2236;
	and.b32  	%r2239, %r2235, %r2238;
	and.b32  	%r2240, %r2239, %r2237;
	and.b32  	%r2241, %r2240, %r2026;
	not.b32 	%r2242, %r2241;
	and.b32  	%r8850, %r2138, %r2242;
	and.b32  	%r2243, %r2150, 1077952576;
	shr.u32 	%r2244, %r2243, 1;
	and.b32  	%r2245, %r2150, -2139062144;
	shr.u32 	%r2246, %r2245, 2;
	not.b32 	%r2247, %r2246;
	and.b32  	%r2248, %r2244, %r2247;
	and.b32  	%r2249, %r2150, 522133279;
	add.s32 	%r2250, %r2249, 522133279;
	sub.s32 	%r2251, %r2062, %r2249;
	and.b32  	%r2252, %r2248, %r2251;
	and.b32  	%r2253, %r2252, %r2250;
	and.b32  	%r2254, %r2253, %r2022;
	not.b32 	%r2255, %r2254;
	and.b32  	%r8849, %r2150, %r2255;
	mov.u32 	%r8853, %r14;
	bra.uni 	BB0_1554;

BB0_50:
	setp.eq.s32	%p42, %r1787, 76;
	@%p42 bra 	BB0_428;

	setp.eq.s32	%p43, %r1787, 79;
	@%p43 bra 	BB0_1052;
	bra.uni 	BB0_52;

BB0_1052:
	setp.ge.u32	%p707, %r24, %r14;
	add.s32 	%r4935, %r24, %r26;
	setp.gt.u32	%p708, %r4935, %r14;
	or.pred  	%p709, %p707, %p708;
	@%p709 bra 	BB0_978;

	mov.u32 	%r8849, 0;
	setp.gt.s32	%p710, %r26, 15;
	@%p710 bra 	BB0_1086;

	setp.gt.s32	%p734, %r26, 7;
	@%p734 bra 	BB0_1070;

	setp.gt.s32	%p746, %r26, 3;
	@%p746 bra 	BB0_1063;

	setp.gt.s32	%p752, %r26, 1;
	@%p752 bra 	BB0_1060;

	setp.eq.s32	%p755, %r26, 0;
	@%p755 bra 	BB0_1136;
	bra.uni 	BB0_1058;

BB0_1136:
	mov.u32 	%r8845, %r22;
	mov.u32 	%r8846, %r21;
	mov.u32 	%r8847, %r20;
	mov.u32 	%r8766, %r19;
	mov.u32 	%r8849, %r18;
	mov.u32 	%r8850, %r17;
	mov.u32 	%r8851, %r16;
	mov.u32 	%r8852, %r15;
	bra.uni 	BB0_1137;

BB0_112:
	setp.eq.s32	%p15, %r1787, 115;
	@%p15 bra 	BB0_976;

	setp.eq.s32	%p16, %r1787, 116;
	@%p16 bra 	BB0_1550;
	bra.uni 	BB0_114;

BB0_1550:
	and.b32  	%r8169, %r19, 1077952576;
	shr.u32 	%r8170, %r8169, 1;
	and.b32  	%r8171, %r19, -2139062144;
	shr.u32 	%r8172, %r8171, 2;
	not.b32 	%r8173, %r8172;
	and.b32  	%r8174, %r8170, %r8173;
	and.b32  	%r8175, %r19, 522133279;
	add.s32 	%r8176, %r8175, 522133279;
	mov.u32 	%r8177, -84215046;
	sub.s32 	%r8178, %r8177, %r8175;
	and.b32  	%r8179, %r8174, %r8178;
	and.b32  	%r8180, %r8179, %r8176;
	xor.b32  	%r8848, %r8180, %r19;
	and.b32  	%r8181, %r20, 1077952576;
	shr.u32 	%r8182, %r8181, 1;
	and.b32  	%r8183, %r20, -2139062144;
	shr.u32 	%r8184, %r8183, 2;
	not.b32 	%r8185, %r8184;
	and.b32  	%r8186, %r8182, %r8185;
	and.b32  	%r8187, %r20, 522133279;
	add.s32 	%r8188, %r8187, 522133279;
	sub.s32 	%r8189, %r8177, %r8187;
	and.b32  	%r8190, %r8186, %r8189;
	and.b32  	%r8191, %r8190, %r8188;
	xor.b32  	%r8847, %r8191, %r20;
	and.b32  	%r8192, %r21, 1077952576;
	shr.u32 	%r8193, %r8192, 1;
	and.b32  	%r8194, %r21, -2139062144;
	shr.u32 	%r8195, %r8194, 2;
	not.b32 	%r8196, %r8195;
	and.b32  	%r8197, %r8193, %r8196;
	and.b32  	%r8198, %r21, 522133279;
	add.s32 	%r8199, %r8198, 522133279;
	sub.s32 	%r8200, %r8177, %r8198;
	and.b32  	%r8201, %r8197, %r8200;
	and.b32  	%r8202, %r8201, %r8199;
	xor.b32  	%r8846, %r8202, %r21;
	and.b32  	%r8203, %r22, 1077952576;
	shr.u32 	%r8204, %r8203, 1;
	and.b32  	%r8205, %r22, -2139062144;
	shr.u32 	%r8206, %r8205, 2;
	not.b32 	%r8207, %r8206;
	and.b32  	%r8208, %r8204, %r8207;
	and.b32  	%r8209, %r22, 522133279;
	add.s32 	%r8210, %r8209, 522133279;
	sub.s32 	%r8211, %r8177, %r8209;
	and.b32  	%r8212, %r8208, %r8211;
	and.b32  	%r8213, %r8212, %r8210;
	xor.b32  	%r8845, %r8213, %r22;
	and.b32  	%r8214, %r15, 1077952576;
	shr.u32 	%r8215, %r8214, 1;
	and.b32  	%r8216, %r15, -2139062144;
	shr.u32 	%r8217, %r8216, 2;
	not.b32 	%r8218, %r8217;
	and.b32  	%r8219, %r8215, %r8218;
	and.b32  	%r8220, %r15, 522133279;
	add.s32 	%r8221, %r8220, 522133279;
	sub.s32 	%r8222, %r8177, %r8220;
	and.b32  	%r8223, %r8219, %r8222;
	and.b32  	%r8224, %r8223, %r8221;
	xor.b32  	%r8852, %r8224, %r15;
	and.b32  	%r8225, %r16, 1077952576;
	shr.u32 	%r8226, %r8225, 1;
	and.b32  	%r8227, %r16, -2139062144;
	shr.u32 	%r8228, %r8227, 2;
	not.b32 	%r8229, %r8228;
	and.b32  	%r8230, %r8226, %r8229;
	and.b32  	%r8231, %r16, 522133279;
	add.s32 	%r8232, %r8231, 522133279;
	sub.s32 	%r8233, %r8177, %r8231;
	and.b32  	%r8234, %r8230, %r8233;
	and.b32  	%r8235, %r8234, %r8232;
	xor.b32  	%r8851, %r8235, %r16;
	and.b32  	%r8236, %r17, 1077952576;
	shr.u32 	%r8237, %r8236, 1;
	and.b32  	%r8238, %r17, -2139062144;
	shr.u32 	%r8239, %r8238, 2;
	not.b32 	%r8240, %r8239;
	and.b32  	%r8241, %r8237, %r8240;
	and.b32  	%r8242, %r17, 522133279;
	add.s32 	%r8243, %r8242, 522133279;
	sub.s32 	%r8244, %r8177, %r8242;
	and.b32  	%r8245, %r8241, %r8244;
	and.b32  	%r8246, %r8245, %r8243;
	xor.b32  	%r8850, %r8246, %r17;
	and.b32  	%r8247, %r18, 1077952576;
	shr.u32 	%r8248, %r8247, 1;
	and.b32  	%r8249, %r18, -2139062144;
	shr.u32 	%r8250, %r8249, 2;
	not.b32 	%r8251, %r8250;
	and.b32  	%r8252, %r8248, %r8251;
	and.b32  	%r8253, %r18, 522133279;
	add.s32 	%r8254, %r8253, 522133279;
	sub.s32 	%r8255, %r8177, %r8253;
	and.b32  	%r8256, %r8252, %r8255;
	and.b32  	%r8257, %r8256, %r8254;
	xor.b32  	%r8849, %r8257, %r18;
	bra.uni 	BB0_1553;

BB0_31:
	setp.eq.s32	%p49, %r1787, 64;
	@%p49 bra 	BB0_951;

	setp.eq.s32	%p50, %r1787, 67;
	@%p50 bra 	BB0_1551;
	bra.uni 	BB0_33;

BB0_1551:
	and.b32  	%r8258, %r19, 1077952576;
	shr.u32 	%r8259, %r8258, 1;
	and.b32  	%r8260, %r19, -2139062144;
	shr.u32 	%r8261, %r8260, 2;
	not.b32 	%r8262, %r8261;
	and.b32  	%r8263, %r8259, %r8262;
	and.b32  	%r8264, %r19, 522133279;
	add.s32 	%r8265, %r8264, 522133279;
	mov.u32 	%r8266, -84215046;
	sub.s32 	%r8267, %r8266, %r8264;
	and.b32  	%r8268, %r8263, %r8267;
	and.b32  	%r8269, %r8268, %r8265;
	not.b32 	%r8270, %r8269;
	and.b32  	%r8271, %r20, 1077952576;
	shr.u32 	%r8272, %r8271, 1;
	and.b32  	%r8273, %r20, -2139062144;
	shr.u32 	%r8274, %r8273, 2;
	not.b32 	%r8275, %r8274;
	and.b32  	%r8276, %r8272, %r8275;
	and.b32  	%r8277, %r20, 522133279;
	add.s32 	%r8278, %r8277, 522133279;
	sub.s32 	%r8279, %r8266, %r8277;
	and.b32  	%r8280, %r8276, %r8279;
	and.b32  	%r8281, %r8280, %r8278;
	not.b32 	%r8282, %r8281;
	and.b32  	%r8847, %r20, %r8282;
	and.b32  	%r8283, %r21, 1077952576;
	shr.u32 	%r8284, %r8283, 1;
	and.b32  	%r8285, %r21, -2139062144;
	shr.u32 	%r8286, %r8285, 2;
	not.b32 	%r8287, %r8286;
	and.b32  	%r8288, %r8284, %r8287;
	and.b32  	%r8289, %r21, 522133279;
	add.s32 	%r8290, %r8289, 522133279;
	sub.s32 	%r8291, %r8266, %r8289;
	and.b32  	%r8292, %r8288, %r8291;
	and.b32  	%r8293, %r8292, %r8290;
	not.b32 	%r8294, %r8293;
	and.b32  	%r8846, %r21, %r8294;
	and.b32  	%r8295, %r22, 1077952576;
	shr.u32 	%r8296, %r8295, 1;
	and.b32  	%r8297, %r22, -2139062144;
	shr.u32 	%r8298, %r8297, 2;
	not.b32 	%r8299, %r8298;
	and.b32  	%r8300, %r8296, %r8299;
	and.b32  	%r8301, %r22, 522133279;
	add.s32 	%r8302, %r8301, 522133279;
	sub.s32 	%r8303, %r8266, %r8301;
	and.b32  	%r8304, %r8300, %r8303;
	and.b32  	%r8305, %r8304, %r8302;
	not.b32 	%r8306, %r8305;
	and.b32  	%r8845, %r22, %r8306;
	and.b32  	%r8307, %r15, 1077952576;
	shr.u32 	%r8308, %r8307, 1;
	and.b32  	%r8309, %r15, -2139062144;
	shr.u32 	%r8310, %r8309, 2;
	not.b32 	%r8311, %r8310;
	and.b32  	%r8312, %r8308, %r8311;
	and.b32  	%r8313, %r15, 522133279;
	add.s32 	%r8314, %r8313, 522133279;
	sub.s32 	%r8315, %r8266, %r8313;
	and.b32  	%r8316, %r8312, %r8315;
	and.b32  	%r8317, %r8316, %r8314;
	not.b32 	%r8318, %r8317;
	and.b32  	%r8852, %r15, %r8318;
	and.b32  	%r8319, %r16, 1077952576;
	shr.u32 	%r8320, %r8319, 1;
	and.b32  	%r8321, %r16, -2139062144;
	shr.u32 	%r8322, %r8321, 2;
	not.b32 	%r8323, %r8322;
	and.b32  	%r8324, %r8320, %r8323;
	and.b32  	%r8325, %r16, 522133279;
	add.s32 	%r8326, %r8325, 522133279;
	sub.s32 	%r8327, %r8266, %r8325;
	and.b32  	%r8328, %r8324, %r8327;
	and.b32  	%r8329, %r8328, %r8326;
	not.b32 	%r8330, %r8329;
	and.b32  	%r8851, %r16, %r8330;
	and.b32  	%r8331, %r17, 1077952576;
	shr.u32 	%r8332, %r8331, 1;
	and.b32  	%r8333, %r17, -2139062144;
	shr.u32 	%r8334, %r8333, 2;
	not.b32 	%r8335, %r8334;
	and.b32  	%r8336, %r8332, %r8335;
	and.b32  	%r8337, %r17, 522133279;
	add.s32 	%r8338, %r8337, 522133279;
	sub.s32 	%r8339, %r8266, %r8337;
	and.b32  	%r8340, %r8336, %r8339;
	and.b32  	%r8341, %r8340, %r8338;
	not.b32 	%r8342, %r8341;
	and.b32  	%r8850, %r17, %r8342;
	and.b32  	%r8343, %r18, 1077952576;
	shr.u32 	%r8344, %r8343, 1;
	and.b32  	%r8345, %r18, -2139062144;
	shr.u32 	%r8346, %r8345, 2;
	not.b32 	%r8347, %r8346;
	and.b32  	%r8348, %r8344, %r8347;
	and.b32  	%r8349, %r18, 522133279;
	add.s32 	%r8350, %r8349, 522133279;
	sub.s32 	%r8351, %r8266, %r8349;
	and.b32  	%r8352, %r8348, %r8351;
	and.b32  	%r8353, %r8352, %r8350;
	not.b32 	%r8354, %r8353;
	and.b32  	%r8849, %r18, %r8354;
	and.b32  	%r8355, %r19, %r8270;
	and.b32  	%r8356, %r8355, 64;
	shr.u32 	%r8357, %r8356, 1;
	shr.u32 	%r8358, %r8355, 2;
	and.b32  	%r8359, %r8355, 522133279;
	add.s32 	%r8360, %r8359, 31;
	sub.s32 	%r8361, %r8266, %r8359;
	not.b32 	%r8362, %r8358;
	and.b32  	%r8363, %r8362, %r8357;
	and.b32  	%r8364, %r8363, %r8361;
	and.b32  	%r8365, %r8364, %r8360;
	or.b32  	%r8848, %r8365, %r8355;
	bra.uni 	BB0_1553;

BB0_94:
	setp.eq.s32	%p22, %r1787, 108;
	@%p22 bra 	BB0_1552;

	setp.eq.s32	%p23, %r1787, 111;
	@%p23 bra 	BB0_1003;
	bra.uni 	BB0_96;

BB0_1003:
	setp.ge.u32	%p681, %r24, %r14;
	@%p681 bra 	BB0_978;

	and.b32  	%r4861, %r23, 3;
	shl.b32 	%r4862, %r4861, 3;
	shl.b32 	%r913, %r26, %r4862;
	mov.u32 	%r4863, 255;
	shl.b32 	%r4864, %r4863, %r4862;
	not.b32 	%r914, %r4864;
	shr.u32 	%r4860, %r24, 2;
	setp.gt.s32	%p682, %r4860, 3;
	@%p682 bra 	BB0_1013;

	setp.gt.s32	%p688, %r4860, 1;
	@%p688 bra 	BB0_1010;

	setp.eq.s32	%p691, %r4860, 0;
	@%p691 bra 	BB0_1027;
	bra.uni 	BB0_1007;

BB0_1027:
	and.b32  	%r4872, %r19, %r914;
	or.b32  	%r8848, %r4872, %r913;

BB0_1028:
	mov.u32 	%r8845, %r22;
	mov.u32 	%r8846, %r21;
	mov.u32 	%r8847, %r20;
	bra.uni 	BB0_15;

BB0_68:
	setp.eq.s32	%p36, %r1787, 90;
	@%p36 bra 	BB0_785;

	setp.eq.s32	%p37, %r1787, 91;
	@%p37 bra 	BB0_1290;
	bra.uni 	BB0_70;

BB0_1290:
	setp.eq.s32	%p848, %r14, 0;
	mov.u32 	%r8853, 0;
	@%p848 bra 	BB0_1034;

	add.s32 	%r8853, %r14, -1;
	mov.u32 	%r6187, 8;
	// inline asm
	shf.r.wrap.b32 %r8848, %r19, %r20, %r6187;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8847, %r20, %r21, %r6187;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8846, %r21, %r22, %r6187;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8845, %r22, %r15, %r6187;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8852, %r15, %r16, %r6187;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8851, %r16, %r17, %r6187;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8850, %r17, %r18, %r6187;
	// inline asm
	mov.u32 	%r6186, 0;
	// inline asm
	shf.r.wrap.b32 %r8849, %r18, %r6186, %r6187;
	// inline asm
	bra.uni 	BB0_1554;

BB0_124:
	setp.eq.s32	%p9, %r1787, 122;
	@%p9 bra 	BB0_788;

	setp.eq.s32	%p10, %r1787, 123;
	@%p10 bra 	BB0_1308;
	bra.uni 	BB0_126;

BB0_1308:
	setp.eq.s32	%p869, %r14, 0;
	mov.u32 	%r8853, 0;
	@%p869 bra 	BB0_1034;

	add.s32 	%r6308, %r14, -1;
	and.b32  	%r6309, %r6308, 3;
	shl.b32 	%r6310, %r6309, 3;
	and.b32  	%r6311, %r19, 255;
	shl.b32 	%r6312, %r6311, %r6310;
	mov.u32 	%r6307, 8;
	// inline asm
	shf.r.wrap.b32 %r6276, %r19, %r20, %r6307;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6280, %r20, %r21, %r6307;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6284, %r21, %r22, %r6307;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6288, %r22, %r15, %r6307;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6292, %r15, %r16, %r6307;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6296, %r16, %r17, %r6307;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6300, %r17, %r18, %r6307;
	// inline asm
	mov.u32 	%r6306, 0;
	// inline asm
	shf.r.wrap.b32 %r6304, %r18, %r6306, %r6307;
	// inline asm
	setp.lt.u32	%p870, %r6308, 4;
	selp.b32	%r6313, %r6312, 0, %p870;
	or.b32  	%r8848, %r6276, %r6313;
	and.b32  	%r6314, %r6308, -4;
	setp.eq.s32	%p871, %r6314, 4;
	selp.b32	%r6315, %r6312, 0, %p871;
	or.b32  	%r8847, %r6280, %r6315;
	setp.eq.s32	%p872, %r6314, 8;
	selp.b32	%r6316, %r6312, 0, %p872;
	or.b32  	%r8846, %r6284, %r6316;
	setp.eq.s32	%p873, %r6314, 12;
	selp.b32	%r6317, %r6312, 0, %p873;
	or.b32  	%r8845, %r6288, %r6317;
	setp.eq.s32	%p874, %r6314, 16;
	selp.b32	%r6318, %r6312, 0, %p874;
	or.b32  	%r8852, %r6292, %r6318;
	setp.eq.s32	%p875, %r6314, 20;
	selp.b32	%r6319, %r6312, 0, %p875;
	or.b32  	%r8851, %r6296, %r6319;
	setp.eq.s32	%p876, %r6314, 24;
	selp.b32	%r6320, %r6312, 0, %p876;
	or.b32  	%r8850, %r6300, %r6320;
	setp.gt.u32	%p877, %r6308, 27;
	selp.b32	%r6321, %r6312, 0, %p877;
	or.b32  	%r8849, %r6304, %r6321;
	bra.uni 	BB0_1553;

BB0_10:
	setp.eq.s32	%p59, %r1787, 39;
	@%p59 bra 	BB0_977;
	bra.uni 	BB0_11;

BB0_977:
	setp.ge.u32	%p669, %r24, %r14;
	@%p669 bra 	BB0_978;

	and.b32  	%r4828, %r23, 3;
	shl.b32 	%r4829, %r4828, 3;
	mov.u32 	%r4830, 1;
	shl.b32 	%r4831, %r4830, %r4829;
	add.s32 	%r904, %r4831, -1;
	shr.u32 	%r4827, %r24, 2;
	setp.gt.s32	%p670, %r4827, 3;
	@%p670 bra 	BB0_987;

	setp.gt.s32	%p676, %r4827, 1;
	@%p676 bra 	BB0_984;

	setp.eq.s32	%p679, %r4827, 0;
	@%p679 bra 	BB0_1002;
	bra.uni 	BB0_982;

BB0_1002:
	and.b32  	%r8848, %r904, %r19;
	mov.u32 	%r8845, 0;
	mov.u32 	%r8846, %r8845;
	mov.u32 	%r8847, %r8845;
	bra.uni 	BB0_1000;

BB0_77:
	setp.eq.s32	%p32, %r1787, 99;
	@%p32 bra 	BB0_78;
	bra.uni 	BB0_11;

BB0_78:
	and.b32  	%r8366, %r19, 1077952576;
	shr.u32 	%r8367, %r8366, 1;
	and.b32  	%r8368, %r19, -2139062144;
	shr.u32 	%r8369, %r8368, 2;
	not.b32 	%r8370, %r8369;
	and.b32  	%r8371, %r8367, %r8370;
	and.b32  	%r8372, %r19, 522133279;
	add.s32 	%r8373, %r8372, 522133279;
	mov.u32 	%r8374, -84215046;
	sub.s32 	%r8375, %r8374, %r8372;
	and.b32  	%r8376, %r8371, %r8375;
	and.b32  	%r8377, %r8376, %r8373;
	or.b32  	%r8378, %r8377, %r19;
	and.b32  	%r8379, %r20, 1077952576;
	shr.u32 	%r8380, %r8379, 1;
	and.b32  	%r8381, %r20, -2139062144;
	shr.u32 	%r8382, %r8381, 2;
	not.b32 	%r8383, %r8382;
	and.b32  	%r8384, %r8380, %r8383;
	and.b32  	%r8385, %r20, 522133279;
	add.s32 	%r8386, %r8385, 522133279;
	sub.s32 	%r8387, %r8374, %r8385;
	and.b32  	%r8388, %r8384, %r8387;
	and.b32  	%r8389, %r8388, %r8386;
	or.b32  	%r8847, %r8389, %r20;
	and.b32  	%r8390, %r21, 1077952576;
	shr.u32 	%r8391, %r8390, 1;
	and.b32  	%r8392, %r21, -2139062144;
	shr.u32 	%r8393, %r8392, 2;
	not.b32 	%r8394, %r8393;
	and.b32  	%r8395, %r8391, %r8394;
	and.b32  	%r8396, %r21, 522133279;
	add.s32 	%r8397, %r8396, 522133279;
	sub.s32 	%r8398, %r8374, %r8396;
	and.b32  	%r8399, %r8395, %r8398;
	and.b32  	%r8400, %r8399, %r8397;
	or.b32  	%r8846, %r8400, %r21;
	and.b32  	%r8401, %r22, 1077952576;
	shr.u32 	%r8402, %r8401, 1;
	and.b32  	%r8403, %r22, -2139062144;
	shr.u32 	%r8404, %r8403, 2;
	not.b32 	%r8405, %r8404;
	and.b32  	%r8406, %r8402, %r8405;
	and.b32  	%r8407, %r22, 522133279;
	add.s32 	%r8408, %r8407, 522133279;
	sub.s32 	%r8409, %r8374, %r8407;
	and.b32  	%r8410, %r8406, %r8409;
	and.b32  	%r8411, %r8410, %r8408;
	or.b32  	%r8845, %r8411, %r22;
	and.b32  	%r8412, %r15, 1077952576;
	shr.u32 	%r8413, %r8412, 1;
	and.b32  	%r8414, %r15, -2139062144;
	shr.u32 	%r8415, %r8414, 2;
	not.b32 	%r8416, %r8415;
	and.b32  	%r8417, %r8413, %r8416;
	and.b32  	%r8418, %r15, 522133279;
	add.s32 	%r8419, %r8418, 522133279;
	sub.s32 	%r8420, %r8374, %r8418;
	and.b32  	%r8421, %r8417, %r8420;
	and.b32  	%r8422, %r8421, %r8419;
	or.b32  	%r8852, %r8422, %r15;
	and.b32  	%r8423, %r16, 1077952576;
	shr.u32 	%r8424, %r8423, 1;
	and.b32  	%r8425, %r16, -2139062144;
	shr.u32 	%r8426, %r8425, 2;
	not.b32 	%r8427, %r8426;
	and.b32  	%r8428, %r8424, %r8427;
	and.b32  	%r8429, %r16, 522133279;
	add.s32 	%r8430, %r8429, 522133279;
	sub.s32 	%r8431, %r8374, %r8429;
	and.b32  	%r8432, %r8428, %r8431;
	and.b32  	%r8433, %r8432, %r8430;
	or.b32  	%r8851, %r8433, %r16;
	and.b32  	%r8434, %r17, 1077952576;
	shr.u32 	%r8435, %r8434, 1;
	and.b32  	%r8436, %r17, -2139062144;
	shr.u32 	%r8437, %r8436, 2;
	not.b32 	%r8438, %r8437;
	and.b32  	%r8439, %r8435, %r8438;
	and.b32  	%r8440, %r17, 522133279;
	add.s32 	%r8441, %r8440, 522133279;
	sub.s32 	%r8442, %r8374, %r8440;
	and.b32  	%r8443, %r8439, %r8442;
	and.b32  	%r8444, %r8443, %r8441;
	or.b32  	%r8850, %r8444, %r17;
	and.b32  	%r8445, %r18, 1077952576;
	shr.u32 	%r8446, %r8445, 1;
	and.b32  	%r8447, %r18, -2139062144;
	shr.u32 	%r8448, %r8447, 2;
	not.b32 	%r8449, %r8448;
	and.b32  	%r8450, %r8446, %r8449;
	and.b32  	%r8451, %r18, 522133279;
	add.s32 	%r8452, %r8451, 522133279;
	sub.s32 	%r8453, %r8374, %r8451;
	and.b32  	%r8454, %r8450, %r8453;
	and.b32  	%r8455, %r8454, %r8452;
	or.b32  	%r8849, %r8455, %r18;
	and.b32  	%r8456, %r8378, 64;
	shr.u32 	%r8457, %r8456, 1;
	and.b32  	%r8458, %r8378, 128;
	shr.u32 	%r8459, %r8458, 2;
	not.b32 	%r8460, %r8459;
	and.b32  	%r8461, %r8457, %r8460;
	and.b32  	%r8462, %r8378, 522133279;
	add.s32 	%r8463, %r8462, 31;
	sub.s32 	%r8464, %r8374, %r8462;
	and.b32  	%r8465, %r8461, %r8464;
	and.b32  	%r8466, %r8465, %r8463;
	not.b32 	%r8467, %r8466;
	or.b32  	%r8468, %r8467, -33;
	and.b32  	%r8848, %r8468, %r8378;
	bra.uni 	BB0_1553;

BB0_42:
	setp.eq.s32	%p46, %r1787, 75;
	@%p46 bra 	BB0_43;
	bra.uni 	BB0_11;

BB0_43:
	setp.lt.u32	%p462, %r14, 2;
	@%p462 bra 	BB0_11;

	setp.gt.s32	%p463, %r14, 16;
	@%p463 bra 	BB0_724;

	setp.gt.s32	%p485, %r14, 8;
	@%p485 bra 	BB0_709;

	setp.gt.s32	%p497, %r14, 4;
	@%p497 bra 	BB0_702;

	setp.eq.s32	%p503, %r14, 2;
	@%p503 bra 	BB0_781;

	setp.eq.s32	%p504, %r14, 3;
	@%p504 bra 	BB0_49;
	bra.uni 	BB0_700;

BB0_49:
	and.b32  	%r3912, %r19, 255;
	shl.b32 	%r3913, %r19, 8;
	and.b32  	%r3914, %r3913, 16711680;
	or.b32  	%r3915, %r3914, %r3912;
	shr.u32 	%r3916, %r19, 8;
	and.b32  	%r3917, %r3916, 65280;
	or.b32  	%r8848, %r3915, %r3917;
	mov.u32 	%r8853, 3;
	bra.uni 	BB0_782;

BB0_105:
	setp.eq.s32	%p19, %r1787, 114;
	@%p19 bra 	BB0_106;
	bra.uni 	BB0_11;

BB0_106:
	mov.u32 	%r7500, 32;
	sub.s32 	%r7499, %r7500, %r14;
	setp.gt.s32	%p974, %r7499, 15;
	@%p974 bra 	BB0_1475;

	setp.gt.s32	%p998, %r7499, 7;
	@%p998 bra 	BB0_1460;

	setp.gt.s32	%p1010, %r7499, 3;
	@%p1010 bra 	BB0_1453;

	setp.eq.s32	%p1016, %r7499, 1;
	@%p1016 bra 	BB0_1523;

	setp.eq.s32	%p1017, %r7499, 2;
	@%p1017 bra 	BB0_111;
	bra.uni 	BB0_1451;

BB0_111:
	mov.u32 	%r8001, 16;
	// inline asm
	shf.r.wrap.b32 %r18, %r17, %r18, %r8001;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r17, %r16, %r17, %r8001;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r16, %r15, %r16, %r8001;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r7982, %r22, %r15, %r8001;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8837, %r21, %r22, %r8001;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8838, %r20, %r21, %r8001;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8839, %r19, %r20, %r8001;
	// inline asm
	mov.u32 	%r7999, 0;
	// inline asm
	shf.r.wrap.b32 %r8840, %r7999, %r19, %r8001;
	// inline asm
	mov.u32 	%r19, %r7982;
	bra.uni 	BB0_1529;

BB0_25:
	setp.eq.s32	%p53, %r1787, 46;
	@%p53 bra 	BB0_26;
	bra.uni 	BB0_11;

BB0_26:
	add.s32 	%r3469, %r24, 1;
	setp.ge.u32	%p258, %r3469, %r14;
	@%p258 bra 	BB0_11;

	mov.u32 	%r3497, 8;
	// inline asm
	shf.r.wrap.b32 %r3470, %r19, %r20, %r3497;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r3474, %r20, %r21, %r3497;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r3478, %r21, %r22, %r3497;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r3482, %r22, %r15, %r3497;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r3486, %r15, %r16, %r3497;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r3490, %r16, %r17, %r3497;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r3494, %r17, %r18, %r3497;
	// inline asm
	and.b32  	%r3499, %r23, 3;
	shl.b32 	%r3500, %r3499, 3;
	mov.u32 	%r3501, 255;
	shl.b32 	%r351, %r3501, %r3500;
	not.b32 	%r352, %r351;
	shr.u32 	%r3498, %r24, 2;
	setp.gt.s32	%p259, %r3498, 3;
	@%p259 bra 	BB0_363;

	setp.gt.s32	%p265, %r3498, 1;
	@%p265 bra 	BB0_360;

	setp.eq.s32	%p268, %r3498, 0;
	@%p268 bra 	BB0_30;
	bra.uni 	BB0_358;

BB0_30:
	and.b32  	%r3520, %r19, %r352;
	and.b32  	%r3521, %r3470, %r351;
	or.b32  	%r8848, %r3521, %r3520;
	bra.uni 	BB0_617;

BB0_91:
	setp.eq.s32	%p26, %r1787, 107;
	@%p26 bra 	BB0_92;
	bra.uni 	BB0_11;

BB0_92:
	setp.lt.u32	%p506, %r14, 2;
	@%p506 bra 	BB0_11;

	and.b32  	%r3922, %r19, -65536;
	shl.b32 	%r3923, %r19, 8;
	and.b32  	%r3924, %r3923, 65280;
	or.b32  	%r3925, %r3924, %r3922;
	bfe.u32 	%r3926, %r19, 8, 8;
	or.b32  	%r8848, %r3925, %r3926;

BB0_617:
	mov.u32 	%r8845, %r22;
	mov.u32 	%r8846, %r21;
	mov.u32 	%r8847, %r20;
	bra.uni 	BB0_645;

BB0_60:
	setp.eq.s32	%p40, %r1787, 89;
	@%p40 bra 	BB0_61;
	bra.uni 	BB0_11;

BB0_61:
	setp.gt.u32	%p124, %r24, %r14;
	add.s32 	%r8853, %r24, %r14;
	setp.gt.u32	%p125, %r8853, 31;
	or.pred  	%p126, %p124, %p125;
	@%p126 bra 	BB0_11;

	mov.u32 	%r8691, 0;
	setp.gt.s32	%p127, %r24, 15;
	@%p127 bra 	BB0_163;

	setp.gt.s32	%p151, %r24, 7;
	@%p151 bra 	BB0_147;

	setp.gt.s32	%p163, %r24, 3;
	@%p163 bra 	BB0_140;

	setp.gt.s32	%p169, %r24, 1;
	@%p169 bra 	BB0_137;

	setp.eq.s32	%p172, %r24, 0;
	@%p172 bra 	BB0_67;
	bra.uni 	BB0_135;

BB0_67:
	mov.u32 	%r8688, %r22;
	mov.u32 	%r8689, %r21;
	mov.u32 	%r8690, %r20;
	mov.u32 	%r8691, %r19;
	mov.u32 	%r8692, %r18;
	mov.u32 	%r8693, %r17;
	mov.u32 	%r8694, %r16;
	mov.u32 	%r8695, %r15;
	bra.uni 	BB0_215;

BB0_118:
	setp.eq.s32	%p13, %r1787, 121;
	@%p13 bra 	BB0_119;
	bra.uni 	BB0_11;

BB0_119:
	setp.gt.u32	%p185, %r24, %r14;
	add.s32 	%r8853, %r24, %r14;
	setp.gt.u32	%p186, %r8853, 31;
	or.pred  	%p187, %p185, %p186;
	@%p187 bra 	BB0_11;

	and.b32  	%r2841, %r23, 3;
	shl.b32 	%r2842, %r2841, 3;
	mov.u32 	%r2843, 1;
	shl.b32 	%r2844, %r2843, %r2842;
	add.s32 	%r186, %r2844, -1;
	shr.u32 	%r2840, %r24, 2;
	setp.gt.s32	%p188, %r2840, 3;
	@%p188 bra 	BB0_241;

	setp.gt.s32	%p194, %r2840, 1;
	@%p194 bra 	BB0_238;

	setp.eq.s32	%p197, %r2840, 0;
	@%p197 bra 	BB0_123;
	bra.uni 	BB0_236;

BB0_123:
	and.b32  	%r8707, %r186, %r19;
	mov.u32 	%r8704, 0;
	mov.u32 	%r8705, %r8704;
	mov.u32 	%r8706, %r8704;
	bra.uni 	BB0_253;

BB0_448:
	setp.lt.u32	%p318, %r24, %r14;
	setp.gt.u32	%p319, %r14, %r26;
	and.pred  	%p320, %p318, %p319;
	mov.u32 	%r8845, %r22;
	mov.u32 	%r8846, %r21;
	mov.u32 	%r8847, %r20;
	mov.u32 	%r8848, %r19;
	mov.u32 	%r8849, %r18;
	mov.u32 	%r8850, %r17;
	mov.u32 	%r8851, %r16;
	mov.u32 	%r8852, %r15;
	mov.u32 	%r8853, %r14;
	@!%p320 bra 	BB0_1554;
	bra.uni 	BB0_449;

BB0_449:
	mov.u32 	%r8729, 0;
	setp.gt.s32	%p321, %r24, 15;
	@%p321 bra 	BB0_481;

	setp.gt.s32	%p345, %r24, 7;
	@%p345 bra 	BB0_466;

	setp.gt.s32	%p357, %r24, 3;
	@%p357 bra 	BB0_459;

	setp.gt.s32	%p363, %r24, 1;
	@%p363 bra 	BB0_456;

	setp.eq.s32	%p366, %r24, 0;
	@%p366 bra 	BB0_527;
	bra.uni 	BB0_454;

BB0_527:
	and.b32  	%r8720, %r19, 255;
	bra.uni 	BB0_528;

BB0_21:
	setp.eq.s32	%p57, %r1787, 44;
	@%p57 bra 	BB0_22;
	bra.uni 	BB0_11;

BB0_22:
	setp.ne.s32	%p244, %r24, 0;
	setp.lt.u32	%p245, %r24, %r14;
	and.pred  	%p246, %p244, %p245;
	mov.u32 	%r8845, %r22;
	mov.u32 	%r8846, %r21;
	mov.u32 	%r8847, %r20;
	mov.u32 	%r8848, %r19;
	mov.u32 	%r8849, %r18;
	mov.u32 	%r8850, %r17;
	mov.u32 	%r8851, %r16;
	mov.u32 	%r8852, %r15;
	mov.u32 	%r8853, %r14;
	@!%p246 bra 	BB0_1554;
	bra.uni 	BB0_339;

BB0_339:
	mov.u32 	%r3444, 24;
	// inline asm
	shf.r.wrap.b32 %r3417, %r17, %r18, %r3444;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r3421, %r16, %r17, %r3444;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r3425, %r15, %r16, %r3444;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r3429, %r22, %r15, %r3444;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r3433, %r21, %r22, %r3444;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r3437, %r20, %r21, %r3444;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r3441, %r19, %r20, %r3444;
	// inline asm
	and.b32  	%r3446, %r23, 3;
	shl.b32 	%r3447, %r3446, 3;
	mov.u32 	%r3448, 255;
	shl.b32 	%r334, %r3448, %r3447;
	not.b32 	%r335, %r334;
	shr.u32 	%r3445, %r24, 2;
	setp.gt.s32	%p247, %r3445, 3;
	@%p247 bra 	BB0_347;

	setp.gt.s32	%p253, %r3445, 1;
	@%p253 bra 	BB0_344;

	setp.eq.s32	%p256, %r3445, 0;
	@%p256 bra 	BB0_357;
	bra.uni 	BB0_342;

BB0_357:
	mov.u32 	%r3464, 0;
	// inline asm
	shf.r.wrap.b32 %r3463, %r3464, %r19, %r3444;
	// inline asm
	and.b32  	%r3467, %r3463, %r334;
	and.b32  	%r3468, %r19, %r335;
	or.b32  	%r8848, %r3467, %r3468;
	bra.uni 	BB0_617;

BB0_1430:
	add.s32 	%r8853, %r14, %r14;
	setp.gt.u32	%p962, %r8853, 31;
	@%p962 bra 	BB0_978;

	and.b32  	%r7321, %r14, 3;
	mov.u32 	%r7322, 4;
	sub.s32 	%r7323, %r7322, %r7321;
	shl.b32 	%r7324, %r7323, 2;
	mov.u32 	%r7325, 1985229328;
	shr.u32 	%r7326, %r7325, %r7324;
	and.b32  	%r1533, %r7326, 65535;
	shr.u32 	%r7320, %r14, 2;
	mov.u32 	%r8829, 0;
	setp.gt.s32	%p963, %r7320, 3;
	@%p963 bra 	BB0_1439;

	setp.gt.s32	%p969, %r7320, 1;
	@%p969 bra 	BB0_1436;

	setp.eq.s32	%p972, %r7320, 0;
	@%p972 bra 	BB0_1449;
	bra.uni 	BB0_1434;

BB0_1449:
	// inline asm
	prmt.b32 %r8836, %r17, %r18, %r1533;
	// inline asm
	// inline asm
	prmt.b32 %r8835, %r16, %r17, %r1533;
	// inline asm
	// inline asm
	prmt.b32 %r8834, %r15, %r16, %r1533;
	// inline asm
	// inline asm
	prmt.b32 %r8833, %r22, %r15, %r1533;
	// inline asm
	// inline asm
	prmt.b32 %r8832, %r21, %r22, %r1533;
	// inline asm
	// inline asm
	prmt.b32 %r8831, %r20, %r21, %r1533;
	// inline asm
	// inline asm
	prmt.b32 %r8830, %r19, %r20, %r1533;
	// inline asm
	mov.u32 	%r7496, 0;
	// inline asm
	prmt.b32 %r8829, %r7496, %r19, %r1533;
	// inline asm
	bra.uni 	BB0_1450;

BB0_81:
	setp.eq.s32	%p30, %r1787, 102;
	@%p30 bra 	BB0_82;
	bra.uni 	BB0_11;

BB0_82:
	add.s32 	%r8853, %r14, %r14;
	setp.gt.u32	%p888, %r8853, 31;
	@%p888 bra 	BB0_978;

	mov.u32 	%r6375, 32;
	sub.s32 	%r6374, %r6375, %r14;
	mov.u32 	%r8803, 0;
	setp.gt.s32	%p889, %r6374, 15;
	@%p889 bra 	BB0_1342;

	setp.gt.s32	%p913, %r6374, 7;
	@%p913 bra 	BB0_1326;

	setp.gt.s32	%p925, %r6374, 3;
	@%p925 bra 	BB0_1319;

	setp.gt.s32	%p931, %r6374, 1;
	@%p931 bra 	BB0_1316;

	setp.eq.s32	%p934, %r6374, 0;
	@%p934 bra 	BB0_88;
	bra.uni 	BB0_1314;

BB0_88:
	mov.u32 	%r8795, %r22;
	mov.u32 	%r8796, %r21;
	mov.u32 	%r8797, %r20;
	mov.u32 	%r8798, %r19;
	mov.u32 	%r8799, %r18;
	mov.u32 	%r8800, %r17;
	mov.u32 	%r8801, %r16;
	mov.u32 	%r8802, %r15;
	bra.uni 	BB0_1394;

BB0_428:
	setp.ge.u32	%p306, %r24, %r14;
	@%p306 bra 	BB0_11;

	and.b32  	%r3631, %r23, 3;
	shl.b32 	%r3632, %r3631, 3;
	mov.u32 	%r3633, 255;
	shl.b32 	%r393, %r3633, %r3632;
	not.b32 	%r394, %r393;
	shr.u32 	%r3630, %r24, 2;
	setp.gt.s32	%p307, %r3630, 3;
	@%p307 bra 	BB0_437;

	setp.gt.s32	%p313, %r3630, 1;
	@%p313 bra 	BB0_434;

	setp.eq.s32	%p316, %r3630, 0;
	@%p316 bra 	BB0_447;
	bra.uni 	BB0_432;

BB0_447:
	and.b32  	%r3662, %r19, %r394;
	and.b32  	%r3663, %r393, %r19;
	shl.b32 	%r3664, %r3663, 1;
	and.b32  	%r3665, %r3664, %r393;
	or.b32  	%r8848, %r3665, %r3662;
	bra.uni 	BB0_617;

BB0_52:
	setp.eq.s32	%p44, %r1787, 82;
	@%p44 bra 	BB0_53;
	bra.uni 	BB0_11;

BB0_53:
	setp.ge.u32	%p294, %r24, %r14;
	@%p294 bra 	BB0_11;

	and.b32  	%r3595, %r23, 3;
	shl.b32 	%r3596, %r3595, 3;
	mov.u32 	%r3597, 255;
	shl.b32 	%r383, %r3597, %r3596;
	not.b32 	%r384, %r383;
	shr.u32 	%r3594, %r24, 2;
	setp.gt.s32	%p295, %r3594, 3;
	@%p295 bra 	BB0_418;

	setp.gt.s32	%p301, %r3594, 1;
	@%p301 bra 	BB0_415;

	setp.eq.s32	%p304, %r3594, 0;
	@%p304 bra 	BB0_57;
	bra.uni 	BB0_413;

BB0_57:
	and.b32  	%r3626, %r19, %r384;
	and.b32  	%r3627, %r383, %r19;
	shr.u32 	%r3628, %r3627, 1;
	and.b32  	%r3629, %r3628, %r383;
	or.b32  	%r8848, %r3629, %r3626;
	bra.uni 	BB0_617;

BB0_976:
	mov.b32	{%rs341, %rs342}, %r19;
	shr.u16 	%rs343, %rs342, 8;
	and.b16  	%rs344, %rs342, 255;
	shr.u16 	%rs345, %rs341, 8;
	cvt.u16.u32	%rs346, %r23;
	and.b16  	%rs347, %rs346, 255;
	and.b16  	%rs348, %rs341, 255;
	setp.eq.s16	%p637, %rs348, %rs347;
	cvt.u16.u32	%rs349, %r25;
	setp.eq.s16	%p638, %rs345, %rs347;
	setp.eq.s16	%p639, %rs344, %rs347;
	setp.eq.s16	%p640, %rs343, %rs347;
	selp.b16	%rs350, %rs349, %rs345, %p638;
	cvt.u32.u16	%r4779, %rs350;
	selp.b16	%rs351, %rs349, %rs341, %p637;
	and.b16  	%rs352, %rs351, 255;
	cvt.u32.u16	%r4780, %rs352;
	prmt.b32 	%r4781, %r4779, %r4780, 30212;
	selp.b16	%rs353, %rs349, %rs343, %p640;
	cvt.u32.u16	%r4782, %rs353;
	selp.b16	%rs354, %rs349, %rs342, %p639;
	and.b16  	%rs355, %rs354, 255;
	cvt.u32.u16	%r4783, %rs355;
	prmt.b32 	%r4784, %r4782, %r4783, 30212;
	prmt.b32 	%r8848, %r4784, %r4781, 4180;
	mov.b32	{%rs356, %rs357}, %r20;
	shr.u16 	%rs358, %rs357, 8;
	and.b16  	%rs359, %rs357, 255;
	shr.u16 	%rs360, %rs356, 8;
	and.b16  	%rs361, %rs356, 255;
	setp.eq.s16	%p641, %rs361, %rs347;
	setp.eq.s16	%p642, %rs360, %rs347;
	setp.eq.s16	%p643, %rs359, %rs347;
	setp.eq.s16	%p644, %rs358, %rs347;
	selp.b16	%rs362, %rs349, %rs360, %p642;
	cvt.u32.u16	%r4785, %rs362;
	selp.b16	%rs363, %rs349, %rs356, %p641;
	and.b16  	%rs364, %rs363, 255;
	cvt.u32.u16	%r4786, %rs364;
	prmt.b32 	%r4787, %r4785, %r4786, 30212;
	selp.b16	%rs365, %rs349, %rs358, %p644;
	cvt.u32.u16	%r4788, %rs365;
	selp.b16	%rs366, %rs349, %rs357, %p643;
	and.b16  	%rs367, %rs366, 255;
	cvt.u32.u16	%r4789, %rs367;
	prmt.b32 	%r4790, %r4788, %r4789, 30212;
	prmt.b32 	%r8847, %r4790, %r4787, 4180;
	mov.b32	{%rs368, %rs369}, %r21;
	shr.u16 	%rs370, %rs369, 8;
	and.b16  	%rs371, %rs369, 255;
	shr.u16 	%rs372, %rs368, 8;
	and.b16  	%rs373, %rs368, 255;
	setp.eq.s16	%p645, %rs373, %rs347;
	setp.eq.s16	%p646, %rs372, %rs347;
	setp.eq.s16	%p647, %rs371, %rs347;
	setp.eq.s16	%p648, %rs370, %rs347;
	selp.b16	%rs374, %rs349, %rs372, %p646;
	cvt.u32.u16	%r4791, %rs374;
	selp.b16	%rs375, %rs349, %rs368, %p645;
	and.b16  	%rs376, %rs375, 255;
	cvt.u32.u16	%r4792, %rs376;
	prmt.b32 	%r4793, %r4791, %r4792, 30212;
	selp.b16	%rs377, %rs349, %rs370, %p648;
	cvt.u32.u16	%r4794, %rs377;
	selp.b16	%rs378, %rs349, %rs369, %p647;
	and.b16  	%rs379, %rs378, 255;
	cvt.u32.u16	%r4795, %rs379;
	prmt.b32 	%r4796, %r4794, %r4795, 30212;
	prmt.b32 	%r8846, %r4796, %r4793, 4180;
	mov.b32	{%rs380, %rs381}, %r22;
	shr.u16 	%rs382, %rs381, 8;
	and.b16  	%rs383, %rs381, 255;
	shr.u16 	%rs384, %rs380, 8;
	and.b16  	%rs385, %rs380, 255;
	setp.eq.s16	%p649, %rs385, %rs347;
	setp.eq.s16	%p650, %rs384, %rs347;
	setp.eq.s16	%p651, %rs383, %rs347;
	setp.eq.s16	%p652, %rs382, %rs347;
	selp.b16	%rs386, %rs349, %rs384, %p650;
	cvt.u32.u16	%r4797, %rs386;
	selp.b16	%rs387, %rs349, %rs380, %p649;
	and.b16  	%rs388, %rs387, 255;
	cvt.u32.u16	%r4798, %rs388;
	prmt.b32 	%r4799, %r4797, %r4798, 30212;
	selp.b16	%rs389, %rs349, %rs382, %p652;
	cvt.u32.u16	%r4800, %rs389;
	selp.b16	%rs390, %rs349, %rs381, %p651;
	and.b16  	%rs391, %rs390, 255;
	cvt.u32.u16	%r4801, %rs391;
	prmt.b32 	%r4802, %r4800, %r4801, 30212;
	prmt.b32 	%r8845, %r4802, %r4799, 4180;
	mov.b32	{%rs392, %rs393}, %r15;
	shr.u16 	%rs394, %rs393, 8;
	and.b16  	%rs395, %rs393, 255;
	shr.u16 	%rs396, %rs392, 8;
	and.b16  	%rs397, %rs392, 255;
	setp.eq.s16	%p653, %rs397, %rs347;
	setp.eq.s16	%p654, %rs396, %rs347;
	setp.eq.s16	%p655, %rs395, %rs347;
	setp.eq.s16	%p656, %rs394, %rs347;
	selp.b16	%rs398, %rs349, %rs396, %p654;
	cvt.u32.u16	%r4803, %rs398;
	selp.b16	%rs399, %rs349, %rs392, %p653;
	and.b16  	%rs400, %rs399, 255;
	cvt.u32.u16	%r4804, %rs400;
	prmt.b32 	%r4805, %r4803, %r4804, 30212;
	selp.b16	%rs401, %rs349, %rs394, %p656;
	cvt.u32.u16	%r4806, %rs401;
	selp.b16	%rs402, %rs349, %rs393, %p655;
	and.b16  	%rs403, %rs402, 255;
	cvt.u32.u16	%r4807, %rs403;
	prmt.b32 	%r4808, %r4806, %r4807, 30212;
	prmt.b32 	%r8852, %r4808, %r4805, 4180;
	mov.b32	{%rs404, %rs405}, %r16;
	shr.u16 	%rs406, %rs405, 8;
	and.b16  	%rs407, %rs405, 255;
	shr.u16 	%rs408, %rs404, 8;
	and.b16  	%rs409, %rs404, 255;
	setp.eq.s16	%p657, %rs409, %rs347;
	setp.eq.s16	%p658, %rs408, %rs347;
	setp.eq.s16	%p659, %rs407, %rs347;
	setp.eq.s16	%p660, %rs406, %rs347;
	selp.b16	%rs410, %rs349, %rs408, %p658;
	cvt.u32.u16	%r4809, %rs410;
	selp.b16	%rs411, %rs349, %rs404, %p657;
	and.b16  	%rs412, %rs411, 255;
	cvt.u32.u16	%r4810, %rs412;
	prmt.b32 	%r4811, %r4809, %r4810, 30212;
	selp.b16	%rs413, %rs349, %rs406, %p660;
	cvt.u32.u16	%r4812, %rs413;
	selp.b16	%rs414, %rs349, %rs405, %p659;
	and.b16  	%rs415, %rs414, 255;
	cvt.u32.u16	%r4813, %rs415;
	prmt.b32 	%r4814, %r4812, %r4813, 30212;
	prmt.b32 	%r8851, %r4814, %r4811, 4180;
	mov.b32	{%rs416, %rs417}, %r17;
	shr.u16 	%rs418, %rs417, 8;
	and.b16  	%rs419, %rs417, 255;
	shr.u16 	%rs420, %rs416, 8;
	and.b16  	%rs421, %rs416, 255;
	setp.eq.s16	%p661, %rs421, %rs347;
	setp.eq.s16	%p662, %rs420, %rs347;
	setp.eq.s16	%p663, %rs419, %rs347;
	setp.eq.s16	%p664, %rs418, %rs347;
	selp.b16	%rs422, %rs349, %rs420, %p662;
	cvt.u32.u16	%r4815, %rs422;
	selp.b16	%rs423, %rs349, %rs416, %p661;
	and.b16  	%rs424, %rs423, 255;
	cvt.u32.u16	%r4816, %rs424;
	prmt.b32 	%r4817, %r4815, %r4816, 30212;
	selp.b16	%rs425, %rs349, %rs418, %p664;
	cvt.u32.u16	%r4818, %rs425;
	selp.b16	%rs426, %rs349, %rs417, %p663;
	and.b16  	%rs427, %rs426, 255;
	cvt.u32.u16	%r4819, %rs427;
	prmt.b32 	%r4820, %r4818, %r4819, 30212;
	prmt.b32 	%r8850, %r4820, %r4817, 4180;
	mov.b32	{%rs428, %rs429}, %r18;
	shr.u16 	%rs430, %rs429, 8;
	and.b16  	%rs431, %rs429, 255;
	shr.u16 	%rs432, %rs428, 8;
	and.b16  	%rs433, %rs428, 255;
	setp.eq.s16	%p665, %rs433, %rs347;
	setp.eq.s16	%p666, %rs432, %rs347;
	setp.eq.s16	%p667, %rs431, %rs347;
	setp.eq.s16	%p668, %rs430, %rs347;
	selp.b16	%rs434, %rs349, %rs432, %p666;
	cvt.u32.u16	%r4821, %rs434;
	selp.b16	%rs435, %rs349, %rs428, %p665;
	and.b16  	%rs436, %rs435, 255;
	cvt.u32.u16	%r4822, %rs436;
	prmt.b32 	%r4823, %r4821, %r4822, 30212;
	selp.b16	%rs437, %rs349, %rs430, %p668;
	cvt.u32.u16	%r4824, %rs437;
	selp.b16	%rs438, %rs349, %rs429, %p667;
	and.b16  	%rs439, %rs438, 255;
	cvt.u32.u16	%r4825, %rs439;
	prmt.b32 	%r4826, %r4824, %r4825, 30212;
	prmt.b32 	%r8849, %r4826, %r4823, 4180;
	mov.u32 	%r8853, %r14;
	bra.uni 	BB0_1554;

BB0_114:
	setp.eq.s32	%p17, %r1787, 117;
	@%p17 bra 	BB0_115;
	bra.uni 	BB0_11;

BB0_115:
	and.b32  	%r8469, %r19, 1077952576;
	shr.u32 	%r8470, %r8469, 1;
	and.b32  	%r8471, %r19, -2139062144;
	shr.u32 	%r8472, %r8471, 2;
	not.b32 	%r8473, %r8472;
	and.b32  	%r8474, %r8470, %r8473;
	and.b32  	%r8475, %r19, 522133279;
	add.s32 	%r8476, %r8475, 522133279;
	mov.u32 	%r8477, -84215046;
	sub.s32 	%r8478, %r8477, %r8475;
	and.b32  	%r8479, %r8474, %r8478;
	and.b32  	%r8480, %r8479, %r8476;
	not.b32 	%r8481, %r8480;
	and.b32  	%r8848, %r19, %r8481;
	and.b32  	%r8482, %r20, 1077952576;
	shr.u32 	%r8483, %r8482, 1;
	and.b32  	%r8484, %r20, -2139062144;
	shr.u32 	%r8485, %r8484, 2;
	not.b32 	%r8486, %r8485;
	and.b32  	%r8487, %r8483, %r8486;
	and.b32  	%r8488, %r20, 522133279;
	add.s32 	%r8489, %r8488, 522133279;
	sub.s32 	%r8490, %r8477, %r8488;
	and.b32  	%r8491, %r8487, %r8490;
	and.b32  	%r8492, %r8491, %r8489;
	not.b32 	%r8493, %r8492;
	and.b32  	%r8847, %r20, %r8493;
	and.b32  	%r8494, %r21, 1077952576;
	shr.u32 	%r8495, %r8494, 1;
	and.b32  	%r8496, %r21, -2139062144;
	shr.u32 	%r8497, %r8496, 2;
	not.b32 	%r8498, %r8497;
	and.b32  	%r8499, %r8495, %r8498;
	and.b32  	%r8500, %r21, 522133279;
	add.s32 	%r8501, %r8500, 522133279;
	sub.s32 	%r8502, %r8477, %r8500;
	and.b32  	%r8503, %r8499, %r8502;
	and.b32  	%r8504, %r8503, %r8501;
	not.b32 	%r8505, %r8504;
	and.b32  	%r8846, %r21, %r8505;
	and.b32  	%r8506, %r22, 1077952576;
	shr.u32 	%r8507, %r8506, 1;
	and.b32  	%r8508, %r22, -2139062144;
	shr.u32 	%r8509, %r8508, 2;
	not.b32 	%r8510, %r8509;
	and.b32  	%r8511, %r8507, %r8510;
	and.b32  	%r8512, %r22, 522133279;
	add.s32 	%r8513, %r8512, 522133279;
	sub.s32 	%r8514, %r8477, %r8512;
	and.b32  	%r8515, %r8511, %r8514;
	and.b32  	%r8516, %r8515, %r8513;
	not.b32 	%r8517, %r8516;
	and.b32  	%r8845, %r22, %r8517;
	and.b32  	%r8518, %r15, 1077952576;
	shr.u32 	%r8519, %r8518, 1;
	and.b32  	%r8520, %r15, -2139062144;
	shr.u32 	%r8521, %r8520, 2;
	not.b32 	%r8522, %r8521;
	and.b32  	%r8523, %r8519, %r8522;
	and.b32  	%r8524, %r15, 522133279;
	add.s32 	%r8525, %r8524, 522133279;
	sub.s32 	%r8526, %r8477, %r8524;
	and.b32  	%r8527, %r8523, %r8526;
	and.b32  	%r8528, %r8527, %r8525;
	not.b32 	%r8529, %r8528;
	and.b32  	%r8852, %r15, %r8529;
	and.b32  	%r8530, %r16, 1077952576;
	shr.u32 	%r8531, %r8530, 1;
	and.b32  	%r8532, %r16, -2139062144;
	shr.u32 	%r8533, %r8532, 2;
	not.b32 	%r8534, %r8533;
	and.b32  	%r8535, %r8531, %r8534;
	and.b32  	%r8536, %r16, 522133279;
	add.s32 	%r8537, %r8536, 522133279;
	sub.s32 	%r8538, %r8477, %r8536;
	and.b32  	%r8539, %r8535, %r8538;
	and.b32  	%r8540, %r8539, %r8537;
	not.b32 	%r8541, %r8540;
	and.b32  	%r8851, %r16, %r8541;
	and.b32  	%r8542, %r17, 1077952576;
	shr.u32 	%r8543, %r8542, 1;
	and.b32  	%r8544, %r17, -2139062144;
	shr.u32 	%r8545, %r8544, 2;
	not.b32 	%r8546, %r8545;
	and.b32  	%r8547, %r8543, %r8546;
	and.b32  	%r8548, %r17, 522133279;
	add.s32 	%r8549, %r8548, 522133279;
	sub.s32 	%r8550, %r8477, %r8548;
	and.b32  	%r8551, %r8547, %r8550;
	and.b32  	%r8552, %r8551, %r8549;
	not.b32 	%r8553, %r8552;
	and.b32  	%r8850, %r17, %r8553;
	and.b32  	%r8554, %r18, 1077952576;
	shr.u32 	%r8555, %r8554, 1;
	and.b32  	%r8556, %r18, -2139062144;
	shr.u32 	%r8557, %r8556, 2;
	not.b32 	%r8558, %r8557;
	and.b32  	%r8559, %r8555, %r8558;
	and.b32  	%r8560, %r18, 522133279;
	add.s32 	%r8561, %r8560, 522133279;
	sub.s32 	%r8562, %r8477, %r8560;
	and.b32  	%r8563, %r8559, %r8562;
	and.b32  	%r8564, %r8563, %r8561;
	not.b32 	%r8565, %r8564;
	and.b32  	%r8849, %r18, %r8565;
	bra.uni 	BB0_1553;

BB0_951:
	st.local.v4.u32 	[%rd7], {%r19, %r20, %r21, %r22};
	st.local.v4.u32 	[%rd7+16], {%r15, %r16, %r17, %r18};
	mov.u64 	%rd15, 0;
	st.local.v2.u64 	[%rd6], {%rd15, %rd15};
	st.local.v2.u64 	[%rd6+16], {%rd15, %rd15};
	cvt.u16.u32	%rs440, %r19;
	setp.eq.s32	%p624, %r14, 0;
	mov.u32 	%r8853, 0;
	@%p624 bra 	BB0_975;

	cvt.u16.u32	%rs2, %r23;
	and.b32  	%r863, %r14, 3;
	setp.eq.s32	%p625, %r863, 0;
	mov.u32 	%r8756, 0;
	mov.u32 	%r8853, %r8756;
	@%p625 bra 	BB0_965;

	setp.eq.s32	%p626, %r863, 1;
	mov.u32 	%r8751, 0;
	@%p626 bra 	BB0_954;
	bra.uni 	BB0_955;

BB0_954:
	mov.u32 	%r8853, %r8751;
	bra.uni 	BB0_962;

BB0_33:
	setp.eq.s32	%p51, %r1787, 68;
	@%p51 bra 	BB0_34;
	bra.uni 	BB0_11;

BB0_34:
	setp.ge.u32	%p827, %r24, %r14;
	@%p827 bra 	BB0_978;

	mov.u32 	%r6118, 8;
	// inline asm
	shf.r.wrap.b32 %r6087, %r19, %r20, %r6118;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8847, %r20, %r21, %r6118;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8846, %r21, %r22, %r6118;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8845, %r22, %r15, %r6118;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8852, %r15, %r16, %r6118;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8851, %r16, %r17, %r6118;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8850, %r17, %r18, %r6118;
	// inline asm
	mov.u32 	%r6117, 0;
	// inline asm
	shf.r.wrap.b32 %r8849, %r18, %r6117, %r6118;
	// inline asm
	and.b32  	%r6120, %r23, 3;
	shl.b32 	%r6121, %r6120, 3;
	mov.u32 	%r6122, 1;
	shl.b32 	%r6123, %r6122, %r6121;
	add.s32 	%r1210, %r6123, -1;
	neg.s32 	%r1211, %r6123;
	shr.u32 	%r6119, %r24, 2;
	setp.gt.s32	%p828, %r6119, 3;
	@%p828 bra 	BB0_1273;

	setp.gt.s32	%p834, %r6119, 1;
	@%p834 bra 	BB0_1270;

	setp.eq.s32	%p837, %r6119, 0;
	@%p837 bra 	BB0_38;
	bra.uni 	BB0_1268;

BB0_38:
	and.b32  	%r6138, %r1210, %r19;
	and.b32  	%r6139, %r6087, %r1211;
	or.b32  	%r8848, %r6139, %r6138;
	bra.uni 	BB0_1278;

BB0_1552:
	and.b32  	%r8566, %r19, 1077952576;
	shr.u32 	%r8567, %r8566, 1;
	and.b32  	%r8568, %r19, -2139062144;
	shr.u32 	%r8569, %r8568, 2;
	not.b32 	%r8570, %r8569;
	and.b32  	%r8571, %r8567, %r8570;
	and.b32  	%r8572, %r19, 522133279;
	add.s32 	%r8573, %r8572, 522133279;
	mov.u32 	%r8574, -84215046;
	sub.s32 	%r8575, %r8574, %r8572;
	and.b32  	%r8576, %r8571, %r8575;
	and.b32  	%r8577, %r8576, %r8573;
	or.b32  	%r8848, %r8577, %r19;
	and.b32  	%r8578, %r20, 1077952576;
	shr.u32 	%r8579, %r8578, 1;
	and.b32  	%r8580, %r20, -2139062144;
	shr.u32 	%r8581, %r8580, 2;
	not.b32 	%r8582, %r8581;
	and.b32  	%r8583, %r8579, %r8582;
	and.b32  	%r8584, %r20, 522133279;
	add.s32 	%r8585, %r8584, 522133279;
	sub.s32 	%r8586, %r8574, %r8584;
	and.b32  	%r8587, %r8583, %r8586;
	and.b32  	%r8588, %r8587, %r8585;
	or.b32  	%r8847, %r8588, %r20;
	and.b32  	%r8589, %r21, 1077952576;
	shr.u32 	%r8590, %r8589, 1;
	and.b32  	%r8591, %r21, -2139062144;
	shr.u32 	%r8592, %r8591, 2;
	not.b32 	%r8593, %r8592;
	and.b32  	%r8594, %r8590, %r8593;
	and.b32  	%r8595, %r21, 522133279;
	add.s32 	%r8596, %r8595, 522133279;
	sub.s32 	%r8597, %r8574, %r8595;
	and.b32  	%r8598, %r8594, %r8597;
	and.b32  	%r8599, %r8598, %r8596;
	or.b32  	%r8846, %r8599, %r21;
	and.b32  	%r8600, %r22, 1077952576;
	shr.u32 	%r8601, %r8600, 1;
	and.b32  	%r8602, %r22, -2139062144;
	shr.u32 	%r8603, %r8602, 2;
	not.b32 	%r8604, %r8603;
	and.b32  	%r8605, %r8601, %r8604;
	and.b32  	%r8606, %r22, 522133279;
	add.s32 	%r8607, %r8606, 522133279;
	sub.s32 	%r8608, %r8574, %r8606;
	and.b32  	%r8609, %r8605, %r8608;
	and.b32  	%r8610, %r8609, %r8607;
	or.b32  	%r8845, %r8610, %r22;
	and.b32  	%r8611, %r15, 1077952576;
	shr.u32 	%r8612, %r8611, 1;
	and.b32  	%r8613, %r15, -2139062144;
	shr.u32 	%r8614, %r8613, 2;
	not.b32 	%r8615, %r8614;
	and.b32  	%r8616, %r8612, %r8615;
	and.b32  	%r8617, %r15, 522133279;
	add.s32 	%r8618, %r8617, 522133279;
	sub.s32 	%r8619, %r8574, %r8617;
	and.b32  	%r8620, %r8616, %r8619;
	and.b32  	%r8621, %r8620, %r8618;
	or.b32  	%r8852, %r8621, %r15;
	and.b32  	%r8622, %r16, 1077952576;
	shr.u32 	%r8623, %r8622, 1;
	and.b32  	%r8624, %r16, -2139062144;
	shr.u32 	%r8625, %r8624, 2;
	not.b32 	%r8626, %r8625;
	and.b32  	%r8627, %r8623, %r8626;
	and.b32  	%r8628, %r16, 522133279;
	add.s32 	%r8629, %r8628, 522133279;
	sub.s32 	%r8630, %r8574, %r8628;
	and.b32  	%r8631, %r8627, %r8630;
	and.b32  	%r8632, %r8631, %r8629;
	or.b32  	%r8851, %r8632, %r16;
	and.b32  	%r8633, %r17, 1077952576;
	shr.u32 	%r8634, %r8633, 1;
	and.b32  	%r8635, %r17, -2139062144;
	shr.u32 	%r8636, %r8635, 2;
	not.b32 	%r8637, %r8636;
	and.b32  	%r8638, %r8634, %r8637;
	and.b32  	%r8639, %r17, 522133279;
	add.s32 	%r8640, %r8639, 522133279;
	sub.s32 	%r8641, %r8574, %r8639;
	and.b32  	%r8642, %r8638, %r8641;
	and.b32  	%r8643, %r8642, %r8640;
	or.b32  	%r8850, %r8643, %r17;
	and.b32  	%r8644, %r18, 1077952576;
	shr.u32 	%r8645, %r8644, 1;
	and.b32  	%r8646, %r18, -2139062144;
	shr.u32 	%r8647, %r8646, 2;
	not.b32 	%r8648, %r8647;
	and.b32  	%r8649, %r8645, %r8648;
	and.b32  	%r8650, %r18, 522133279;
	add.s32 	%r8651, %r8650, 522133279;
	sub.s32 	%r8652, %r8574, %r8650;
	and.b32  	%r8653, %r8649, %r8652;
	and.b32  	%r8654, %r8653, %r8651;
	or.b32  	%r8849, %r8654, %r18;
	bra.uni 	BB0_1553;

BB0_96:
	setp.eq.s32	%p24, %r1787, 112;
	@%p24 bra 	BB0_97;
	bra.uni 	BB0_11;

BB0_97:
	mad.lo.s32 	%r7124, %r24, %r14, %r14;
	setp.gt.u32	%p947, %r7124, 31;
	setp.eq.s32	%p948, %r24, 0;
	or.pred  	%p949, %p947, %p948;
	mov.u32 	%r8811, 0;
	mov.u32 	%r8853, %r14;
	mov.u32 	%r8852, %r15;
	mov.u32 	%r8851, %r16;
	mov.u32 	%r8850, %r17;
	mov.u32 	%r8849, %r18;
	mov.u32 	%r8848, %r19;
	mov.u32 	%r8847, %r20;
	mov.u32 	%r8846, %r21;
	mov.u32 	%r8845, %r22;
	@%p949 bra 	BB0_978;

BB0_98:
	and.b32  	%r7134, %r8853, 3;
	mov.u32 	%r7135, 4;
	sub.s32 	%r7136, %r7135, %r7134;
	shl.b32 	%r7137, %r7136, 2;
	mov.u32 	%r7138, 1985229328;
	shr.u32 	%r7139, %r7138, %r7137;
	and.b32  	%r1477, %r7139, 65535;
	shr.u32 	%r7133, %r8853, 2;
	setp.gt.s32	%p950, %r7133, 3;
	@%p950 bra 	BB0_1419;

	setp.gt.s32	%p956, %r7133, 1;
	@%p956 bra 	BB0_1416;

	setp.eq.s32	%p959, %r7133, 0;
	@%p959 bra 	BB0_101;
	bra.uni 	BB0_1414;

BB0_101:
	// inline asm
	prmt.b32 %r8828, %r17, %r18, %r1477;
	// inline asm
	// inline asm
	prmt.b32 %r8827, %r16, %r17, %r1477;
	// inline asm
	// inline asm
	prmt.b32 %r8826, %r15, %r16, %r1477;
	// inline asm
	// inline asm
	prmt.b32 %r8825, %r22, %r15, %r1477;
	// inline asm
	// inline asm
	prmt.b32 %r8824, %r21, %r22, %r1477;
	// inline asm
	// inline asm
	prmt.b32 %r8823, %r20, %r21, %r1477;
	// inline asm
	// inline asm
	prmt.b32 %r8822, %r19, %r20, %r1477;
	// inline asm
	mov.u32 	%r7309, 0;
	// inline asm
	prmt.b32 %r8821, %r7309, %r19, %r1477;
	// inline asm
	bra.uni 	BB0_1429;

BB0_1419:
	setp.gt.s32	%p951, %r7133, 5;
	@%p951 bra 	BB0_1423;

	setp.eq.s32	%p954, %r7133, 4;
	@%p954 bra 	BB0_1427;
	bra.uni 	BB0_1421;

BB0_1427:
	// inline asm
	prmt.b32 %r8828, %r21, %r22, %r1477;
	// inline asm
	// inline asm
	prmt.b32 %r8827, %r20, %r21, %r1477;
	// inline asm
	// inline asm
	prmt.b32 %r8826, %r19, %r20, %r1477;
	// inline asm
	mov.u32 	%r8821, 0;
	// inline asm
	prmt.b32 %r8825, %r8821, %r19, %r1477;
	// inline asm
	mov.u32 	%r8822, %r8821;
	mov.u32 	%r8823, %r8821;
	mov.u32 	%r8824, %r8821;
	bra.uni 	BB0_1429;

BB0_1416:
	setp.eq.s32	%p957, %r7133, 2;
	@%p957 bra 	BB0_1428;
	bra.uni 	BB0_1417;

BB0_1428:
	// inline asm
	prmt.b32 %r8828, %r15, %r16, %r1477;
	// inline asm
	// inline asm
	prmt.b32 %r8827, %r22, %r15, %r1477;
	// inline asm
	// inline asm
	prmt.b32 %r8826, %r21, %r22, %r1477;
	// inline asm
	// inline asm
	prmt.b32 %r8825, %r20, %r21, %r1477;
	// inline asm
	// inline asm
	prmt.b32 %r8824, %r19, %r20, %r1477;
	// inline asm
	mov.u32 	%r8821, 0;
	// inline asm
	prmt.b32 %r8823, %r8821, %r19, %r1477;
	// inline asm
	mov.u32 	%r8822, %r8821;
	bra.uni 	BB0_1429;

BB0_1423:
	setp.eq.s32	%p952, %r7133, 6;
	@%p952 bra 	BB0_1426;
	bra.uni 	BB0_1424;

BB0_1426:
	// inline asm
	prmt.b32 %r8828, %r19, %r20, %r1477;
	// inline asm
	mov.u32 	%r8821, 0;
	// inline asm
	prmt.b32 %r8827, %r8821, %r19, %r1477;
	// inline asm
	mov.u32 	%r8822, %r8821;
	mov.u32 	%r8823, %r8821;
	mov.u32 	%r8824, %r8821;
	mov.u32 	%r8825, %r8821;
	mov.u32 	%r8826, %r8821;
	bra.uni 	BB0_1429;

BB0_1414:
	mov.u32 	%r8821, 0;
	setp.eq.s32	%p960, %r7133, 1;
	mov.u32 	%r8822, %r8821;
	mov.u32 	%r8823, %r8821;
	mov.u32 	%r8824, %r8821;
	mov.u32 	%r8825, %r8821;
	mov.u32 	%r8826, %r8821;
	mov.u32 	%r8827, %r8821;
	mov.u32 	%r8828, %r8821;
	@%p960 bra 	BB0_1415;
	bra.uni 	BB0_1429;

BB0_1415:
	// inline asm
	prmt.b32 %r8828, %r16, %r17, %r1477;
	// inline asm
	// inline asm
	prmt.b32 %r8827, %r15, %r16, %r1477;
	// inline asm
	// inline asm
	prmt.b32 %r8826, %r22, %r15, %r1477;
	// inline asm
	// inline asm
	prmt.b32 %r8825, %r21, %r22, %r1477;
	// inline asm
	// inline asm
	prmt.b32 %r8824, %r20, %r21, %r1477;
	// inline asm
	// inline asm
	prmt.b32 %r8823, %r19, %r20, %r1477;
	// inline asm
	mov.u32 	%r8821, 0;
	// inline asm
	prmt.b32 %r8822, %r8821, %r19, %r1477;
	// inline asm
	bra.uni 	BB0_1429;

BB0_1421:
	mov.u32 	%r8821, 0;
	setp.eq.s32	%p955, %r7133, 5;
	mov.u32 	%r8822, %r8821;
	mov.u32 	%r8823, %r8821;
	mov.u32 	%r8824, %r8821;
	mov.u32 	%r8825, %r8821;
	mov.u32 	%r8826, %r8821;
	mov.u32 	%r8827, %r8821;
	mov.u32 	%r8828, %r8821;
	@%p955 bra 	BB0_1422;
	bra.uni 	BB0_1429;

BB0_1422:
	// inline asm
	prmt.b32 %r8828, %r20, %r21, %r1477;
	// inline asm
	// inline asm
	prmt.b32 %r8827, %r19, %r20, %r1477;
	// inline asm
	mov.u32 	%r8821, 0;
	// inline asm
	prmt.b32 %r8826, %r8821, %r19, %r1477;
	// inline asm
	mov.u32 	%r8822, %r8821;
	mov.u32 	%r8823, %r8821;
	mov.u32 	%r8824, %r8821;
	mov.u32 	%r8825, %r8821;
	bra.uni 	BB0_1429;

BB0_1417:
	mov.u32 	%r8821, 0;
	setp.eq.s32	%p958, %r7133, 3;
	mov.u32 	%r8822, %r8821;
	mov.u32 	%r8823, %r8821;
	mov.u32 	%r8824, %r8821;
	mov.u32 	%r8825, %r8821;
	mov.u32 	%r8826, %r8821;
	mov.u32 	%r8827, %r8821;
	mov.u32 	%r8828, %r8821;
	@%p958 bra 	BB0_1418;
	bra.uni 	BB0_1429;

BB0_1418:
	// inline asm
	prmt.b32 %r8828, %r22, %r15, %r1477;
	// inline asm
	// inline asm
	prmt.b32 %r8827, %r21, %r22, %r1477;
	// inline asm
	// inline asm
	prmt.b32 %r8826, %r20, %r21, %r1477;
	// inline asm
	// inline asm
	prmt.b32 %r8825, %r19, %r20, %r1477;
	// inline asm
	mov.u32 	%r8821, 0;
	// inline asm
	prmt.b32 %r8824, %r8821, %r19, %r1477;
	// inline asm
	mov.u32 	%r8822, %r8821;
	mov.u32 	%r8823, %r8821;
	bra.uni 	BB0_1429;

BB0_1424:
	mov.u32 	%r8821, 0;
	setp.ne.s32	%p953, %r7133, 7;
	mov.u32 	%r8822, %r8821;
	mov.u32 	%r8823, %r8821;
	mov.u32 	%r8824, %r8821;
	mov.u32 	%r8825, %r8821;
	mov.u32 	%r8826, %r8821;
	mov.u32 	%r8827, %r8821;
	mov.u32 	%r8828, %r8821;
	@%p953 bra 	BB0_1429;

	mov.u32 	%r8821, 0;
	// inline asm
	prmt.b32 %r8828, %r8821, %r19, %r1477;
	// inline asm
	mov.u32 	%r8822, %r8821;
	mov.u32 	%r8823, %r8821;
	mov.u32 	%r8824, %r8821;
	mov.u32 	%r8825, %r8821;
	mov.u32 	%r8826, %r8821;
	mov.u32 	%r8827, %r8821;

BB0_1429:
	or.b32  	%r8848, %r8821, %r8848;
	or.b32  	%r8847, %r8822, %r8847;
	or.b32  	%r8846, %r8823, %r8846;
	or.b32  	%r8845, %r8824, %r8845;
	or.b32  	%r8852, %r8825, %r8852;
	or.b32  	%r8851, %r8826, %r8851;
	or.b32  	%r8850, %r8827, %r8850;
	or.b32  	%r8849, %r8828, %r8849;
	add.s32 	%r8853, %r8853, %r14;
	add.s32 	%r8811, %r8811, 1;
	setp.lt.u32	%p961, %r8811, %r24;
	@%p961 bra 	BB0_98;
	bra.uni 	BB0_1554;

BB0_785:
	setp.eq.s32	%p510, %r14, 0;
	add.s32 	%r3963, %r24, %r14;
	setp.gt.u32	%p511, %r3963, 31;
	or.pred  	%p512, %p510, %p511;
	@%p512 bra 	BB0_11;

	add.s32 	%r3965, %r14, -1;
	and.b32  	%r3966, %r3965, 3;
	shl.b32 	%r3967, %r3966, 3;
	setp.lt.u32	%p513, %r3965, 4;
	selp.b32	%r3968, %r19, 0, %p513;
	and.b32  	%r3969, %r3965, -4;
	setp.eq.s32	%p514, %r3969, 4;
	selp.b32	%r3970, %r20, 0, %p514;
	setp.eq.s32	%p515, %r3969, 8;
	selp.b32	%r3971, %r21, 0, %p515;
	setp.eq.s32	%p516, %r3969, 12;
	selp.b32	%r3972, %r22, 0, %p516;
	setp.eq.s32	%p517, %r3969, 16;
	selp.b32	%r3973, %r15, 0, %p517;
	setp.eq.s32	%p518, %r3969, 20;
	selp.b32	%r3974, %r16, 0, %p518;
	setp.eq.s32	%p519, %r3969, 24;
	selp.b32	%r3975, %r17, 0, %p519;
	setp.gt.u32	%p520, %r3965, 27;
	selp.b32	%r3976, %r18, 0, %p520;
	or.b32  	%r3977, %r3976, %r3968;
	or.b32  	%r3978, %r3977, %r3970;
	or.b32  	%r3979, %r3978, %r3971;
	or.b32  	%r3980, %r3979, %r3972;
	or.b32  	%r3981, %r3980, %r3973;
	or.b32  	%r3982, %r3981, %r3974;
	or.b32  	%r3983, %r3982, %r3975;
	shr.u32 	%r3984, %r3983, %r3967;
	and.b32  	%r588, %r3984, 255;
	setp.eq.s32	%p521, %r24, 0;
	mov.u32 	%r8730, 0;
	mov.u32 	%r8853, %r14;
	mov.u32 	%r8852, %r15;
	mov.u32 	%r8851, %r16;
	mov.u32 	%r8850, %r17;
	mov.u32 	%r8849, %r18;
	mov.u32 	%r8848, %r19;
	mov.u32 	%r8847, %r20;
	mov.u32 	%r8846, %r21;
	mov.u32 	%r8845, %r22;
	@%p521 bra 	BB0_1554;

BB0_787:
	and.b32  	%r3985, %r8853, 3;
	shl.b32 	%r3986, %r3985, 3;
	shl.b32 	%r3987, %r588, %r3986;
	setp.lt.u32	%p522, %r8853, 4;
	selp.b32	%r3988, %r3987, 0, %p522;
	or.b32  	%r8848, %r3988, %r8848;
	and.b32  	%r3989, %r8853, -4;
	setp.eq.s32	%p523, %r3989, 4;
	selp.b32	%r3990, %r3987, 0, %p523;
	or.b32  	%r8847, %r3990, %r8847;
	setp.eq.s32	%p524, %r3989, 8;
	selp.b32	%r3991, %r3987, 0, %p524;
	or.b32  	%r8846, %r3991, %r8846;
	setp.eq.s32	%p525, %r3989, 12;
	selp.b32	%r3992, %r3987, 0, %p525;
	or.b32  	%r8845, %r3992, %r8845;
	setp.eq.s32	%p526, %r3989, 16;
	selp.b32	%r3993, %r3987, 0, %p526;
	or.b32  	%r8852, %r3993, %r8852;
	setp.eq.s32	%p527, %r3989, 20;
	selp.b32	%r3994, %r3987, 0, %p527;
	or.b32  	%r8851, %r3994, %r8851;
	setp.eq.s32	%p528, %r3989, 24;
	selp.b32	%r3995, %r3987, 0, %p528;
	or.b32  	%r8850, %r3995, %r8850;
	setp.gt.u32	%p529, %r8853, 27;
	selp.b32	%r3996, %r3987, 0, %p529;
	or.b32  	%r8849, %r3996, %r8849;
	add.s32 	%r8853, %r8853, 1;
	add.s32 	%r8730, %r8730, 1;
	setp.lt.u32	%p530, %r8730, %r24;
	@%p530 bra 	BB0_787;
	bra.uni 	BB0_1554;

BB0_70:
	setp.eq.s32	%p38, %r1787, 93;
	@%p38 bra 	BB0_71;
	bra.uni 	BB0_11;

BB0_71:
	setp.eq.s32	%p839, %r14, 0;
	mov.u32 	%r8853, 0;
	@%p839 bra 	BB0_1034;

	add.s32 	%r8853, %r14, -1;
	and.b32  	%r6141, %r8853, 3;
	shl.b32 	%r6142, %r6141, 3;
	mov.u32 	%r6143, 1;
	shl.b32 	%r6144, %r6143, %r6142;
	add.s32 	%r6145, %r6144, -1;
	setp.lt.u32	%p840, %r8853, 4;
	selp.b32	%r6146, %r6145, -1, %p840;
	and.b32  	%r8848, %r6146, %r19;
	and.b32  	%r6147, %r8853, -4;
	setp.eq.s32	%p841, %r6147, 4;
	selp.b32	%r6148, %r6145, -1, %p841;
	and.b32  	%r8847, %r6148, %r20;
	setp.eq.s32	%p842, %r6147, 8;
	selp.b32	%r6149, %r6145, -1, %p842;
	and.b32  	%r8846, %r6149, %r21;
	setp.eq.s32	%p843, %r6147, 12;
	selp.b32	%r6150, %r6145, -1, %p843;
	and.b32  	%r8845, %r6150, %r22;
	setp.eq.s32	%p844, %r6147, 16;
	selp.b32	%r6151, %r6145, -1, %p844;
	and.b32  	%r8852, %r6151, %r15;
	setp.eq.s32	%p845, %r6147, 20;
	selp.b32	%r6152, %r6145, -1, %p845;
	and.b32  	%r8851, %r6152, %r16;
	setp.eq.s32	%p846, %r6147, 24;
	selp.b32	%r6153, %r6145, -1, %p846;
	and.b32  	%r8850, %r6153, %r17;
	setp.gt.u32	%p847, %r8853, 27;
	selp.b32	%r6154, %r6145, -1, %p847;
	and.b32  	%r8849, %r6154, %r18;
	bra.uni 	BB0_1554;

BB0_788:
	setp.eq.s32	%p531, %r14, 0;
	add.s32 	%r8853, %r24, %r14;
	setp.gt.u32	%p532, %r8853, 31;
	or.pred  	%p533, %p531, %p532;
	@%p533 bra 	BB0_11;

	and.b32  	%r610, %r19, 255;
	setp.gt.s32	%p534, %r24, 15;
	@%p534 bra 	BB0_819;

	setp.gt.s32	%p558, %r24, 7;
	@%p558 bra 	BB0_803;

	setp.gt.s32	%p570, %r24, 3;
	@%p570 bra 	BB0_796;

	setp.eq.s32	%p576, %r24, 1;
	@%p576 bra 	BB0_868;

	setp.eq.s32	%p577, %r24, 2;
	@%p577 bra 	BB0_867;
	bra.uni 	BB0_794;

BB0_867:
	mov.u32 	%r4497, 16;
	// inline asm
	shf.r.wrap.b32 %r18, %r17, %r18, %r4497;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r17, %r16, %r17, %r4497;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r16, %r15, %r16, %r4497;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r15, %r22, %r15, %r4497;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8845, %r21, %r22, %r4497;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8846, %r20, %r21, %r4497;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8847, %r19, %r20, %r4497;
	// inline asm
	mov.u32 	%r4495, 0;
	// inline asm
	shf.r.wrap.b32 %r8848, %r4495, %r19, %r4497;
	// inline asm
	bra.uni 	BB0_874;

BB0_126:
	setp.eq.s32	%p11, %r1787, 125;
	@%p11 bra 	BB0_127;
	bra.uni 	BB0_11;

BB0_127:
	setp.eq.s32	%p849, %r14, 0;
	mov.u32 	%r8853, 0;
	@%p849 bra 	BB0_1034;

	add.s32 	%r6222, %r14, -1;
	shl.b32 	%r6223, %r6222, 3;
	and.b32  	%r6224, %r6223, 24;
	setp.lt.u32	%p850, %r6222, 4;
	selp.b32	%r6225, %r19, 0, %p850;
	and.b32  	%r6226, %r6222, -4;
	setp.eq.s32	%p851, %r6226, 4;
	selp.b32	%r6227, %r20, 0, %p851;
	setp.eq.s32	%p852, %r6226, 8;
	selp.b32	%r6228, %r21, 0, %p852;
	setp.eq.s32	%p853, %r6226, 12;
	selp.b32	%r6229, %r22, 0, %p853;
	setp.eq.s32	%p854, %r6226, 16;
	selp.b32	%r6230, %r15, 0, %p854;
	setp.eq.s32	%p855, %r6226, 20;
	selp.b32	%r6231, %r16, 0, %p855;
	setp.eq.s32	%p856, %r6226, 24;
	selp.b32	%r6232, %r17, 0, %p856;
	setp.gt.u32	%p857, %r6222, 27;
	selp.b32	%r6233, %r18, 0, %p857;
	or.b32  	%r6234, %r6233, %r6225;
	or.b32  	%r6235, %r6234, %r6227;
	or.b32  	%r6236, %r6235, %r6228;
	or.b32  	%r6237, %r6236, %r6229;
	or.b32  	%r6238, %r6237, %r6230;
	or.b32  	%r6239, %r6238, %r6231;
	or.b32  	%r6240, %r6239, %r6232;
	shr.u32 	%r6241, %r6240, %r6224;
	and.b32  	%r6242, %r6241, 255;
	mov.u32 	%r6220, 24;
	// inline asm
	shf.r.wrap.b32 %r6189, %r17, %r18, %r6220;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8850, %r16, %r17, %r6220;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8851, %r15, %r16, %r6220;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8852, %r22, %r15, %r6220;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8845, %r21, %r22, %r6220;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8846, %r20, %r21, %r6220;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8847, %r19, %r20, %r6220;
	// inline asm
	mov.u32 	%r8849, 0;
	// inline asm
	shf.r.wrap.b32 %r6217, %r8849, %r19, %r6220;
	// inline asm
	or.b32  	%r8848, %r6217, %r6242;
	shl.b32 	%r6243, %r14, 3;
	and.b32  	%r6244, %r6243, 24;
	mov.u32 	%r6245, 1;
	shl.b32 	%r6246, %r6245, %r6244;
	add.s32 	%r1255, %r6246, -1;
	shr.u32 	%r6221, %r14, 2;
	setp.gt.s32	%p858, %r6221, 3;
	@%p858 bra 	BB0_1295;

	setp.gt.s32	%p864, %r6221, 1;
	@%p864 bra 	BB0_1292;

	setp.eq.s32	%p867, %r6221, 0;
	@%p867 bra 	BB0_1307;
	bra.uni 	BB0_131;

BB0_1307:
	and.b32  	%r8848, %r8848, %r1255;
	mov.u32 	%r8845, 0;
	mov.u32 	%r8846, %r8845;
	mov.u32 	%r8847, %r8845;
	bra.uni 	BB0_1305;

BB0_382:
	setp.gt.s32	%p272, %r3522, 5;
	@%p272 bra 	BB0_386;

	setp.eq.s32	%p275, %r3522, 4;
	@%p275 bra 	BB0_390;
	bra.uni 	BB0_384;

BB0_390:
	and.b32  	%r3538, %r15, %r362;
	and.b32  	%r3539, %r361, %r15;
	sub.s32 	%r3540, %r3539, %r363;
	and.b32  	%r3541, %r3540, %r361;
	or.b32  	%r8852, %r3541, %r3538;
	bra.uni 	BB0_658;

BB0_1038:
	setp.gt.s32	%p697, %r4901, 5;
	@%p697 bra 	BB0_1042;

	setp.eq.s32	%p700, %r4901, 4;
	@%p700 bra 	BB0_1046;
	bra.uni 	BB0_1040;

BB0_1046:
	and.b32  	%r4916, %r932, %r15;
	or.b32  	%r4917, %r4916, %r931;
	and.b32  	%r4918, %r8852, %r933;
	or.b32  	%r8852, %r4917, %r4918;
	mov.u32 	%r8845, %r22;
	bra.uni 	BB0_1047;

BB0_1539:
	setp.gt.s32	%p1021, %r8061, 5;
	@%p1021 bra 	BB0_1543;

	setp.eq.s32	%p1024, %r8061, 4;
	@%p1024 bra 	BB0_1547;
	bra.uni 	BB0_1541;

BB0_1547:
	and.b32  	%r8104, %r15, 1077952576;
	shr.u32 	%r8105, %r8104, 1;
	and.b32  	%r8106, %r15, -2139062144;
	shr.u32 	%r8107, %r8106, 2;
	not.b32 	%r8108, %r8107;
	and.b32  	%r8109, %r8105, %r8108;
	and.b32  	%r8110, %r15, 522133279;
	add.s32 	%r8111, %r8110, 522133279;
	mov.u32 	%r8112, -84215046;
	sub.s32 	%r8113, %r8112, %r8110;
	and.b32  	%r8114, %r8109, %r8113;
	and.b32  	%r8115, %r8114, %r8111;
	and.b32  	%r8116, %r8115, %r1710;
	xor.b32  	%r8852, %r8116, %r15;
	bra.uni 	BB0_658;

BB0_1192:
	setp.gt.s32	%p772, %r24, 23;
	@%p772 bra 	BB0_1208;

	setp.gt.s32	%p784, %r24, 19;
	@%p784 bra 	BB0_1201;

	setp.gt.s32	%p790, %r24, 17;
	@%p790 bra 	BB0_1198;

	setp.eq.s32	%p793, %r24, 16;
	@%p793 bra 	BB0_1230;
	bra.uni 	BB0_1196;

BB0_1230:
	mov.u32 	%r8849, 0;
	mov.u32 	%r8845, %r18;
	mov.u32 	%r8846, %r17;
	mov.u32 	%r8847, %r16;
	mov.u32 	%r22, %r15;
	bra.uni 	BB0_1231;

BB0_1475:
	setp.gt.s32	%p975, %r7499, 23;
	@%p975 bra 	BB0_1492;

	setp.gt.s32	%p987, %r7499, 19;
	@%p987 bra 	BB0_1484;

	setp.gt.s32	%p993, %r7499, 17;
	@%p993 bra 	BB0_1481;

	setp.eq.s32	%p996, %r7499, 16;
	@%p996 bra 	BB0_1516;
	bra.uni 	BB0_1479;

BB0_1516:
	mov.u32 	%r8837, 0;
	mov.u32 	%r8838, %r8837;
	mov.u32 	%r8839, %r8837;
	mov.u32 	%r8840, %r8837;
	mov.u32 	%r18, %r22;
	mov.u32 	%r17, %r21;
	mov.u32 	%r16, %r20;
	bra.uni 	BB0_1529;

BB0_402:
	setp.gt.s32	%p284, %r3558, 5;
	@%p284 bra 	BB0_406;

	setp.eq.s32	%p287, %r3558, 4;
	@%p287 bra 	BB0_410;
	bra.uni 	BB0_404;

BB0_410:
	and.b32  	%r3574, %r15, %r373;
	and.b32  	%r3575, %r372, %r15;
	add.s32 	%r3576, %r3575, %r374;
	and.b32  	%r3577, %r3576, %r372;
	or.b32  	%r8852, %r3577, %r3574;
	bra.uni 	BB0_658;

BB0_1086:
	setp.gt.s32	%p711, %r26, 23;
	@%p711 bra 	BB0_1102;

	setp.gt.s32	%p723, %r26, 19;
	@%p723 bra 	BB0_1095;

	setp.gt.s32	%p729, %r26, 17;
	@%p729 bra 	BB0_1092;

	setp.eq.s32	%p732, %r26, 16;
	@%p732 bra 	BB0_1128;
	bra.uni 	BB0_1090;

BB0_1128:
	mov.u32 	%r8845, %r18;
	mov.u32 	%r8846, %r17;
	mov.u32 	%r8847, %r16;
	mov.u32 	%r8766, %r15;
	bra.uni 	BB0_1122;

BB0_1013:
	setp.gt.s32	%p683, %r4860, 5;
	@%p683 bra 	BB0_1018;

	setp.eq.s32	%p686, %r4860, 4;
	@%p686 bra 	BB0_1024;
	bra.uni 	BB0_1015;

BB0_1024:
	and.b32  	%r4868, %r15, %r914;
	or.b32  	%r8852, %r4868, %r913;
	bra.uni 	BB0_658;

BB0_481:
	setp.gt.s32	%p322, %r24, 23;
	@%p322 bra 	BB0_497;

	setp.gt.s32	%p334, %r24, 19;
	@%p334 bra 	BB0_490;

	setp.gt.s32	%p340, %r24, 17;
	@%p340 bra 	BB0_487;

	setp.eq.s32	%p343, %r24, 16;
	@%p343 bra 	BB0_519;
	bra.uni 	BB0_485;

BB0_519:
	and.b32  	%r8720, %r15, 255;
	bra.uni 	BB0_528;

BB0_1439:
	setp.gt.s32	%p964, %r7320, 5;
	@%p964 bra 	BB0_1443;

	setp.eq.s32	%p967, %r7320, 4;
	@%p967 bra 	BB0_1447;
	bra.uni 	BB0_1441;

BB0_1447:
	// inline asm
	prmt.b32 %r8836, %r21, %r22, %r1533;
	// inline asm
	// inline asm
	prmt.b32 %r8835, %r20, %r21, %r1533;
	// inline asm
	// inline asm
	prmt.b32 %r8834, %r19, %r20, %r1533;
	// inline asm
	mov.u32 	%r8829, 0;
	// inline asm
	prmt.b32 %r8833, %r8829, %r19, %r1533;
	// inline asm
	mov.u32 	%r8830, %r8829;
	mov.u32 	%r8831, %r8829;
	mov.u32 	%r8832, %r8829;
	bra.uni 	BB0_1450;

BB0_437:
	setp.gt.s32	%p308, %r3630, 5;
	@%p308 bra 	BB0_441;

	setp.eq.s32	%p311, %r3630, 4;
	@%p311 bra 	BB0_445;
	bra.uni 	BB0_439;

BB0_445:
	and.b32  	%r3646, %r15, %r394;
	and.b32  	%r3647, %r393, %r15;
	shl.b32 	%r3648, %r3647, 1;
	and.b32  	%r3649, %r3648, %r393;
	or.b32  	%r8852, %r3649, %r3646;
	bra.uni 	BB0_658;

BB0_819:
	setp.gt.s32	%p535, %r24, 23;
	@%p535 bra 	BB0_836;

	setp.gt.s32	%p547, %r24, 19;
	@%p547 bra 	BB0_828;

	setp.gt.s32	%p553, %r24, 17;
	@%p553 bra 	BB0_825;

	setp.eq.s32	%p556, %r24, 16;
	@%p556 bra 	BB0_860;
	bra.uni 	BB0_823;

BB0_860:
	mov.u32 	%r8845, 0;
	mov.u32 	%r8846, %r8845;
	mov.u32 	%r8847, %r8845;
	mov.u32 	%r8848, %r8845;
	mov.u32 	%r18, %r22;
	mov.u32 	%r17, %r21;
	mov.u32 	%r16, %r20;
	mov.u32 	%r15, %r19;
	bra.uni 	BB0_874;

BB0_379:
	setp.eq.s32	%p278, %r3522, 2;
	@%p278 bra 	BB0_391;
	bra.uni 	BB0_380;

BB0_391:
	and.b32  	%r3546, %r21, %r362;
	and.b32  	%r3547, %r361, %r21;
	sub.s32 	%r3548, %r3547, %r363;
	and.b32  	%r3549, %r3548, %r361;
	or.b32  	%r8846, %r3549, %r3546;
	bra.uni 	BB0_634;

BB0_1035:
	setp.eq.s32	%p703, %r4901, 2;
	@%p703 bra 	BB0_1049;
	bra.uni 	BB0_1036;

BB0_1049:
	and.b32  	%r4922, %r932, %r21;
	or.b32  	%r4923, %r4922, %r931;
	and.b32  	%r4924, %r8846, %r933;
	or.b32  	%r8846, %r4923, %r4924;
	bra.uni 	BB0_1048;

BB0_1536:
	setp.eq.s32	%p1027, %r8061, 2;
	@%p1027 bra 	BB0_1548;
	bra.uni 	BB0_1537;

BB0_1548:
	and.b32  	%r8130, %r21, 1077952576;
	shr.u32 	%r8131, %r8130, 1;
	and.b32  	%r8132, %r21, -2139062144;
	shr.u32 	%r8133, %r8132, 2;
	not.b32 	%r8134, %r8133;
	and.b32  	%r8135, %r8131, %r8134;
	and.b32  	%r8136, %r21, 522133279;
	add.s32 	%r8137, %r8136, 522133279;
	mov.u32 	%r8138, -84215046;
	sub.s32 	%r8139, %r8138, %r8136;
	and.b32  	%r8140, %r8135, %r8139;
	and.b32  	%r8141, %r8140, %r8137;
	and.b32  	%r8142, %r8141, %r1710;
	xor.b32  	%r8846, %r8142, %r21;
	bra.uni 	BB0_1026;

BB0_1177:
	setp.gt.s32	%p796, %r24, 11;
	@%p796 bra 	BB0_1185;

	setp.gt.s32	%p802, %r24, 9;
	@%p802 bra 	BB0_1182;

	setp.eq.s32	%p805, %r24, 8;
	@%p805 bra 	BB0_1237;
	bra.uni 	BB0_1180;

BB0_1237:
	mov.u32 	%r8849, 0;
	mov.u32 	%r8845, %r16;
	mov.u32 	%r8846, %r15;
	mov.u32 	%r8847, %r22;
	mov.u32 	%r22, %r21;
	mov.u32 	%r8850, %r8849;
	mov.u32 	%r8851, %r18;
	mov.u32 	%r18, %r17;
	bra.uni 	BB0_1245;

BB0_987:
	setp.gt.s32	%p671, %r4827, 5;
	@%p671 bra 	BB0_991;

	setp.eq.s32	%p674, %r4827, 4;
	@%p674 bra 	BB0_997;
	bra.uni 	BB0_989;

BB0_997:
	and.b32  	%r8852, %r904, %r15;
	mov.u32 	%r8849, 0;
	mov.u32 	%r8845, %r22;
	mov.u32 	%r8846, %r21;
	mov.u32 	%r8847, %r20;
	mov.u32 	%r8848, %r19;
	mov.u32 	%r8850, %r8849;
	mov.u32 	%r8851, %r8849;
	mov.u32 	%r8853, %r24;
	bra.uni 	BB0_1554;

BB0_724:
	setp.gt.s32	%p464, %r14, 23;
	@%p464 bra 	BB0_738;

	setp.gt.s32	%p476, %r14, 19;
	@%p476 bra 	BB0_730;

	setp.eq.s32	%p482, %r14, 17;
	@%p482 bra 	BB0_766;

	setp.eq.s32	%p483, %r14, 18;
	@%p483 bra 	BB0_762;
	bra.uni 	BB0_728;

BB0_762:
	shl.b32 	%r3835, %r15, 8;
	and.b32  	%r3836, %r3835, 65280;
	bfe.u32 	%r3837, %r15, 8, 8;
	or.b32  	%r8852, %r3836, %r3837;
	mov.u32 	%r8853, 18;
	bra.uni 	BB0_763;

BB0_1460:
	setp.gt.s32	%p999, %r7499, 11;
	@%p999 bra 	BB0_1468;

	setp.gt.s32	%p1005, %r7499, 9;
	@%p1005 bra 	BB0_1465;

	setp.eq.s32	%p1008, %r7499, 8;
	@%p1008 bra 	BB0_1520;
	bra.uni 	BB0_1463;

BB0_1520:
	mov.u32 	%r8839, 0;
	mov.u32 	%r8837, %r20;
	mov.u32 	%r8838, %r19;
	mov.u32 	%r8840, %r8839;
	mov.u32 	%r18, %r16;
	mov.u32 	%r17, %r15;
	mov.u32 	%r16, %r22;
	mov.u32 	%r19, %r21;
	bra.uni 	BB0_1529;

BB0_363:
	setp.gt.s32	%p260, %r3498, 5;
	@%p260 bra 	BB0_367;

	setp.eq.s32	%p263, %r3498, 4;
	@%p263 bra 	BB0_371;
	bra.uni 	BB0_365;

BB0_371:
	and.b32  	%r3512, %r15, %r352;
	and.b32  	%r3513, %r3486, %r351;
	or.b32  	%r8852, %r3513, %r3512;
	bra.uni 	BB0_658;

BB0_163:
	setp.gt.s32	%p128, %r24, 23;
	@%p128 bra 	BB0_181;

	setp.gt.s32	%p140, %r24, 19;
	@%p140 bra 	BB0_173;

	setp.gt.s32	%p146, %r24, 17;
	@%p146 bra 	BB0_169;

	setp.eq.s32	%p149, %r24, 16;
	@%p149 bra 	BB0_207;
	bra.uni 	BB0_167;

BB0_207:
	mov.u32 	%r8688, %r8691;
	mov.u32 	%r8689, %r8691;
	mov.u32 	%r8690, %r8691;
	mov.u32 	%r8692, %r22;
	mov.u32 	%r8693, %r21;
	mov.u32 	%r8694, %r20;
	mov.u32 	%r8695, %r19;
	bra.uni 	BB0_215;

BB0_241:
	setp.gt.s32	%p189, %r2840, 5;
	@%p189 bra 	BB0_245;

	setp.eq.s32	%p192, %r2840, 4;
	@%p192 bra 	BB0_250;
	bra.uni 	BB0_243;

BB0_250:
	and.b32  	%r8711, %r186, %r15;
	mov.u32 	%r8708, 0;
	mov.u32 	%r8704, %r22;
	mov.u32 	%r8705, %r21;
	mov.u32 	%r8706, %r20;
	mov.u32 	%r8707, %r19;
	mov.u32 	%r8709, %r8708;
	mov.u32 	%r8710, %r8708;
	bra.uni 	BB0_254;

BB0_386:
	setp.eq.s32	%p273, %r3522, 6;
	@%p273 bra 	BB0_389;
	bra.uni 	BB0_387;

BB0_389:
	and.b32  	%r3530, %r17, %r362;
	and.b32  	%r3531, %r361, %r17;
	sub.s32 	%r3532, %r3531, %r363;
	and.b32  	%r3533, %r3532, %r361;
	or.b32  	%r8850, %r3533, %r3530;
	bra.uni 	BB0_675;

BB0_1042:
	setp.eq.s32	%p698, %r4901, 6;
	@%p698 bra 	BB0_1045;
	bra.uni 	BB0_1043;

BB0_1045:
	and.b32  	%r4910, %r932, %r17;
	or.b32  	%r4911, %r4910, %r931;
	and.b32  	%r4912, %r8850, %r933;
	or.b32  	%r8850, %r4911, %r4912;
	mov.u32 	%r8845, %r22;
	mov.u32 	%r8846, %r21;
	mov.u32 	%r8847, %r20;
	mov.u32 	%r8848, %r19;
	bra.uni 	BB0_773;

BB0_1543:
	setp.eq.s32	%p1022, %r8061, 6;
	@%p1022 bra 	BB0_1546;
	bra.uni 	BB0_1544;

BB0_1546:
	and.b32  	%r8078, %r17, 1077952576;
	shr.u32 	%r8079, %r8078, 1;
	and.b32  	%r8080, %r17, -2139062144;
	shr.u32 	%r8081, %r8080, 2;
	not.b32 	%r8082, %r8081;
	and.b32  	%r8083, %r8079, %r8082;
	and.b32  	%r8084, %r17, 522133279;
	add.s32 	%r8085, %r8084, 522133279;
	mov.u32 	%r8086, -84215046;
	sub.s32 	%r8087, %r8086, %r8084;
	and.b32  	%r8088, %r8083, %r8087;
	and.b32  	%r8089, %r8088, %r8085;
	and.b32  	%r8090, %r8089, %r1710;
	xor.b32  	%r8850, %r8090, %r17;
	bra.uni 	BB0_1023;

BB0_1208:
	setp.gt.s32	%p773, %r24, 27;
	@%p773 bra 	BB0_1217;

	setp.gt.s32	%p779, %r24, 25;
	@%p779 bra 	BB0_1213;

	setp.eq.s32	%p782, %r24, 24;
	@%p782 bra 	BB0_1226;
	bra.uni 	BB0_1211;

BB0_1226:
	mov.u32 	%r8845, 0;
	mov.u32 	%r8846, %r8845;
	mov.u32 	%r8847, %r18;
	mov.u32 	%r22, %r17;
	bra.uni 	BB0_1244;

BB0_1492:
	setp.gt.s32	%p976, %r7499, 27;
	@%p976 bra 	BB0_1501;

	setp.gt.s32	%p982, %r7499, 25;
	@%p982 bra 	BB0_1497;

	setp.eq.s32	%p985, %r7499, 24;
	@%p985 bra 	BB0_1510;
	bra.uni 	BB0_1495;

BB0_1510:
	mov.u32 	%r8837, 0;
	mov.u32 	%r8838, %r8837;
	mov.u32 	%r8839, %r8837;
	mov.u32 	%r8840, %r8837;
	mov.u32 	%r18, %r20;
	mov.u32 	%r17, %r19;
	bra.uni 	BB0_1527;

BB0_399:
	setp.eq.s32	%p290, %r3558, 2;
	@%p290 bra 	BB0_411;
	bra.uni 	BB0_400;

BB0_411:
	and.b32  	%r3582, %r21, %r373;
	and.b32  	%r3583, %r372, %r21;
	add.s32 	%r3584, %r3583, %r374;
	and.b32  	%r3585, %r3584, %r372;
	or.b32  	%r8846, %r3585, %r3582;
	bra.uni 	BB0_634;

BB0_1070:
	setp.gt.s32	%p735, %r26, 11;
	@%p735 bra 	BB0_1078;

	setp.gt.s32	%p741, %r26, 9;
	@%p741 bra 	BB0_1075;

	setp.eq.s32	%p744, %r26, 8;
	@%p744 bra 	BB0_1132;
	bra.uni 	BB0_1073;

BB0_1132:
	mov.u32 	%r8845, %r16;
	mov.u32 	%r8846, %r15;
	mov.u32 	%r8847, %r22;
	mov.u32 	%r8766, %r21;
	mov.u32 	%r8850, %r8849;
	mov.u32 	%r8851, %r18;
	mov.u32 	%r8852, %r17;
	bra.uni 	BB0_1137;

BB0_1010:
	setp.eq.s32	%p689, %r4860, 2;
	@%p689 bra 	BB0_1025;
	bra.uni 	BB0_1011;

BB0_1025:
	and.b32  	%r4870, %r21, %r914;
	or.b32  	%r8846, %r4870, %r913;

BB0_1026:
	mov.u32 	%r8845, %r22;
	bra.uni 	BB0_13;

BB0_466:
	setp.gt.s32	%p346, %r24, 11;
	@%p346 bra 	BB0_474;

	setp.gt.s32	%p352, %r24, 9;
	@%p352 bra 	BB0_471;

	setp.eq.s32	%p355, %r24, 8;
	@%p355 bra 	BB0_523;
	bra.uni 	BB0_469;

BB0_523:
	and.b32  	%r8720, %r21, 255;
	bra.uni 	BB0_528;

BB0_347:
	setp.gt.s32	%p248, %r3445, 5;
	@%p248 bra 	BB0_351;

	setp.eq.s32	%p251, %r3445, 4;
	@%p251 bra 	BB0_355;
	bra.uni 	BB0_349;

BB0_355:
	and.b32  	%r3455, %r15, %r335;
	and.b32  	%r3456, %r3429, %r334;
	or.b32  	%r8852, %r3456, %r3455;
	bra.uni 	BB0_658;

BB0_1436:
	setp.eq.s32	%p970, %r7320, 2;
	@%p970 bra 	BB0_1448;
	bra.uni 	BB0_1437;

BB0_1448:
	// inline asm
	prmt.b32 %r8836, %r15, %r16, %r1533;
	// inline asm
	// inline asm
	prmt.b32 %r8835, %r22, %r15, %r1533;
	// inline asm
	// inline asm
	prmt.b32 %r8834, %r21, %r22, %r1533;
	// inline asm
	// inline asm
	prmt.b32 %r8833, %r20, %r21, %r1533;
	// inline asm
	// inline asm
	prmt.b32 %r8832, %r19, %r20, %r1533;
	// inline asm
	mov.u32 	%r8829, 0;
	// inline asm
	prmt.b32 %r8831, %r8829, %r19, %r1533;
	// inline asm
	mov.u32 	%r8830, %r8829;
	bra.uni 	BB0_1450;

BB0_1342:
	setp.gt.s32	%p890, %r6374, 23;
	@%p890 bra 	BB0_1360;

	setp.gt.s32	%p902, %r6374, 19;
	@%p902 bra 	BB0_1352;

	setp.gt.s32	%p908, %r6374, 17;
	@%p908 bra 	BB0_1348;

	setp.eq.s32	%p911, %r6374, 16;
	@%p911 bra 	BB0_1386;
	bra.uni 	BB0_1346;

BB0_1386:
	mov.u32 	%r8795, %r8803;
	mov.u32 	%r8796, %r8803;
	mov.u32 	%r8797, %r8803;
	mov.u32 	%r8798, %r8803;
	mov.u32 	%r8799, %r22;
	mov.u32 	%r8800, %r21;
	mov.u32 	%r8801, %r20;
	mov.u32 	%r8802, %r19;
	bra.uni 	BB0_1394;

BB0_434:
	setp.eq.s32	%p314, %r3630, 2;
	@%p314 bra 	BB0_446;
	bra.uni 	BB0_435;

BB0_446:
	and.b32  	%r3654, %r21, %r394;
	and.b32  	%r3655, %r393, %r21;
	shl.b32 	%r3656, %r3655, 1;
	and.b32  	%r3657, %r3656, %r393;
	or.b32  	%r8846, %r3657, %r3654;
	bra.uni 	BB0_634;

BB0_418:
	setp.gt.s32	%p296, %r3594, 5;
	@%p296 bra 	BB0_422;

	setp.eq.s32	%p299, %r3594, 4;
	@%p299 bra 	BB0_426;
	bra.uni 	BB0_420;

BB0_426:
	and.b32  	%r3610, %r15, %r384;
	and.b32  	%r3611, %r383, %r15;
	shr.u32 	%r3612, %r3611, 1;
	and.b32  	%r3613, %r3612, %r383;
	or.b32  	%r8852, %r3613, %r3610;
	bra.uni 	BB0_658;

BB0_955:
	setp.eq.s32	%p627, %r863, 2;
	mov.u32 	%r8853, 0;
	@%p627 bra 	BB0_956;
	bra.uni 	BB0_957;

BB0_956:
	mov.u32 	%r8748, %r8853;
	bra.uni 	BB0_959;

BB0_1273:
	setp.gt.s32	%p829, %r6119, 5;
	@%p829 bra 	BB0_1279;

	setp.eq.s32	%p832, %r6119, 4;
	@%p832 bra 	BB0_1286;
	bra.uni 	BB0_1275;

BB0_1286:
	and.b32  	%r6130, %r1210, %r15;
	and.b32  	%r6131, %r8852, %r1211;
	or.b32  	%r8852, %r6131, %r6130;
	mov.u32 	%r8845, %r22;
	bra.uni 	BB0_1287;

BB0_803:
	setp.gt.s32	%p559, %r24, 11;
	@%p559 bra 	BB0_811;

	setp.gt.s32	%p565, %r24, 9;
	@%p565 bra 	BB0_808;

	setp.eq.s32	%p568, %r24, 8;
	@%p568 bra 	BB0_864;
	bra.uni 	BB0_806;

BB0_864:
	mov.u32 	%r8847, 0;
	mov.u32 	%r8845, %r20;
	mov.u32 	%r8846, %r19;
	mov.u32 	%r8848, %r8847;
	mov.u32 	%r18, %r16;
	mov.u32 	%r17, %r15;
	mov.u32 	%r16, %r22;
	mov.u32 	%r15, %r21;
	bra.uni 	BB0_874;

BB0_1295:
	setp.gt.s32	%p859, %r6221, 5;
	@%p859 bra 	BB0_1299;

	setp.eq.s32	%p862, %r6221, 4;
	@%p862 bra 	BB0_1303;
	bra.uni 	BB0_1297;

BB0_1303:
	and.b32  	%r8852, %r8852, %r1255;
	mov.u32 	%r8849, 0;
	mov.u32 	%r8850, %r8849;
	mov.u32 	%r8851, %r8849;
	bra.uni 	BB0_1553;

BB0_406:
	setp.eq.s32	%p285, %r3558, 6;
	@%p285 bra 	BB0_409;
	bra.uni 	BB0_407;

BB0_409:
	and.b32  	%r3566, %r17, %r373;
	and.b32  	%r3567, %r372, %r17;
	add.s32 	%r3568, %r3567, %r374;
	and.b32  	%r3569, %r3568, %r372;
	or.b32  	%r8850, %r3569, %r3566;
	bra.uni 	BB0_675;

BB0_1102:
	setp.gt.s32	%p712, %r26, 27;
	@%p712 bra 	BB0_1112;

	setp.gt.s32	%p718, %r26, 25;
	@%p718 bra 	BB0_1107;

	setp.eq.s32	%p721, %r26, 24;
	@%p721 bra 	BB0_1124;
	bra.uni 	BB0_1105;

BB0_1124:
	mov.u32 	%r8845, %r8849;
	mov.u32 	%r8846, %r8849;
	mov.u32 	%r8847, %r18;
	mov.u32 	%r8766, %r17;
	bra.uni 	BB0_1122;

BB0_1018:
	setp.eq.s32	%p684, %r4860, 6;
	@%p684 bra 	BB0_1022;
	bra.uni 	BB0_1019;

BB0_1022:
	and.b32  	%r4866, %r17, %r914;
	or.b32  	%r8850, %r4866, %r913;

BB0_1023:
	mov.u32 	%r8845, %r22;
	mov.u32 	%r8846, %r21;
	mov.u32 	%r8847, %r20;
	mov.u32 	%r8848, %r19;
	mov.u32 	%r8849, %r18;
	bra.uni 	BB0_17;

BB0_497:
	setp.gt.s32	%p323, %r24, 27;
	@%p323 bra 	BB0_505;

	setp.gt.s32	%p329, %r24, 25;
	@%p329 bra 	BB0_502;

	setp.eq.s32	%p332, %r24, 24;
	@%p332 bra 	BB0_515;
	bra.uni 	BB0_500;

BB0_515:
	and.b32  	%r8720, %r17, 255;
	bra.uni 	BB0_528;

BB0_1443:
	setp.eq.s32	%p965, %r7320, 6;
	@%p965 bra 	BB0_1446;
	bra.uni 	BB0_1444;

BB0_1446:
	// inline asm
	prmt.b32 %r8836, %r19, %r20, %r1533;
	// inline asm
	mov.u32 	%r8829, 0;
	// inline asm
	prmt.b32 %r8835, %r8829, %r19, %r1533;
	// inline asm
	mov.u32 	%r8830, %r8829;
	mov.u32 	%r8831, %r8829;
	mov.u32 	%r8832, %r8829;
	mov.u32 	%r8833, %r8829;
	mov.u32 	%r8834, %r8829;
	bra.uni 	BB0_1450;

BB0_441:
	setp.eq.s32	%p309, %r3630, 6;
	@%p309 bra 	BB0_444;
	bra.uni 	BB0_442;

BB0_444:
	and.b32  	%r3638, %r17, %r394;
	and.b32  	%r3639, %r393, %r17;
	shl.b32 	%r3640, %r3639, 1;
	and.b32  	%r3641, %r3640, %r393;
	or.b32  	%r8850, %r3641, %r3638;
	bra.uni 	BB0_675;

BB0_836:
	setp.gt.s32	%p536, %r24, 27;
	@%p536 bra 	BB0_845;

	setp.gt.s32	%p542, %r24, 25;
	@%p542 bra 	BB0_841;

	setp.eq.s32	%p545, %r24, 24;
	@%p545 bra 	BB0_854;
	bra.uni 	BB0_839;

BB0_854:
	mov.u32 	%r8845, 0;
	mov.u32 	%r8846, %r8845;
	mov.u32 	%r8847, %r8845;
	mov.u32 	%r8848, %r8845;
	mov.u32 	%r18, %r20;
	mov.u32 	%r17, %r19;
	bra.uni 	BB0_872;

BB0_377:
	setp.eq.s32	%p281, %r3522, 1;
	@%p281 bra 	BB0_378;
	bra.uni 	BB0_11;

BB0_378:
	and.b32  	%r3550, %r20, %r362;
	and.b32  	%r3551, %r361, %r20;
	sub.s32 	%r3552, %r3551, %r363;
	and.b32  	%r3553, %r3552, %r361;
	or.b32  	%r8847, %r3553, %r3550;
	bra.uni 	BB0_625;

BB0_1033:
	setp.eq.s32	%p706, %r4901, 1;
	@%p706 bra 	BB0_1050;
	bra.uni 	BB0_1034;

BB0_1050:
	and.b32  	%r4925, %r932, %r20;
	or.b32  	%r4926, %r4925, %r931;
	and.b32  	%r4927, %r8847, %r933;
	or.b32  	%r8847, %r4926, %r4927;
	mov.u32 	%r8848, %r19;
	bra.uni 	BB0_1554;

BB0_1534:
	setp.eq.s32	%p1030, %r8061, 1;
	@%p1030 bra 	BB0_1535;
	bra.uni 	BB0_978;

BB0_1535:
	and.b32  	%r8143, %r20, 1077952576;
	shr.u32 	%r8144, %r8143, 1;
	and.b32  	%r8145, %r20, -2139062144;
	shr.u32 	%r8146, %r8145, 2;
	not.b32 	%r8147, %r8146;
	and.b32  	%r8148, %r8144, %r8147;
	and.b32  	%r8149, %r20, 522133279;
	add.s32 	%r8150, %r8149, 522133279;
	mov.u32 	%r8151, -84215046;
	sub.s32 	%r8152, %r8151, %r8149;
	and.b32  	%r8153, %r8148, %r8152;
	and.b32  	%r8154, %r8153, %r8150;
	and.b32  	%r8155, %r8154, %r1710;
	xor.b32  	%r8847, %r8155, %r20;
	bra.uni 	BB0_1009;

BB0_1170:
	setp.gt.s32	%p808, %r24, 5;
	@%p808 bra 	BB0_1174;

	setp.eq.s32	%p811, %r24, 4;
	@%p811 bra 	BB0_1239;
	bra.uni 	BB0_1172;

BB0_1239:
	mov.u32 	%r8849, 0;
	mov.u32 	%r8845, %r15;
	mov.u32 	%r8846, %r22;
	mov.u32 	%r8847, %r21;
	mov.u32 	%r22, %r20;
	mov.u32 	%r8850, %r18;
	mov.u32 	%r8851, %r17;
	mov.u32 	%r18, %r16;
	bra.uni 	BB0_1245;

BB0_984:
	setp.eq.s32	%p677, %r4827, 2;
	@%p677 bra 	BB0_998;
	bra.uni 	BB0_985;

BB0_998:
	and.b32  	%r8846, %r904, %r21;
	mov.u32 	%r8845, 0;
	mov.u32 	%r8847, %r20;
	bra.uni 	BB0_999;

BB0_709:
	setp.gt.s32	%p486, %r14, 12;
	@%p486 bra 	BB0_717;

	setp.gt.s32	%p492, %r14, 10;
	@%p492 bra 	BB0_714;

	setp.eq.s32	%p495, %r14, 9;
	@%p495 bra 	BB0_777;
	bra.uni 	BB0_712;

BB0_777:
	or.b32  	%r3881, %r20, %r21;
	and.b32  	%r3882, %r20, 16777215;
	prmt.b32 	%r8847, %r21, %r3882, 1620;
	shr.u32 	%r8846, %r3881, 24;
	mov.u32 	%r8853, 9;
	mov.u32 	%r8845, %r22;
	bra.uni 	BB0_770;

BB0_1453:
	setp.gt.s32	%p1011, %r7499, 5;
	@%p1011 bra 	BB0_1457;

	setp.eq.s32	%p1014, %r7499, 4;
	@%p1014 bra 	BB0_1522;
	bra.uni 	BB0_1455;

BB0_1522:
	mov.u32 	%r8840, 0;
	mov.u32 	%r8837, %r21;
	mov.u32 	%r8838, %r20;
	mov.u32 	%r8839, %r19;
	mov.u32 	%r18, %r17;
	mov.u32 	%r17, %r16;
	mov.u32 	%r16, %r15;
	mov.u32 	%r19, %r22;
	bra.uni 	BB0_1529;

BB0_360:
	setp.eq.s32	%p266, %r3498, 2;
	@%p266 bra 	BB0_372;
	bra.uni 	BB0_361;

BB0_372:
	and.b32  	%r3516, %r21, %r352;
	and.b32  	%r3517, %r3478, %r351;
	or.b32  	%r8846, %r3517, %r3516;
	bra.uni 	BB0_634;

BB0_147:
	setp.gt.s32	%p152, %r24, 11;
	@%p152 bra 	BB0_155;

	setp.gt.s32	%p158, %r24, 9;
	@%p158 bra 	BB0_152;

	setp.eq.s32	%p161, %r24, 8;
	@%p161 bra 	BB0_211;
	bra.uni 	BB0_150;

BB0_211:
	mov.u32 	%r8688, %r20;
	mov.u32 	%r8689, %r19;
	mov.u32 	%r8690, %r8691;
	mov.u32 	%r8692, %r16;
	mov.u32 	%r8693, %r15;
	mov.u32 	%r8694, %r22;
	mov.u32 	%r8695, %r21;
	bra.uni 	BB0_215;

BB0_238:
	setp.eq.s32	%p195, %r2840, 2;
	@%p195 bra 	BB0_251;
	bra.uni 	BB0_239;

BB0_251:
	and.b32  	%r8705, %r186, %r21;
	mov.u32 	%r8704, 0;
	mov.u32 	%r8706, %r20;
	bra.uni 	BB0_252;

BB0_384:
	setp.eq.s32	%p276, %r3522, 5;
	@%p276 bra 	BB0_385;
	bra.uni 	BB0_11;

BB0_385:
	and.b32  	%r3534, %r16, %r362;
	and.b32  	%r3535, %r361, %r16;
	sub.s32 	%r3536, %r3535, %r363;
	and.b32  	%r3537, %r3536, %r361;
	or.b32  	%r8851, %r3537, %r3534;
	bra.uni 	BB0_666;

BB0_1040:
	setp.eq.s32	%p701, %r4901, 5;
	@%p701 bra 	BB0_1041;
	bra.uni 	BB0_1034;

BB0_1041:
	and.b32  	%r4913, %r932, %r16;
	or.b32  	%r4914, %r4913, %r931;
	and.b32  	%r4915, %r8851, %r933;
	or.b32  	%r8851, %r4914, %r4915;
	mov.u32 	%r8845, %r22;
	mov.u32 	%r8846, %r21;
	mov.u32 	%r8847, %r20;
	mov.u32 	%r8848, %r19;
	mov.u32 	%r8852, %r15;
	bra.uni 	BB0_1554;

BB0_1541:
	setp.eq.s32	%p1025, %r8061, 5;
	@%p1025 bra 	BB0_1542;
	bra.uni 	BB0_978;

BB0_1542:
	and.b32  	%r8091, %r16, 1077952576;
	shr.u32 	%r8092, %r8091, 1;
	and.b32  	%r8093, %r16, -2139062144;
	shr.u32 	%r8094, %r8093, 2;
	not.b32 	%r8095, %r8094;
	and.b32  	%r8096, %r8092, %r8095;
	and.b32  	%r8097, %r16, 522133279;
	add.s32 	%r8098, %r8097, 522133279;
	mov.u32 	%r8099, -84215046;
	sub.s32 	%r8100, %r8099, %r8097;
	and.b32  	%r8101, %r8096, %r8100;
	and.b32  	%r8102, %r8101, %r8098;
	and.b32  	%r8103, %r8102, %r1710;
	xor.b32  	%r8851, %r8103, %r16;
	bra.uni 	BB0_1017;

BB0_1201:
	setp.gt.s32	%p785, %r24, 21;
	@%p785 bra 	BB0_1205;

	setp.eq.s32	%p788, %r24, 20;
	@%p788 bra 	BB0_1228;
	bra.uni 	BB0_1203;

BB0_1228:
	mov.u32 	%r8845, 0;
	mov.u32 	%r8846, %r18;
	mov.u32 	%r8847, %r17;
	mov.u32 	%r22, %r16;
	bra.uni 	BB0_1244;

BB0_1484:
	setp.gt.s32	%p988, %r7499, 21;
	@%p988 bra 	BB0_1488;

	setp.eq.s32	%p991, %r7499, 20;
	@%p991 bra 	BB0_1512;
	bra.uni 	BB0_1486;

BB0_1512:
	mov.u32 	%r8837, 0;
	mov.u32 	%r8838, %r8837;
	mov.u32 	%r8839, %r8837;
	mov.u32 	%r8840, %r8837;
	mov.u32 	%r18, %r21;
	mov.u32 	%r17, %r20;
	mov.u32 	%r16, %r19;
	bra.uni 	BB0_1528;

BB0_380:
	setp.eq.s32	%p279, %r3522, 3;
	@%p279 bra 	BB0_381;
	bra.uni 	BB0_11;

BB0_381:
	and.b32  	%r3542, %r22, %r362;
	and.b32  	%r3543, %r361, %r22;
	sub.s32 	%r3544, %r3543, %r363;
	and.b32  	%r3545, %r3544, %r361;
	or.b32  	%r8845, %r3545, %r3542;
	bra.uni 	BB0_642;

BB0_1036:
	setp.eq.s32	%p704, %r4901, 3;
	@%p704 bra 	BB0_1037;
	bra.uni 	BB0_1034;

BB0_1037:
	and.b32  	%r4919, %r932, %r22;
	or.b32  	%r4920, %r4919, %r931;
	and.b32  	%r4921, %r8845, %r933;
	or.b32  	%r8845, %r4920, %r4921;

BB0_1047:
	mov.u32 	%r8846, %r21;

BB0_1048:
	mov.u32 	%r8847, %r20;
	mov.u32 	%r8848, %r19;
	bra.uni 	BB0_1554;

BB0_1537:
	setp.eq.s32	%p1028, %r8061, 3;
	@%p1028 bra 	BB0_1538;
	bra.uni 	BB0_978;

BB0_1538:
	and.b32  	%r8117, %r22, 1077952576;
	shr.u32 	%r8118, %r8117, 1;
	and.b32  	%r8119, %r22, -2139062144;
	shr.u32 	%r8120, %r8119, 2;
	not.b32 	%r8121, %r8120;
	and.b32  	%r8122, %r8118, %r8121;
	and.b32  	%r8123, %r22, 522133279;
	add.s32 	%r8124, %r8123, 522133279;
	mov.u32 	%r8125, -84215046;
	sub.s32 	%r8126, %r8125, %r8123;
	and.b32  	%r8127, %r8122, %r8126;
	and.b32  	%r8128, %r8127, %r8124;
	and.b32  	%r8129, %r8128, %r1710;
	xor.b32  	%r8845, %r8129, %r22;
	bra.uni 	BB0_12;

BB0_1185:
	setp.gt.s32	%p797, %r24, 13;
	@%p797 bra 	BB0_1189;

	setp.eq.s32	%p800, %r24, 12;
	@%p800 bra 	BB0_1234;
	bra.uni 	BB0_1187;

BB0_1234:
	mov.u32 	%r8849, 0;
	mov.u32 	%r8845, %r17;
	mov.u32 	%r8846, %r16;
	mov.u32 	%r8847, %r15;
	bra.uni 	BB0_1235;

BB0_991:
	setp.eq.s32	%p672, %r4827, 6;
	@%p672 bra 	BB0_996;
	bra.uni 	BB0_992;

BB0_996:
	and.b32  	%r8850, %r904, %r17;
	mov.u32 	%r8849, 0;
	mov.u32 	%r8845, %r22;
	mov.u32 	%r8846, %r21;
	mov.u32 	%r8847, %r20;
	mov.u32 	%r8848, %r19;
	bra.uni 	BB0_994;

BB0_738:
	setp.gt.s32	%p465, %r14, 27;
	@%p465 bra 	BB0_746;

	setp.gt.s32	%p471, %r14, 25;
	@%p471 bra 	BB0_743;

	setp.eq.s32	%p474, %r14, 24;
	@%p474 bra 	BB0_758;
	bra.uni 	BB0_741;

BB0_758:
	and.b32  	%r3800, %r16, 65535;
	shl.b32 	%r3801, %r16, 8;
	and.b32  	%r3802, %r3801, -16777216;
	or.b32  	%r3803, %r3802, %r3800;
	shr.u32 	%r3804, %r16, 8;
	and.b32  	%r3805, %r3804, 16711680;
	or.b32  	%r8851, %r3803, %r3805;
	mov.u32 	%r8853, 24;
	bra.uni 	BB0_760;

BB0_1468:
	setp.gt.s32	%p1000, %r7499, 13;
	@%p1000 bra 	BB0_1472;

	setp.eq.s32	%p1003, %r7499, 12;
	@%p1003 bra 	BB0_1518;
	bra.uni 	BB0_1470;

BB0_1518:
	mov.u32 	%r8838, 0;
	mov.u32 	%r8837, %r19;
	mov.u32 	%r8839, %r8838;
	mov.u32 	%r8840, %r8838;
	mov.u32 	%r18, %r15;
	mov.u32 	%r17, %r22;
	mov.u32 	%r16, %r21;
	mov.u32 	%r19, %r20;
	bra.uni 	BB0_1529;

BB0_367:
	setp.eq.s32	%p261, %r3498, 6;
	@%p261 bra 	BB0_370;
	bra.uni 	BB0_368;

BB0_370:
	and.b32  	%r3508, %r17, %r352;
	and.b32  	%r3509, %r3494, %r351;
	or.b32  	%r8850, %r3509, %r3508;
	bra.uni 	BB0_675;

BB0_181:
	setp.gt.s32	%p129, %r24, 27;
	@%p129 bra 	BB0_191;

	setp.gt.s32	%p135, %r24, 25;
	@%p135 bra 	BB0_186;

	setp.eq.s32	%p138, %r24, 24;
	@%p138 bra 	BB0_203;
	bra.uni 	BB0_184;

BB0_203:
	mov.u32 	%r8688, %r8691;
	mov.u32 	%r8689, %r8691;
	mov.u32 	%r8690, %r8691;
	mov.u32 	%r8692, %r20;
	mov.u32 	%r8693, %r19;
	bra.uni 	BB0_201;

BB0_245:
	setp.eq.s32	%p190, %r2840, 6;
	@%p190 bra 	BB0_249;
	bra.uni 	BB0_246;

BB0_249:
	and.b32  	%r8709, %r186, %r17;
	mov.u32 	%r8708, 0;
	mov.u32 	%r8704, %r22;
	mov.u32 	%r8705, %r21;
	mov.u32 	%r8706, %r20;
	mov.u32 	%r8707, %r19;
	bra.uni 	BB0_248;

BB0_387:
	setp.ne.s32	%p274, %r3522, 7;
	@%p274 bra 	BB0_11;

	and.b32  	%r3526, %r18, %r362;
	and.b32  	%r3527, %r361, %r18;
	sub.s32 	%r3528, %r3527, %r363;
	and.b32  	%r3529, %r3528, %r361;
	or.b32  	%r8849, %r3529, %r3526;
	bra.uni 	BB0_683;

BB0_1043:
	setp.ne.s32	%p699, %r4901, 7;
	@%p699 bra 	BB0_1034;

	and.b32  	%r4907, %r932, %r18;
	or.b32  	%r4908, %r4907, %r931;
	and.b32  	%r4909, %r8849, %r933;
	or.b32  	%r8849, %r4908, %r4909;
	mov.u32 	%r8845, %r22;
	mov.u32 	%r8846, %r21;
	mov.u32 	%r8847, %r20;
	mov.u32 	%r8848, %r19;
	bra.uni 	BB0_772;

BB0_1034:
	mov.u32 	%r8845, %r22;

BB0_768:
	mov.u32 	%r8846, %r21;

BB0_769:
	mov.u32 	%r8847, %r20;

BB0_770:
	mov.u32 	%r8848, %r19;

BB0_771:
	mov.u32 	%r8849, %r18;

BB0_772:
	mov.u32 	%r8850, %r17;

BB0_773:
	mov.u32 	%r8851, %r16;
	mov.u32 	%r8852, %r15;
	bra.uni 	BB0_1554;

BB0_1544:
	setp.ne.s32	%p1023, %r8061, 7;
	@%p1023 bra 	BB0_978;

	and.b32  	%r8065, %r18, 1077952576;
	shr.u32 	%r8066, %r8065, 1;
	and.b32  	%r8067, %r18, -2139062144;
	shr.u32 	%r8068, %r8067, 2;
	not.b32 	%r8069, %r8068;
	and.b32  	%r8070, %r8066, %r8069;
	and.b32  	%r8071, %r18, 522133279;
	add.s32 	%r8072, %r8071, 522133279;
	mov.u32 	%r8073, -84215046;
	sub.s32 	%r8074, %r8073, %r8071;
	and.b32  	%r8075, %r8070, %r8074;
	and.b32  	%r8076, %r8075, %r8072;
	and.b32  	%r8077, %r8076, %r1710;
	xor.b32  	%r8849, %r8077, %r18;
	bra.uni 	BB0_1021;

BB0_1217:
	setp.gt.s32	%p774, %r24, 29;
	@%p774 bra 	BB0_1221;

	setp.eq.s32	%p777, %r24, 28;
	@%p777 bra 	BB0_1224;
	bra.uni 	BB0_1219;

BB0_1224:
	mov.u32 	%r8845, 0;
	mov.u32 	%r8846, %r8845;
	mov.u32 	%r8847, %r8845;
	mov.u32 	%r22, %r18;
	bra.uni 	BB0_1244;

BB0_1501:
	setp.gt.s32	%p977, %r7499, 29;
	@%p977 bra 	BB0_1505;

	setp.eq.s32	%p980, %r7499, 28;
	@%p980 bra 	BB0_1508;
	bra.uni 	BB0_1503;

BB0_1508:
	mov.u32 	%r8837, 0;
	mov.u32 	%r8838, %r8837;
	mov.u32 	%r8839, %r8837;
	mov.u32 	%r8840, %r8837;
	mov.u32 	%r18, %r19;
	bra.uni 	BB0_1526;

BB0_397:
	setp.eq.s32	%p293, %r3558, 1;
	@%p293 bra 	BB0_398;
	bra.uni 	BB0_11;

BB0_398:
	and.b32  	%r3586, %r20, %r373;
	and.b32  	%r3587, %r372, %r20;
	add.s32 	%r3588, %r3587, %r374;
	and.b32  	%r3589, %r3588, %r372;
	or.b32  	%r8847, %r3589, %r3586;
	bra.uni 	BB0_625;

BB0_1063:
	setp.gt.s32	%p747, %r26, 5;
	@%p747 bra 	BB0_1067;

	setp.eq.s32	%p750, %r26, 4;
	@%p750 bra 	BB0_1134;
	bra.uni 	BB0_1065;

BB0_1134:
	mov.u32 	%r8845, %r15;
	mov.u32 	%r8846, %r22;
	mov.u32 	%r8847, %r21;
	mov.u32 	%r8766, %r20;
	mov.u32 	%r8850, %r18;
	mov.u32 	%r8851, %r17;
	mov.u32 	%r8852, %r16;
	bra.uni 	BB0_1137;

BB0_1007:
	setp.eq.s32	%p692, %r4860, 1;
	@%p692 bra 	BB0_1008;
	bra.uni 	BB0_978;

BB0_1008:
	and.b32  	%r4871, %r20, %r914;
	or.b32  	%r8847, %r4871, %r913;

BB0_1009:
	mov.u32 	%r8845, %r22;
	mov.u32 	%r8846, %r21;
	bra.uni 	BB0_14;

BB0_459:
	setp.gt.s32	%p358, %r24, 5;
	@%p358 bra 	BB0_463;

	setp.eq.s32	%p361, %r24, 4;
	@%p361 bra 	BB0_525;
	bra.uni 	BB0_461;

BB0_525:
	and.b32  	%r8720, %r20, 255;
	bra.uni 	BB0_528;

BB0_344:
	setp.eq.s32	%p254, %r3445, 2;
	@%p254 bra 	BB0_356;
	bra.uni 	BB0_345;

BB0_356:
	and.b32  	%r3459, %r21, %r335;
	and.b32  	%r3460, %r3437, %r334;
	or.b32  	%r8846, %r3460, %r3459;
	bra.uni 	BB0_634;

BB0_1434:
	setp.eq.s32	%p973, %r7320, 1;
	mov.u32 	%r8830, %r8829;
	mov.u32 	%r8831, %r8829;
	mov.u32 	%r8832, %r8829;
	mov.u32 	%r8833, %r8829;
	mov.u32 	%r8834, %r8829;
	mov.u32 	%r8835, %r8829;
	mov.u32 	%r8836, %r8829;
	@%p973 bra 	BB0_1435;
	bra.uni 	BB0_1450;

BB0_1435:
	// inline asm
	prmt.b32 %r8836, %r16, %r17, %r1533;
	// inline asm
	// inline asm
	prmt.b32 %r8835, %r15, %r16, %r1533;
	// inline asm
	// inline asm
	prmt.b32 %r8834, %r22, %r15, %r1533;
	// inline asm
	// inline asm
	prmt.b32 %r8833, %r21, %r22, %r1533;
	// inline asm
	// inline asm
	prmt.b32 %r8832, %r20, %r21, %r1533;
	// inline asm
	// inline asm
	prmt.b32 %r8831, %r19, %r20, %r1533;
	// inline asm
	mov.u32 	%r8829, 0;
	// inline asm
	prmt.b32 %r8830, %r8829, %r19, %r1533;
	// inline asm
	bra.uni 	BB0_1450;

BB0_1326:
	setp.gt.s32	%p914, %r6374, 11;
	@%p914 bra 	BB0_1334;

	setp.gt.s32	%p920, %r6374, 9;
	@%p920 bra 	BB0_1331;

	setp.eq.s32	%p923, %r6374, 8;
	@%p923 bra 	BB0_1390;
	bra.uni 	BB0_1329;

BB0_1390:
	mov.u32 	%r8795, %r20;
	mov.u32 	%r8796, %r19;
	mov.u32 	%r8797, %r8803;
	mov.u32 	%r8798, %r8803;
	mov.u32 	%r8799, %r16;
	mov.u32 	%r8800, %r15;
	mov.u32 	%r8801, %r22;
	mov.u32 	%r8802, %r21;
	bra.uni 	BB0_1394;

BB0_432:
	setp.eq.s32	%p317, %r3630, 1;
	@%p317 bra 	BB0_433;
	bra.uni 	BB0_11;

BB0_433:
	and.b32  	%r3658, %r20, %r394;
	and.b32  	%r3659, %r393, %r20;
	shl.b32 	%r3660, %r3659, 1;
	and.b32  	%r3661, %r3660, %r393;
	or.b32  	%r8847, %r3661, %r3658;
	bra.uni 	BB0_625;

BB0_415:
	setp.eq.s32	%p302, %r3594, 2;
	@%p302 bra 	BB0_427;
	bra.uni 	BB0_416;

BB0_427:
	and.b32  	%r3618, %r21, %r384;
	and.b32  	%r3619, %r383, %r21;
	shr.u32 	%r3620, %r3619, 1;
	and.b32  	%r3621, %r3620, %r383;
	or.b32  	%r8846, %r3621, %r3618;
	bra.uni 	BB0_634;

BB0_1270:
	setp.eq.s32	%p835, %r6119, 2;
	@%p835 bra 	BB0_1289;
	bra.uni 	BB0_1271;

BB0_1289:
	and.b32  	%r6134, %r1210, %r21;
	and.b32  	%r6135, %r8846, %r1211;
	or.b32  	%r8846, %r6135, %r6134;
	bra.uni 	BB0_1288;

BB0_796:
	setp.gt.s32	%p571, %r24, 5;
	@%p571 bra 	BB0_800;

	setp.eq.s32	%p574, %r24, 4;
	@%p574 bra 	BB0_866;
	bra.uni 	BB0_798;

BB0_866:
	mov.u32 	%r8848, 0;
	mov.u32 	%r8845, %r21;
	mov.u32 	%r8846, %r20;
	mov.u32 	%r8847, %r19;
	mov.u32 	%r18, %r17;
	mov.u32 	%r17, %r16;
	mov.u32 	%r16, %r15;
	mov.u32 	%r15, %r22;
	bra.uni 	BB0_874;

BB0_1292:
	setp.eq.s32	%p865, %r6221, 2;
	@%p865 bra 	BB0_1304;
	bra.uni 	BB0_1293;

BB0_1304:
	and.b32  	%r8846, %r8846, %r1255;
	mov.u32 	%r8845, 0;
	bra.uni 	BB0_1305;

BB0_404:
	setp.eq.s32	%p288, %r3558, 5;
	@%p288 bra 	BB0_405;
	bra.uni 	BB0_11;

BB0_405:
	and.b32  	%r3570, %r16, %r373;
	and.b32  	%r3571, %r372, %r16;
	add.s32 	%r3572, %r3571, %r374;
	and.b32  	%r3573, %r3572, %r372;
	or.b32  	%r8851, %r3573, %r3570;
	bra.uni 	BB0_666;

BB0_1095:
	setp.gt.s32	%p724, %r26, 21;
	@%p724 bra 	BB0_1099;

	setp.eq.s32	%p727, %r26, 20;
	@%p727 bra 	BB0_1126;
	bra.uni 	BB0_1097;

BB0_1126:
	mov.u32 	%r8845, %r8849;
	mov.u32 	%r8846, %r18;
	mov.u32 	%r8847, %r17;
	mov.u32 	%r8766, %r16;
	bra.uni 	BB0_1122;

BB0_1015:
	setp.eq.s32	%p687, %r4860, 5;
	@%p687 bra 	BB0_1016;
	bra.uni 	BB0_978;

BB0_1016:
	and.b32  	%r4867, %r16, %r914;
	or.b32  	%r8851, %r4867, %r913;

BB0_1017:
	mov.u32 	%r8845, %r22;
	mov.u32 	%r8846, %r21;
	mov.u32 	%r8847, %r20;
	mov.u32 	%r8848, %r19;
	mov.u32 	%r8849, %r18;
	mov.u32 	%r8850, %r17;
	bra.uni 	BB0_18;

BB0_490:
	setp.gt.s32	%p335, %r24, 21;
	@%p335 bra 	BB0_494;

	setp.eq.s32	%p338, %r24, 20;
	@%p338 bra 	BB0_517;
	bra.uni 	BB0_492;

BB0_517:
	and.b32  	%r8720, %r16, 255;
	bra.uni 	BB0_528;

BB0_1441:
	setp.eq.s32	%p968, %r7320, 5;
	mov.u32 	%r8830, %r8829;
	mov.u32 	%r8831, %r8829;
	mov.u32 	%r8832, %r8829;
	mov.u32 	%r8833, %r8829;
	mov.u32 	%r8834, %r8829;
	mov.u32 	%r8835, %r8829;
	mov.u32 	%r8836, %r8829;
	@%p968 bra 	BB0_1442;
	bra.uni 	BB0_1450;

BB0_1442:
	// inline asm
	prmt.b32 %r8836, %r20, %r21, %r1533;
	// inline asm
	// inline asm
	prmt.b32 %r8835, %r19, %r20, %r1533;
	// inline asm
	mov.u32 	%r8829, 0;
	// inline asm
	prmt.b32 %r8834, %r8829, %r19, %r1533;
	// inline asm
	mov.u32 	%r8830, %r8829;
	mov.u32 	%r8831, %r8829;
	mov.u32 	%r8832, %r8829;
	mov.u32 	%r8833, %r8829;
	bra.uni 	BB0_1450;

BB0_439:
	setp.eq.s32	%p312, %r3630, 5;
	@%p312 bra 	BB0_440;
	bra.uni 	BB0_11;

BB0_440:
	and.b32  	%r3642, %r16, %r394;
	and.b32  	%r3643, %r393, %r16;
	shl.b32 	%r3644, %r3643, 1;
	and.b32  	%r3645, %r3644, %r393;
	or.b32  	%r8851, %r3645, %r3642;
	bra.uni 	BB0_666;

BB0_828:
	setp.gt.s32	%p548, %r24, 21;
	@%p548 bra 	BB0_832;

	setp.eq.s32	%p551, %r24, 20;
	@%p551 bra 	BB0_856;
	bra.uni 	BB0_830;

BB0_856:
	mov.u32 	%r8845, 0;
	mov.u32 	%r8846, %r8845;
	mov.u32 	%r8847, %r8845;
	mov.u32 	%r8848, %r8845;
	mov.u32 	%r18, %r21;
	mov.u32 	%r17, %r20;
	mov.u32 	%r16, %r19;
	bra.uni 	BB0_873;

BB0_400:
	setp.eq.s32	%p291, %r3558, 3;
	@%p291 bra 	BB0_401;
	bra.uni 	BB0_11;

BB0_401:
	and.b32  	%r3578, %r22, %r373;
	and.b32  	%r3579, %r372, %r22;
	add.s32 	%r3580, %r3579, %r374;
	and.b32  	%r3581, %r3580, %r372;
	or.b32  	%r8845, %r3581, %r3578;
	bra.uni 	BB0_642;

BB0_1078:
	setp.gt.s32	%p736, %r26, 13;
	@%p736 bra 	BB0_1082;

	setp.eq.s32	%p739, %r26, 12;
	@%p739 bra 	BB0_1130;
	bra.uni 	BB0_1080;

BB0_1130:
	mov.u32 	%r8845, %r17;
	mov.u32 	%r8846, %r16;
	mov.u32 	%r8847, %r15;
	mov.u32 	%r8766, %r22;
	mov.u32 	%r8850, %r8849;
	mov.u32 	%r8851, %r8849;
	mov.u32 	%r8852, %r18;
	bra.uni 	BB0_1137;

BB0_1011:
	setp.eq.s32	%p690, %r4860, 3;
	@%p690 bra 	BB0_1012;
	bra.uni 	BB0_978;

BB0_1012:
	and.b32  	%r4869, %r22, %r914;
	or.b32  	%r8845, %r4869, %r913;
	bra.uni 	BB0_12;

BB0_474:
	setp.gt.s32	%p347, %r24, 13;
	@%p347 bra 	BB0_478;

	setp.eq.s32	%p350, %r24, 12;
	@%p350 bra 	BB0_521;
	bra.uni 	BB0_476;

BB0_521:
	and.b32  	%r8720, %r22, 255;
	bra.uni 	BB0_528;

BB0_351:
	setp.eq.s32	%p249, %r3445, 6;
	@%p249 bra 	BB0_354;
	bra.uni 	BB0_352;

BB0_354:
	and.b32  	%r3451, %r17, %r335;
	and.b32  	%r3452, %r3421, %r334;
	or.b32  	%r8850, %r3452, %r3451;
	bra.uni 	BB0_675;

BB0_1437:
	setp.eq.s32	%p971, %r7320, 3;
	mov.u32 	%r8830, %r8829;
	mov.u32 	%r8831, %r8829;
	mov.u32 	%r8832, %r8829;
	mov.u32 	%r8833, %r8829;
	mov.u32 	%r8834, %r8829;
	mov.u32 	%r8835, %r8829;
	mov.u32 	%r8836, %r8829;
	@%p971 bra 	BB0_1438;
	bra.uni 	BB0_1450;

BB0_1438:
	// inline asm
	prmt.b32 %r8836, %r22, %r15, %r1533;
	// inline asm
	// inline asm
	prmt.b32 %r8835, %r21, %r22, %r1533;
	// inline asm
	// inline asm
	prmt.b32 %r8834, %r20, %r21, %r1533;
	// inline asm
	// inline asm
	prmt.b32 %r8833, %r19, %r20, %r1533;
	// inline asm
	mov.u32 	%r8829, 0;
	// inline asm
	prmt.b32 %r8832, %r8829, %r19, %r1533;
	// inline asm
	mov.u32 	%r8830, %r8829;
	mov.u32 	%r8831, %r8829;
	bra.uni 	BB0_1450;

BB0_1360:
	setp.gt.s32	%p891, %r6374, 27;
	@%p891 bra 	BB0_1370;

	setp.gt.s32	%p897, %r6374, 25;
	@%p897 bra 	BB0_1365;

	setp.eq.s32	%p900, %r6374, 24;
	@%p900 bra 	BB0_1382;
	bra.uni 	BB0_1363;

BB0_1382:
	mov.u32 	%r8795, %r8803;
	mov.u32 	%r8796, %r8803;
	mov.u32 	%r8797, %r8803;
	mov.u32 	%r8798, %r8803;
	mov.u32 	%r8799, %r20;
	mov.u32 	%r8800, %r19;
	bra.uni 	BB0_1380;

BB0_435:
	setp.eq.s32	%p315, %r3630, 3;
	@%p315 bra 	BB0_436;
	bra.uni 	BB0_11;

BB0_436:
	and.b32  	%r3650, %r22, %r394;
	and.b32  	%r3651, %r393, %r22;
	shl.b32 	%r3652, %r3651, 1;
	and.b32  	%r3653, %r3652, %r393;
	or.b32  	%r8845, %r3653, %r3650;
	bra.uni 	BB0_642;

BB0_422:
	setp.eq.s32	%p297, %r3594, 6;
	@%p297 bra 	BB0_425;
	bra.uni 	BB0_423;

BB0_425:
	and.b32  	%r3602, %r17, %r384;
	and.b32  	%r3603, %r383, %r17;
	shr.u32 	%r3604, %r3603, 1;
	and.b32  	%r3605, %r3604, %r383;
	or.b32  	%r8850, %r3605, %r3602;
	bra.uni 	BB0_675;

BB0_957:
	and.b16  	%rs332, %rs2, 255;
	and.b16  	%rs333, %rs440, 255;
	setp.eq.s16	%p628, %rs333, %rs332;
	mov.u32 	%r8748, 1;
	@%p628 bra 	BB0_959;

	st.local.u8 	[%rd6], %rs440;
	mov.u32 	%r8748, 1;
	mov.u32 	%r8853, %r8748;

BB0_959:
	cvt.u64.u32	%rd16, %r8748;
	add.s64 	%rd17, %rd7, %rd16;
	ld.local.u8 	%rs3, [%rd17];
	and.b16  	%rs334, %rs2, 255;
	setp.eq.s16	%p629, %rs3, %rs334;
	@%p629 bra 	BB0_961;

	cvt.u64.u32	%rd18, %r8853;
	add.s64 	%rd19, %rd6, %rd18;
	st.local.u8 	[%rd19], %rs3;
	add.s32 	%r8853, %r8853, 1;

BB0_961:
	add.s32 	%r8751, %r8748, 1;
	cvt.u64.u32	%rd20, %r8751;
	add.s64 	%rd21, %rd7, %rd20;
	ld.local.u8 	%rs440, [%rd21];

BB0_962:
	and.b16  	%rs335, %rs2, 255;
	and.b16  	%rs336, %rs440, 255;
	setp.eq.s16	%p630, %rs336, %rs335;
	@%p630 bra 	BB0_964;

	cvt.u64.u32	%rd22, %r8853;
	add.s64 	%rd23, %rd6, %rd22;
	st.local.u8 	[%rd23], %rs440;
	add.s32 	%r8853, %r8853, 1;

BB0_964:
	add.s32 	%r8756, %r8751, 1;

BB0_965:
	setp.lt.u32	%p631, %r14, 4;
	@%p631 bra 	BB0_975;

BB0_966:
	cvt.u64.u32	%rd24, %r8756;
	add.s64 	%rd25, %rd7, %rd24;
	ld.local.u8 	%rs6, [%rd25];
	and.b16  	%rs337, %rs2, 255;
	setp.eq.s16	%p632, %rs6, %rs337;
	@%p632 bra 	BB0_968;

	cvt.u64.u32	%rd26, %r8853;
	add.s64 	%rd27, %rd6, %rd26;
	st.local.u8 	[%rd27], %rs6;
	add.s32 	%r8853, %r8853, 1;

BB0_968:
	add.s32 	%r4768, %r8756, 1;
	cvt.u64.u32	%rd28, %r4768;
	add.s64 	%rd29, %rd7, %rd28;
	ld.local.u8 	%rs7, [%rd29];
	setp.eq.s16	%p633, %rs7, %rs337;
	@%p633 bra 	BB0_970;

	cvt.u64.u32	%rd30, %r8853;
	add.s64 	%rd31, %rd6, %rd30;
	st.local.u8 	[%rd31], %rs7;
	add.s32 	%r8853, %r8853, 1;

BB0_970:
	add.s32 	%r4769, %r8756, 2;
	cvt.u64.u32	%rd32, %r4769;
	add.s64 	%rd33, %rd7, %rd32;
	ld.local.u8 	%rs8, [%rd33];
	setp.eq.s16	%p634, %rs8, %rs337;
	@%p634 bra 	BB0_972;

	cvt.u64.u32	%rd34, %r8853;
	add.s64 	%rd35, %rd6, %rd34;
	st.local.u8 	[%rd35], %rs8;
	add.s32 	%r8853, %r8853, 1;

BB0_972:
	add.s32 	%r4770, %r8756, 3;
	cvt.u64.u32	%rd36, %r4770;
	add.s64 	%rd37, %rd7, %rd36;
	ld.local.u8 	%rs9, [%rd37];
	setp.eq.s16	%p635, %rs9, %rs337;
	@%p635 bra 	BB0_974;

	cvt.u64.u32	%rd38, %r8853;
	add.s64 	%rd39, %rd6, %rd38;
	st.local.u8 	[%rd39], %rs9;
	add.s32 	%r8853, %r8853, 1;

BB0_974:
	add.s32 	%r8756, %r8756, 4;
	setp.lt.u32	%p636, %r8756, %r14;
	@%p636 bra 	BB0_966;

BB0_975:
	ld.local.v4.u32 	{%r8848, %r8847, %r8846, %r8845}, [%rd6];
	ld.local.v4.u32 	{%r8852, %r8851, %r8850, %r8849}, [%rd6+16];
	bra.uni 	BB0_1554;

BB0_1279:
	setp.eq.s32	%p830, %r6119, 6;
	@%p830 bra 	BB0_1285;
	bra.uni 	BB0_1280;

BB0_1285:
	and.b32  	%r6126, %r1210, %r17;
	and.b32  	%r6127, %r8850, %r1211;
	or.b32  	%r8850, %r6127, %r6126;
	mov.u32 	%r8845, %r22;
	mov.u32 	%r8846, %r21;
	mov.u32 	%r8847, %r20;
	mov.u32 	%r8848, %r19;
	bra.uni 	BB0_1283;

BB0_811:
	setp.gt.s32	%p560, %r24, 13;
	@%p560 bra 	BB0_815;

	setp.eq.s32	%p563, %r24, 12;
	@%p563 bra 	BB0_862;
	bra.uni 	BB0_813;

BB0_862:
	mov.u32 	%r8846, 0;
	mov.u32 	%r8845, %r19;
	mov.u32 	%r8847, %r8846;
	mov.u32 	%r8848, %r8846;
	mov.u32 	%r18, %r15;
	mov.u32 	%r17, %r22;
	mov.u32 	%r16, %r21;
	mov.u32 	%r15, %r20;
	bra.uni 	BB0_874;

BB0_1299:
	setp.eq.s32	%p860, %r6221, 6;
	@%p860 bra 	BB0_1302;
	bra.uni 	BB0_1300;

BB0_1302:
	and.b32  	%r8850, %r8850, %r1255;
	bra.uni 	BB0_1553;

BB0_407:
	setp.ne.s32	%p286, %r3558, 7;
	@%p286 bra 	BB0_11;

	and.b32  	%r3562, %r18, %r373;
	and.b32  	%r3563, %r372, %r18;
	add.s32 	%r3564, %r3563, %r374;
	and.b32  	%r3565, %r3564, %r372;
	or.b32  	%r8849, %r3565, %r3562;
	bra.uni 	BB0_683;

BB0_1112:
	setp.gt.s32	%p713, %r26, 29;
	@%p713 bra 	BB0_1116;

	setp.eq.s32	%p716, %r26, 28;
	@%p716 bra 	BB0_1121;
	bra.uni 	BB0_1114;

BB0_1121:
	mov.u32 	%r8845, %r8849;
	mov.u32 	%r8846, %r8849;
	mov.u32 	%r8847, %r8849;
	mov.u32 	%r8766, %r18;
	bra.uni 	BB0_1122;

BB0_1019:
	setp.ne.s32	%p685, %r4860, 7;
	@%p685 bra 	BB0_978;

	and.b32  	%r4865, %r18, %r914;
	or.b32  	%r8849, %r4865, %r913;

BB0_1021:
	mov.u32 	%r8845, %r22;
	mov.u32 	%r8846, %r21;
	mov.u32 	%r8847, %r20;
	mov.u32 	%r8848, %r19;
	bra.uni 	BB0_16;

BB0_978:
	mov.u32 	%r8845, %r22;

BB0_642:
	mov.u32 	%r8846, %r21;

BB0_643:
	mov.u32 	%r8847, %r20;

BB0_644:
	mov.u32 	%r8848, %r19;

BB0_645:
	mov.u32 	%r8849, %r18;

BB0_646:
	mov.u32 	%r8850, %r17;

BB0_647:
	mov.u32 	%r8851, %r16;

BB0_648:
	mov.u32 	%r8852, %r15;
	bra.uni 	BB0_1553;

BB0_505:
	setp.gt.s32	%p324, %r24, 29;
	@%p324 bra 	BB0_509;

	setp.eq.s32	%p327, %r24, 28;
	@%p327 bra 	BB0_513;
	bra.uni 	BB0_507;

BB0_513:
	and.b32  	%r8720, %r18, 255;
	bra.uni 	BB0_528;

BB0_1444:
	setp.ne.s32	%p966, %r7320, 7;
	mov.u32 	%r8830, %r8829;
	mov.u32 	%r8831, %r8829;
	mov.u32 	%r8832, %r8829;
	mov.u32 	%r8833, %r8829;
	mov.u32 	%r8834, %r8829;
	mov.u32 	%r8835, %r8829;
	mov.u32 	%r8836, %r8829;
	@%p966 bra 	BB0_1450;

	mov.u32 	%r8829, 0;
	// inline asm
	prmt.b32 %r8836, %r8829, %r19, %r1533;
	// inline asm
	mov.u32 	%r8830, %r8829;
	mov.u32 	%r8831, %r8829;
	mov.u32 	%r8832, %r8829;
	mov.u32 	%r8833, %r8829;
	mov.u32 	%r8834, %r8829;
	mov.u32 	%r8835, %r8829;

BB0_1450:
	or.b32  	%r8848, %r8829, %r19;
	or.b32  	%r8847, %r8830, %r20;
	or.b32  	%r8846, %r8831, %r21;
	or.b32  	%r8845, %r8832, %r22;
	or.b32  	%r8852, %r8833, %r15;
	or.b32  	%r8851, %r8834, %r16;
	or.b32  	%r8850, %r8835, %r17;
	or.b32  	%r8849, %r8836, %r18;
	bra.uni 	BB0_1554;

BB0_442:
	setp.ne.s32	%p310, %r3630, 7;
	@%p310 bra 	BB0_11;

	and.b32  	%r3634, %r18, %r394;
	and.b32  	%r3635, %r393, %r18;
	shl.b32 	%r3636, %r3635, 1;
	and.b32  	%r3637, %r3636, %r393;
	or.b32  	%r8849, %r3637, %r3634;
	bra.uni 	BB0_683;

BB0_845:
	setp.gt.s32	%p537, %r24, 29;
	@%p537 bra 	BB0_849;

	setp.eq.s32	%p540, %r24, 28;
	@%p540 bra 	BB0_852;
	bra.uni 	BB0_847;

BB0_852:
	mov.u32 	%r8845, 0;
	mov.u32 	%r8846, %r8845;
	mov.u32 	%r8847, %r8845;
	mov.u32 	%r8848, %r8845;
	mov.u32 	%r18, %r19;
	bra.uni 	BB0_871;

BB0_982:
	setp.eq.s32	%p680, %r4827, 1;
	@%p680 bra 	BB0_1001;
	bra.uni 	BB0_983;

BB0_1001:
	and.b32  	%r8847, %r904, %r20;
	mov.u32 	%r8845, 0;
	mov.u32 	%r8846, %r8845;

BB0_999:
	mov.u32 	%r8848, %r19;

BB0_1000:
	mov.u32 	%r8849, %r8845;
	mov.u32 	%r8850, %r8845;
	mov.u32 	%r8851, %r8845;
	mov.u32 	%r8852, %r8845;
	mov.u32 	%r8853, %r24;
	bra.uni 	BB0_1554;

BB0_702:
	setp.gt.s32	%p498, %r14, 6;
	@%p498 bra 	BB0_706;

	setp.eq.s32	%p501, %r14, 5;
	@%p501 bra 	BB0_780;
	bra.uni 	BB0_704;

BB0_780:
	or.b32  	%r3902, %r19, %r20;
	and.b32  	%r3903, %r19, 16777215;
	prmt.b32 	%r8848, %r20, %r3903, 1620;
	shr.u32 	%r8847, %r3902, 24;
	mov.u32 	%r8853, 5;
	mov.u32 	%r8845, %r22;
	mov.u32 	%r8846, %r21;
	bra.uni 	BB0_771;

BB0_358:
	setp.eq.s32	%p269, %r3498, 1;
	@%p269 bra 	BB0_359;
	bra.uni 	BB0_11;

BB0_359:
	and.b32  	%r3518, %r20, %r352;
	and.b32  	%r3519, %r3474, %r351;
	or.b32  	%r8847, %r3519, %r3518;
	bra.uni 	BB0_625;

BB0_140:
	setp.gt.s32	%p164, %r24, 5;
	@%p164 bra 	BB0_144;

	setp.eq.s32	%p167, %r24, 4;
	@%p167 bra 	BB0_213;
	bra.uni 	BB0_142;

BB0_213:
	mov.u32 	%r8688, %r21;
	mov.u32 	%r8689, %r20;
	mov.u32 	%r8690, %r19;
	mov.u32 	%r8692, %r17;
	mov.u32 	%r8693, %r16;
	mov.u32 	%r8694, %r15;
	mov.u32 	%r8695, %r22;
	bra.uni 	BB0_215;

BB0_236:
	setp.eq.s32	%p198, %r2840, 1;
	mov.u32 	%r8704, %r22;
	mov.u32 	%r8705, %r21;
	mov.u32 	%r8706, %r20;
	mov.u32 	%r8707, %r19;
	mov.u32 	%r8708, %r18;
	mov.u32 	%r8709, %r17;
	mov.u32 	%r8710, %r16;
	mov.u32 	%r8711, %r15;
	@%p198 bra 	BB0_237;
	bra.uni 	BB0_254;

BB0_237:
	and.b32  	%r8706, %r186, %r20;
	mov.u32 	%r8704, 0;
	mov.u32 	%r8705, %r8704;

BB0_252:
	mov.u32 	%r8707, %r19;

BB0_253:
	mov.u32 	%r8708, %r8704;
	mov.u32 	%r8709, %r8704;
	mov.u32 	%r8710, %r8704;
	mov.u32 	%r8711, %r8704;
	bra.uni 	BB0_254;

BB0_1198:
	setp.eq.s32	%p791, %r24, 18;
	@%p791 bra 	BB0_1229;
	bra.uni 	BB0_1199;

BB0_1229:
	mov.u32 	%r5678, 16;
	// inline asm
	shf.r.wrap.b32 %r22, %r15, %r16, %r5678;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8847, %r16, %r17, %r5678;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8846, %r17, %r18, %r5678;
	// inline asm
	mov.u32 	%r8849, 0;
	// inline asm
	shf.r.wrap.b32 %r8845, %r18, %r8849, %r5678;
	// inline asm
	bra.uni 	BB0_1231;

BB0_1481:
	setp.eq.s32	%p994, %r7499, 18;
	@%p994 bra 	BB0_1515;
	bra.uni 	BB0_1482;

BB0_1515:
	mov.u32 	%r7669, 16;
	// inline asm
	shf.r.wrap.b32 %r18, %r21, %r22, %r7669;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r17, %r20, %r21, %r7669;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r16, %r19, %r20, %r7669;
	// inline asm
	mov.u32 	%r8837, 0;
	// inline asm
	shf.r.wrap.b32 %r19, %r8837, %r19, %r7669;
	// inline asm
	bra.uni 	BB0_1514;

BB0_1182:
	setp.eq.s32	%p803, %r24, 10;
	@%p803 bra 	BB0_1236;
	bra.uni 	BB0_1183;

BB0_1236:
	mov.u32 	%r5828, 16;
	// inline asm
	shf.r.wrap.b32 %r5805, %r21, %r22, %r5828;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8847, %r22, %r15, %r5828;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8846, %r15, %r16, %r5828;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8845, %r16, %r17, %r5828;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5821, %r17, %r18, %r5828;
	// inline asm
	mov.u32 	%r8849, 0;
	// inline asm
	shf.r.wrap.b32 %r8851, %r18, %r8849, %r5828;
	// inline asm
	mov.u32 	%r22, %r5805;
	mov.u32 	%r8850, %r8849;
	mov.u32 	%r18, %r5821;
	bra.uni 	BB0_1245;

BB0_989:
	setp.eq.s32	%p675, %r4827, 5;
	@%p675 bra 	BB0_990;
	bra.uni 	BB0_983;

BB0_990:
	and.b32  	%r8851, %r904, %r16;
	mov.u32 	%r8849, 0;
	mov.u32 	%r8845, %r22;
	mov.u32 	%r8846, %r21;
	mov.u32 	%r8847, %r20;
	mov.u32 	%r8848, %r19;
	mov.u32 	%r8850, %r8849;
	bra.uni 	BB0_995;

BB0_730:
	setp.gt.s32	%p477, %r14, 21;
	@%p477 bra 	BB0_735;

	setp.eq.s32	%p480, %r14, 20;
	@%p480 bra 	BB0_761;
	bra.uni 	BB0_732;

BB0_761:
	and.b32  	%r3821, %r15, 65535;
	shl.b32 	%r3822, %r15, 8;
	and.b32  	%r3823, %r3822, -16777216;
	or.b32  	%r3824, %r3823, %r3821;
	shr.u32 	%r3825, %r15, 8;
	and.b32  	%r3826, %r3825, 16711680;
	or.b32  	%r8852, %r3824, %r3826;
	mov.u32 	%r8853, 20;
	bra.uni 	BB0_763;

BB0_1465:
	setp.eq.s32	%p1006, %r7499, 10;
	@%p1006 bra 	BB0_1519;
	bra.uni 	BB0_1466;

BB0_1519:
	mov.u32 	%r7819, 16;
	// inline asm
	shf.r.wrap.b32 %r18, %r15, %r16, %r7819;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r17, %r22, %r15, %r7819;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r16, %r21, %r22, %r7819;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r7808, %r20, %r21, %r7819;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8837, %r19, %r20, %r7819;
	// inline asm
	mov.u32 	%r8839, 0;
	// inline asm
	shf.r.wrap.b32 %r8838, %r8839, %r19, %r7819;
	// inline asm
	mov.u32 	%r8840, %r8839;
	mov.u32 	%r19, %r7808;
	bra.uni 	BB0_1529;

BB0_365:
	setp.eq.s32	%p264, %r3498, 5;
	@%p264 bra 	BB0_366;
	bra.uni 	BB0_11;

BB0_366:
	and.b32  	%r3510, %r16, %r352;
	and.b32  	%r3511, %r3490, %r351;
	or.b32  	%r8851, %r3511, %r3510;
	bra.uni 	BB0_666;

BB0_173:
	setp.gt.s32	%p141, %r24, 21;
	@%p141 bra 	BB0_177;

	setp.eq.s32	%p144, %r24, 20;
	@%p144 bra 	BB0_205;
	bra.uni 	BB0_175;

BB0_205:
	mov.u32 	%r8688, %r8691;
	mov.u32 	%r8689, %r8691;
	mov.u32 	%r8690, %r8691;
	mov.u32 	%r8692, %r21;
	mov.u32 	%r8693, %r20;
	mov.u32 	%r8694, %r19;
	mov.u32 	%r8695, %r8691;
	bra.uni 	BB0_215;

BB0_243:
	setp.eq.s32	%p193, %r2840, 5;
	mov.u32 	%r8704, %r22;
	mov.u32 	%r8705, %r21;
	mov.u32 	%r8706, %r20;
	mov.u32 	%r8707, %r19;
	mov.u32 	%r8708, %r18;
	mov.u32 	%r8709, %r17;
	mov.u32 	%r8710, %r16;
	mov.u32 	%r8711, %r15;
	@%p193 bra 	BB0_244;
	bra.uni 	BB0_254;

BB0_244:
	and.b32  	%r8710, %r186, %r16;
	mov.u32 	%r8708, 0;
	mov.u32 	%r8704, %r22;
	mov.u32 	%r8705, %r21;
	mov.u32 	%r8706, %r20;
	mov.u32 	%r8707, %r19;
	mov.u32 	%r8709, %r8708;
	mov.u32 	%r8711, %r15;
	bra.uni 	BB0_254;

BB0_1213:
	setp.eq.s32	%p780, %r24, 26;
	@%p780 bra 	BB0_1225;
	bra.uni 	BB0_1214;

BB0_1225:
	mov.u32 	%r5560, 16;
	// inline asm
	shf.r.wrap.b32 %r22, %r17, %r18, %r5560;
	// inline asm
	mov.u32 	%r8845, 0;
	// inline asm
	shf.r.wrap.b32 %r8847, %r18, %r8845, %r5560;
	// inline asm
	bra.uni 	BB0_1216;

BB0_1497:
	setp.eq.s32	%p983, %r7499, 26;
	@%p983 bra 	BB0_1509;
	bra.uni 	BB0_1498;

BB0_1509:
	mov.u32 	%r7551, 16;
	// inline asm
	shf.r.wrap.b32 %r18, %r19, %r20, %r7551;
	// inline asm
	mov.u32 	%r8837, 0;
	// inline asm
	shf.r.wrap.b32 %r17, %r8837, %r19, %r7551;
	// inline asm
	bra.uni 	BB0_1500;

BB0_1174:
	setp.eq.s32	%p809, %r24, 6;
	@%p809 bra 	BB0_1238;
	bra.uni 	BB0_1175;

BB0_1238:
	mov.u32 	%r5915, 16;
	// inline asm
	shf.r.wrap.b32 %r5888, %r20, %r21, %r5915;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8847, %r21, %r22, %r5915;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8846, %r22, %r15, %r5915;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8845, %r15, %r16, %r5915;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5904, %r16, %r17, %r5915;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8851, %r17, %r18, %r5915;
	// inline asm
	mov.u32 	%r8849, 0;
	// inline asm
	shf.r.wrap.b32 %r8850, %r18, %r8849, %r5915;
	// inline asm
	mov.u32 	%r22, %r5888;
	mov.u32 	%r18, %r5904;
	bra.uni 	BB0_1245;

BB0_985:
	setp.eq.s32	%p678, %r4827, 3;
	@%p678 bra 	BB0_986;
	bra.uni 	BB0_983;

BB0_986:
	and.b32  	%r8845, %r904, %r22;
	mov.u32 	%r8849, 0;
	mov.u32 	%r8846, %r21;
	mov.u32 	%r8847, %r20;
	mov.u32 	%r8848, %r19;
	mov.u32 	%r8850, %r8849;
	mov.u32 	%r8851, %r8849;
	mov.u32 	%r8852, %r8849;
	mov.u32 	%r8853, %r24;
	bra.uni 	BB0_1554;

BB0_717:
	setp.gt.s32	%p487, %r14, 14;
	@%p487 bra 	BB0_721;

	setp.eq.s32	%p490, %r14, 13;
	@%p490 bra 	BB0_774;
	bra.uni 	BB0_719;

BB0_774:
	or.b32  	%r3860, %r21, %r22;
	and.b32  	%r3861, %r21, 16777215;
	prmt.b32 	%r8846, %r22, %r3861, 1620;
	shr.u32 	%r8845, %r3860, 24;
	mov.u32 	%r8853, 13;
	bra.uni 	BB0_769;

BB0_1457:
	setp.eq.s32	%p1012, %r7499, 6;
	@%p1012 bra 	BB0_1521;
	bra.uni 	BB0_1458;

BB0_1521:
	mov.u32 	%r7906, 16;
	// inline asm
	shf.r.wrap.b32 %r18, %r16, %r17, %r7906;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r17, %r15, %r16, %r7906;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r16, %r22, %r15, %r7906;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r7891, %r21, %r22, %r7906;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8837, %r20, %r21, %r7906;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8838, %r19, %r20, %r7906;
	// inline asm
	mov.u32 	%r8840, 0;
	// inline asm
	shf.r.wrap.b32 %r8839, %r8840, %r19, %r7906;
	// inline asm
	mov.u32 	%r19, %r7891;
	bra.uni 	BB0_1529;

BB0_361:
	setp.eq.s32	%p267, %r3498, 3;
	@%p267 bra 	BB0_362;
	bra.uni 	BB0_11;

BB0_362:
	and.b32  	%r3514, %r22, %r352;
	and.b32  	%r3515, %r3482, %r351;
	or.b32  	%r8845, %r3515, %r3514;
	bra.uni 	BB0_642;

BB0_155:
	setp.gt.s32	%p153, %r24, 13;
	@%p153 bra 	BB0_159;

	setp.eq.s32	%p156, %r24, 12;
	@%p156 bra 	BB0_209;
	bra.uni 	BB0_157;

BB0_209:
	mov.u32 	%r8688, %r19;
	mov.u32 	%r8689, %r8691;
	mov.u32 	%r8690, %r8691;
	mov.u32 	%r8692, %r15;
	mov.u32 	%r8693, %r22;
	mov.u32 	%r8694, %r21;
	mov.u32 	%r8695, %r20;
	bra.uni 	BB0_215;

BB0_239:
	setp.eq.s32	%p196, %r2840, 3;
	mov.u32 	%r8704, %r22;
	mov.u32 	%r8705, %r21;
	mov.u32 	%r8706, %r20;
	mov.u32 	%r8707, %r19;
	mov.u32 	%r8708, %r18;
	mov.u32 	%r8709, %r17;
	mov.u32 	%r8710, %r16;
	mov.u32 	%r8711, %r15;
	@%p196 bra 	BB0_240;
	bra.uni 	BB0_254;

BB0_240:
	and.b32  	%r8704, %r186, %r22;
	mov.u32 	%r8708, 0;
	mov.u32 	%r8705, %r21;
	mov.u32 	%r8706, %r20;
	mov.u32 	%r8707, %r19;
	mov.u32 	%r8709, %r8708;
	mov.u32 	%r8710, %r8708;
	mov.u32 	%r8711, %r8708;
	bra.uni 	BB0_254;

BB0_1205:
	setp.eq.s32	%p786, %r24, 22;
	@%p786 bra 	BB0_1227;
	bra.uni 	BB0_1206;

BB0_1227:
	mov.u32 	%r5615, 16;
	// inline asm
	shf.r.wrap.b32 %r22, %r16, %r17, %r5615;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8847, %r17, %r18, %r5615;
	// inline asm
	mov.u32 	%r8845, 0;
	// inline asm
	shf.r.wrap.b32 %r8846, %r18, %r8845, %r5615;
	// inline asm
	bra.uni 	BB0_1244;

BB0_1488:
	setp.eq.s32	%p989, %r7499, 22;
	@%p989 bra 	BB0_1511;
	bra.uni 	BB0_1489;

BB0_1511:
	mov.u32 	%r7606, 16;
	// inline asm
	shf.r.wrap.b32 %r18, %r20, %r21, %r7606;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r17, %r19, %r20, %r7606;
	// inline asm
	mov.u32 	%r8837, 0;
	// inline asm
	shf.r.wrap.b32 %r16, %r8837, %r19, %r7606;
	// inline asm
	bra.uni 	BB0_1491;

BB0_1189:
	setp.eq.s32	%p798, %r24, 14;
	@%p798 bra 	BB0_1233;
	bra.uni 	BB0_1190;

BB0_1233:
	mov.u32 	%r5749, 16;
	// inline asm
	shf.r.wrap.b32 %r22, %r22, %r15, %r5749;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8847, %r15, %r16, %r5749;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8846, %r16, %r17, %r5749;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8845, %r17, %r18, %r5749;
	// inline asm
	mov.u32 	%r8849, 0;
	// inline asm
	shf.r.wrap.b32 %r18, %r18, %r8849, %r5749;
	// inline asm
	bra.uni 	BB0_1235;

BB0_992:
	setp.ne.s32	%p673, %r4827, 7;
	@%p673 bra 	BB0_983;

	and.b32  	%r8849, %r904, %r18;
	mov.u32 	%r8845, %r22;
	mov.u32 	%r8846, %r21;
	mov.u32 	%r8847, %r20;
	mov.u32 	%r8848, %r19;
	mov.u32 	%r8850, %r17;
	bra.uni 	BB0_994;

BB0_983:
	mov.u32 	%r8845, %r22;
	mov.u32 	%r8846, %r21;
	mov.u32 	%r8847, %r20;
	mov.u32 	%r8848, %r19;
	mov.u32 	%r8849, %r18;
	mov.u32 	%r8850, %r17;

BB0_994:
	mov.u32 	%r8851, %r16;

BB0_995:
	mov.u32 	%r8852, %r15;
	mov.u32 	%r8853, %r24;
	bra.uni 	BB0_1554;

BB0_746:
	setp.gt.s32	%p466, %r14, 29;
	@%p466 bra 	BB0_750;

	setp.eq.s32	%p469, %r14, 28;
	@%p469 bra 	BB0_755;
	bra.uni 	BB0_748;

BB0_755:
	and.b32  	%r3779, %r17, 65535;
	shl.b32 	%r3780, %r17, 8;
	and.b32  	%r3781, %r3780, -16777216;
	or.b32  	%r3782, %r3781, %r3779;
	shr.u32 	%r3783, %r17, 8;
	and.b32  	%r3784, %r3783, 16711680;
	or.b32  	%r8850, %r3782, %r3784;
	mov.u32 	%r8853, 28;
	bra.uni 	BB0_757;

BB0_1472:
	setp.eq.s32	%p1001, %r7499, 14;
	@%p1001 bra 	BB0_1517;
	bra.uni 	BB0_1473;

BB0_1517:
	mov.u32 	%r7740, 16;
	// inline asm
	shf.r.wrap.b32 %r18, %r22, %r15, %r7740;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r17, %r21, %r22, %r7740;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r16, %r20, %r21, %r7740;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r7733, %r19, %r20, %r7740;
	// inline asm
	mov.u32 	%r8838, 0;
	// inline asm
	shf.r.wrap.b32 %r8837, %r8838, %r19, %r7740;
	// inline asm
	mov.u32 	%r8839, %r8838;
	mov.u32 	%r8840, %r8838;
	mov.u32 	%r19, %r7733;
	bra.uni 	BB0_1529;

BB0_368:
	setp.ne.s32	%p262, %r3498, 7;
	@%p262 bra 	BB0_11;

	mov.u32 	%r3504, 0;
	// inline asm
	shf.r.wrap.b32 %r3502, %r18, %r3504, %r3497;
	// inline asm
	and.b32  	%r3506, %r3502, %r351;
	and.b32  	%r3507, %r18, %r352;
	or.b32  	%r8849, %r3506, %r3507;
	bra.uni 	BB0_683;

BB0_191:
	setp.gt.s32	%p130, %r24, 29;
	@%p130 bra 	BB0_195;

	setp.eq.s32	%p133, %r24, 28;
	@%p133 bra 	BB0_200;
	bra.uni 	BB0_193;

BB0_200:
	mov.u32 	%r8688, %r8691;
	mov.u32 	%r8689, %r8691;
	mov.u32 	%r8690, %r8691;
	mov.u32 	%r8692, %r19;
	mov.u32 	%r8693, %r8691;

BB0_201:
	mov.u32 	%r8694, %r8691;
	mov.u32 	%r8695, %r8691;
	bra.uni 	BB0_215;

BB0_246:
	setp.ne.s32	%p191, %r2840, 7;
	mov.u32 	%r8704, %r22;
	mov.u32 	%r8705, %r21;
	mov.u32 	%r8706, %r20;
	mov.u32 	%r8707, %r19;
	mov.u32 	%r8708, %r18;
	mov.u32 	%r8709, %r17;
	mov.u32 	%r8710, %r16;
	mov.u32 	%r8711, %r15;
	@%p191 bra 	BB0_254;

	and.b32  	%r8708, %r186, %r18;
	mov.u32 	%r8704, %r22;
	mov.u32 	%r8705, %r21;
	mov.u32 	%r8706, %r20;
	mov.u32 	%r8707, %r19;
	mov.u32 	%r8709, %r17;

BB0_248:
	mov.u32 	%r8710, %r16;
	mov.u32 	%r8711, %r15;

BB0_254:
	setp.gt.s32	%p199, %r24, 15;
	@%p199 bra 	BB0_283;

	setp.gt.s32	%p223, %r24, 7;
	@%p223 bra 	BB0_268;

	setp.gt.s32	%p235, %r24, 3;
	@%p235 bra 	BB0_261;

	setp.eq.s32	%p241, %r24, 1;
	@%p241 bra 	BB0_332;

	setp.eq.s32	%p242, %r24, 2;
	@%p242 bra 	BB0_331;
	bra.uni 	BB0_259;

BB0_331:
	mov.u32 	%r3373, 16;
	// inline asm
	shf.r.wrap.b32 %r18, %r17, %r18, %r3373;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r17, %r16, %r17, %r3373;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r16, %r15, %r16, %r3373;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r3354, %r22, %r15, %r3373;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8712, %r21, %r22, %r3373;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8713, %r20, %r21, %r3373;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8714, %r19, %r20, %r3373;
	// inline asm
	mov.u32 	%r3371, 0;
	// inline asm
	shf.r.wrap.b32 %r8715, %r3371, %r19, %r3373;
	// inline asm
	mov.u32 	%r19, %r3354;
	bra.uni 	BB0_338;

BB0_283:
	setp.gt.s32	%p200, %r24, 23;
	@%p200 bra 	BB0_300;

	setp.gt.s32	%p212, %r24, 19;
	@%p212 bra 	BB0_292;

	setp.gt.s32	%p218, %r24, 17;
	@%p218 bra 	BB0_289;

	setp.eq.s32	%p221, %r24, 16;
	@%p221 bra 	BB0_324;
	bra.uni 	BB0_287;

BB0_324:
	mov.u32 	%r8712, 0;
	mov.u32 	%r8713, %r8712;
	mov.u32 	%r8714, %r8712;
	mov.u32 	%r8715, %r8712;
	mov.u32 	%r18, %r22;
	mov.u32 	%r17, %r21;
	mov.u32 	%r16, %r20;
	bra.uni 	BB0_338;

BB0_268:
	setp.gt.s32	%p224, %r24, 11;
	@%p224 bra 	BB0_276;

	setp.gt.s32	%p230, %r24, 9;
	@%p230 bra 	BB0_273;

	setp.eq.s32	%p233, %r24, 8;
	@%p233 bra 	BB0_328;
	bra.uni 	BB0_271;

BB0_328:
	mov.u32 	%r8714, 0;
	mov.u32 	%r8712, %r20;
	mov.u32 	%r8713, %r19;
	mov.u32 	%r8715, %r8714;
	mov.u32 	%r18, %r16;
	mov.u32 	%r17, %r15;
	mov.u32 	%r16, %r22;
	mov.u32 	%r19, %r21;
	bra.uni 	BB0_338;

BB0_300:
	setp.gt.s32	%p201, %r24, 27;
	@%p201 bra 	BB0_309;

	setp.gt.s32	%p207, %r24, 25;
	@%p207 bra 	BB0_305;

	setp.eq.s32	%p210, %r24, 24;
	@%p210 bra 	BB0_318;
	bra.uni 	BB0_303;

BB0_318:
	mov.u32 	%r8712, 0;
	mov.u32 	%r8713, %r8712;
	mov.u32 	%r8714, %r8712;
	mov.u32 	%r8715, %r8712;
	mov.u32 	%r18, %r20;
	mov.u32 	%r17, %r19;
	bra.uni 	BB0_336;

BB0_1221:
	setp.eq.s32	%p775, %r24, 31;
	@%p775 bra 	BB0_1242;
	bra.uni 	BB0_1222;

BB0_1242:
	mov.u32 	%r8845, 0;
	mov.u32 	%r6046, 24;
	// inline asm
	shf.r.wrap.b32 %r22, %r18, %r8845, %r6046;
	// inline asm
	bra.uni 	BB0_1243;

BB0_1505:
	setp.eq.s32	%p978, %r7499, 31;
	@%p978 bra 	BB0_1524;
	bra.uni 	BB0_1506;

BB0_1524:
	mov.u32 	%r8837, 0;
	mov.u32 	%r8037, 8;
	// inline asm
	shf.r.wrap.b32 %r18, %r8837, %r19, %r8037;
	// inline asm
	bra.uni 	BB0_1525;

BB0_261:
	setp.gt.s32	%p236, %r24, 5;
	@%p236 bra 	BB0_265;

	setp.eq.s32	%p239, %r24, 4;
	@%p239 bra 	BB0_330;
	bra.uni 	BB0_263;

BB0_330:
	mov.u32 	%r8715, 0;
	mov.u32 	%r8712, %r21;
	mov.u32 	%r8713, %r20;
	mov.u32 	%r8714, %r19;
	mov.u32 	%r18, %r17;
	mov.u32 	%r17, %r16;
	mov.u32 	%r16, %r15;
	mov.u32 	%r19, %r22;
	bra.uni 	BB0_338;

BB0_292:
	setp.gt.s32	%p213, %r24, 21;
	@%p213 bra 	BB0_296;

	setp.eq.s32	%p216, %r24, 20;
	@%p216 bra 	BB0_320;
	bra.uni 	BB0_294;

BB0_320:
	mov.u32 	%r8712, 0;
	mov.u32 	%r8713, %r8712;
	mov.u32 	%r8714, %r8712;
	mov.u32 	%r8715, %r8712;
	mov.u32 	%r18, %r21;
	mov.u32 	%r17, %r20;
	mov.u32 	%r16, %r19;
	bra.uni 	BB0_337;

BB0_276:
	setp.gt.s32	%p225, %r24, 13;
	@%p225 bra 	BB0_280;

	setp.eq.s32	%p228, %r24, 12;
	@%p228 bra 	BB0_326;
	bra.uni 	BB0_278;

BB0_326:
	mov.u32 	%r8713, 0;
	mov.u32 	%r8712, %r19;
	mov.u32 	%r8714, %r8713;
	mov.u32 	%r8715, %r8713;
	mov.u32 	%r18, %r15;
	mov.u32 	%r17, %r22;
	mov.u32 	%r16, %r21;
	mov.u32 	%r19, %r20;
	bra.uni 	BB0_338;

BB0_309:
	setp.gt.s32	%p202, %r24, 29;
	@%p202 bra 	BB0_313;

	setp.eq.s32	%p205, %r24, 28;
	@%p205 bra 	BB0_316;
	bra.uni 	BB0_311;

BB0_316:
	mov.u32 	%r8712, 0;
	mov.u32 	%r8713, %r8712;
	mov.u32 	%r8714, %r8712;
	mov.u32 	%r8715, %r8712;
	mov.u32 	%r18, %r19;
	bra.uni 	BB0_335;

BB0_1241:
	mov.u32 	%r6042, 8;
	// inline asm
	shf.r.wrap.b32 %r6011, %r19, %r20, %r6042;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8847, %r20, %r21, %r6042;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8846, %r21, %r22, %r6042;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8845, %r22, %r15, %r6042;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6027, %r15, %r16, %r6042;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8851, %r16, %r17, %r6042;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8850, %r17, %r18, %r6042;
	// inline asm
	mov.u32 	%r6041, 0;
	// inline asm
	shf.r.wrap.b32 %r8849, %r18, %r6041, %r6042;
	// inline asm
	mov.u32 	%r22, %r6011;
	mov.u32 	%r18, %r6027;
	bra.uni 	BB0_1245;

BB0_1168:
	setp.eq.s32	%p815, %r24, 3;
	@%p815 bra 	BB0_1169;
	bra.uni 	BB0_1191;

BB0_1169:
	mov.u32 	%r5978, 24;
	// inline asm
	shf.r.wrap.b32 %r5947, %r19, %r20, %r5978;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8847, %r20, %r21, %r5978;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8846, %r21, %r22, %r5978;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8845, %r22, %r15, %r5978;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5963, %r15, %r16, %r5978;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8851, %r16, %r17, %r5978;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8850, %r17, %r18, %r5978;
	// inline asm
	mov.u32 	%r5977, 0;
	// inline asm
	shf.r.wrap.b32 %r8849, %r18, %r5977, %r5978;
	// inline asm
	mov.u32 	%r22, %r5947;
	mov.u32 	%r18, %r5963;
	bra.uni 	BB0_1245;

BB0_1060:
	setp.eq.s32	%p753, %r26, 2;
	@%p753 bra 	BB0_1135;
	bra.uni 	BB0_1061;

BB0_1135:
	mov.u32 	%r5455, 16;
	// inline asm
	shf.r.wrap.b32 %r8766, %r19, %r20, %r5455;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8847, %r20, %r21, %r5455;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8846, %r21, %r22, %r5455;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8845, %r22, %r15, %r5455;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8852, %r15, %r16, %r5455;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8851, %r16, %r17, %r5455;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8850, %r17, %r18, %r5455;
	// inline asm
	mov.u32 	%r5454, 0;
	// inline asm
	shf.r.wrap.b32 %r8849, %r18, %r5454, %r5455;
	// inline asm
	bra.uni 	BB0_1137;

BB0_1523:
	mov.u32 	%r8033, 24;
	// inline asm
	shf.r.wrap.b32 %r18, %r17, %r18, %r8033;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r17, %r16, %r17, %r8033;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r16, %r15, %r16, %r8033;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8014, %r22, %r15, %r8033;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8837, %r21, %r22, %r8033;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8838, %r20, %r21, %r8033;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8839, %r19, %r20, %r8033;
	// inline asm
	mov.u32 	%r8031, 0;
	// inline asm
	shf.r.wrap.b32 %r8840, %r8031, %r19, %r8033;
	// inline asm
	mov.u32 	%r19, %r8014;
	bra.uni 	BB0_1529;

BB0_1451:
	setp.eq.s32	%p1018, %r7499, 3;
	@%p1018 bra 	BB0_1452;
	bra.uni 	BB0_1483;

BB0_1452:
	mov.u32 	%r7969, 8;
	// inline asm
	shf.r.wrap.b32 %r18, %r17, %r18, %r7969;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r17, %r16, %r17, %r7969;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r16, %r15, %r16, %r7969;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r7950, %r22, %r15, %r7969;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8837, %r21, %r22, %r7969;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8838, %r20, %r21, %r7969;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8839, %r19, %r20, %r7969;
	// inline asm
	mov.u32 	%r7967, 0;
	// inline asm
	shf.r.wrap.b32 %r8840, %r7967, %r19, %r7969;
	// inline asm
	mov.u32 	%r19, %r7950;
	bra.uni 	BB0_1529;

BB0_456:
	setp.eq.s32	%p364, %r24, 2;
	@%p364 bra 	BB0_526;
	bra.uni 	BB0_457;

BB0_526:
	bfe.u32 	%r8720, %r19, 16, 8;
	bra.uni 	BB0_528;

BB0_342:
	setp.eq.s32	%p257, %r3445, 1;
	@%p257 bra 	BB0_343;
	bra.uni 	BB0_11;

BB0_343:
	and.b32  	%r3461, %r20, %r335;
	and.b32  	%r3462, %r3441, %r334;
	or.b32  	%r8847, %r3462, %r3461;
	bra.uni 	BB0_625;

BB0_1319:
	setp.gt.s32	%p926, %r6374, 5;
	@%p926 bra 	BB0_1323;

	setp.eq.s32	%p929, %r6374, 4;
	@%p929 bra 	BB0_1392;
	bra.uni 	BB0_1321;

BB0_1392:
	mov.u32 	%r8795, %r21;
	mov.u32 	%r8796, %r20;
	mov.u32 	%r8797, %r19;
	mov.u32 	%r8798, %r8803;
	mov.u32 	%r8799, %r17;
	mov.u32 	%r8800, %r16;
	mov.u32 	%r8801, %r15;
	mov.u32 	%r8802, %r22;
	bra.uni 	BB0_1394;

BB0_413:
	setp.eq.s32	%p305, %r3594, 1;
	@%p305 bra 	BB0_414;
	bra.uni 	BB0_11;

BB0_414:
	and.b32  	%r3622, %r20, %r384;
	and.b32  	%r3623, %r383, %r20;
	shr.u32 	%r3624, %r3623, 1;
	and.b32  	%r3625, %r3624, %r383;
	or.b32  	%r8847, %r3625, %r3622;
	bra.uni 	BB0_625;

BB0_1268:
	setp.eq.s32	%p838, %r6119, 1;
	@%p838 bra 	BB0_1269;
	bra.uni 	BB0_1281;

BB0_1269:
	and.b32  	%r6136, %r1210, %r20;
	and.b32  	%r6137, %r8847, %r1211;
	or.b32  	%r8847, %r6137, %r6136;
	mov.u32 	%r8848, %r19;
	bra.uni 	BB0_1278;

BB0_131:
	setp.eq.s32	%p868, %r6221, 1;
	@%p868 bra 	BB0_1306;
	bra.uni 	BB0_132;

BB0_1306:
	and.b32  	%r8847, %r8847, %r1255;
	mov.u32 	%r8845, 0;
	mov.u32 	%r8846, %r8845;

BB0_1305:
	mov.u32 	%r8849, %r8845;
	mov.u32 	%r8850, %r8845;
	mov.u32 	%r8851, %r8845;
	mov.u32 	%r8852, %r8845;
	bra.uni 	BB0_1553;

BB0_1092:
	setp.eq.s32	%p730, %r26, 18;
	@%p730 bra 	BB0_1127;
	bra.uni 	BB0_1093;

BB0_1127:
	mov.u32 	%r5123, 16;
	// inline asm
	shf.r.wrap.b32 %r8766, %r15, %r16, %r5123;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8847, %r16, %r17, %r5123;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8846, %r17, %r18, %r5123;
	// inline asm
	mov.u32 	%r8849, 0;
	// inline asm
	shf.r.wrap.b32 %r8845, %r18, %r8849, %r5123;
	// inline asm
	bra.uni 	BB0_1122;

BB0_487:
	setp.eq.s32	%p341, %r24, 18;
	@%p341 bra 	BB0_518;
	bra.uni 	BB0_488;

BB0_518:
	bfe.u32 	%r8720, %r15, 16, 8;
	bra.uni 	BB0_528;

BB0_825:
	setp.eq.s32	%p554, %r24, 18;
	@%p554 bra 	BB0_859;
	bra.uni 	BB0_826;

BB0_859:
	mov.u32 	%r4165, 16;
	// inline asm
	shf.r.wrap.b32 %r18, %r21, %r22, %r4165;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r17, %r20, %r21, %r4165;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r16, %r19, %r20, %r4165;
	// inline asm
	mov.u32 	%r8845, 0;
	// inline asm
	shf.r.wrap.b32 %r15, %r8845, %r19, %r4165;
	// inline asm
	bra.uni 	BB0_858;

BB0_1075:
	setp.eq.s32	%p742, %r26, 10;
	@%p742 bra 	BB0_1131;
	bra.uni 	BB0_1076;

BB0_1131:
	mov.u32 	%r5273, 16;
	// inline asm
	shf.r.wrap.b32 %r8766, %r21, %r22, %r5273;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8847, %r22, %r15, %r5273;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8846, %r15, %r16, %r5273;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8845, %r16, %r17, %r5273;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8852, %r17, %r18, %r5273;
	// inline asm
	mov.u32 	%r8849, 0;
	// inline asm
	shf.r.wrap.b32 %r8851, %r18, %r8849, %r5273;
	// inline asm
	mov.u32 	%r8850, %r8849;
	bra.uni 	BB0_1137;

BB0_471:
	setp.eq.s32	%p353, %r24, 10;
	@%p353 bra 	BB0_522;
	bra.uni 	BB0_472;

BB0_522:
	bfe.u32 	%r8720, %r21, 16, 8;
	bra.uni 	BB0_528;

BB0_349:
	setp.eq.s32	%p252, %r3445, 5;
	@%p252 bra 	BB0_350;
	bra.uni 	BB0_11;

BB0_350:
	and.b32  	%r3453, %r16, %r335;
	and.b32  	%r3454, %r3425, %r334;
	or.b32  	%r8851, %r3454, %r3453;
	bra.uni 	BB0_666;

BB0_1352:
	setp.gt.s32	%p903, %r6374, 21;
	@%p903 bra 	BB0_1356;

	setp.eq.s32	%p906, %r6374, 20;
	@%p906 bra 	BB0_1384;
	bra.uni 	BB0_1354;

BB0_1384:
	mov.u32 	%r8795, %r8803;
	mov.u32 	%r8796, %r8803;
	mov.u32 	%r8797, %r8803;
	mov.u32 	%r8798, %r8803;
	mov.u32 	%r8799, %r21;
	mov.u32 	%r8800, %r20;
	mov.u32 	%r8801, %r19;
	mov.u32 	%r8802, %r8803;
	bra.uni 	BB0_1394;

BB0_420:
	setp.eq.s32	%p300, %r3594, 5;
	@%p300 bra 	BB0_421;
	bra.uni 	BB0_11;

BB0_421:
	and.b32  	%r3606, %r16, %r384;
	and.b32  	%r3607, %r383, %r16;
	shr.u32 	%r3608, %r3607, 1;
	and.b32  	%r3609, %r3608, %r383;
	or.b32  	%r8851, %r3609, %r3606;
	bra.uni 	BB0_666;

BB0_1275:
	setp.eq.s32	%p833, %r6119, 5;
	@%p833 bra 	BB0_1276;
	bra.uni 	BB0_1281;

BB0_1276:
	and.b32  	%r6128, %r1210, %r16;
	and.b32  	%r6129, %r8851, %r1211;
	or.b32  	%r8851, %r6129, %r6128;
	mov.u32 	%r8845, %r22;
	mov.u32 	%r8846, %r21;
	mov.u32 	%r8847, %r20;
	mov.u32 	%r8848, %r19;
	bra.uni 	BB0_1277;

BB0_808:
	setp.eq.s32	%p566, %r24, 10;
	@%p566 bra 	BB0_863;
	bra.uni 	BB0_809;

BB0_863:
	mov.u32 	%r4315, 16;
	// inline asm
	shf.r.wrap.b32 %r18, %r15, %r16, %r4315;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r17, %r22, %r15, %r4315;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r16, %r21, %r22, %r4315;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r15, %r20, %r21, %r4315;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8845, %r19, %r20, %r4315;
	// inline asm
	mov.u32 	%r8847, 0;
	// inline asm
	shf.r.wrap.b32 %r8846, %r8847, %r19, %r4315;
	// inline asm
	mov.u32 	%r8848, %r8847;
	bra.uni 	BB0_874;

BB0_1297:
	setp.eq.s32	%p863, %r6221, 5;
	@%p863 bra 	BB0_1298;
	bra.uni 	BB0_132;

BB0_1298:
	and.b32  	%r8851, %r8851, %r1255;
	mov.u32 	%r8849, 0;
	mov.u32 	%r8850, %r8849;
	bra.uni 	BB0_1553;

BB0_1107:
	setp.eq.s32	%p719, %r26, 26;
	@%p719 bra 	BB0_1123;
	bra.uni 	BB0_1108;

BB0_1123:
	mov.u32 	%r5005, 16;
	// inline asm
	shf.r.wrap.b32 %r8766, %r17, %r18, %r5005;
	// inline asm
	mov.u32 	%r8845, 0;
	// inline asm
	shf.r.wrap.b32 %r8847, %r18, %r8845, %r5005;
	// inline asm
	bra.uni 	BB0_1110;

BB0_502:
	setp.eq.s32	%p330, %r24, 26;
	@%p330 bra 	BB0_514;
	bra.uni 	BB0_503;

BB0_514:
	bfe.u32 	%r8720, %r17, 16, 8;
	bra.uni 	BB0_528;

BB0_841:
	setp.eq.s32	%p543, %r24, 26;
	@%p543 bra 	BB0_853;
	bra.uni 	BB0_842;

BB0_853:
	mov.u32 	%r4047, 16;
	// inline asm
	shf.r.wrap.b32 %r18, %r19, %r20, %r4047;
	// inline asm
	mov.u32 	%r8845, 0;
	// inline asm
	shf.r.wrap.b32 %r17, %r8845, %r19, %r4047;
	// inline asm
	bra.uni 	BB0_844;

BB0_1067:
	setp.eq.s32	%p748, %r26, 6;
	@%p748 bra 	BB0_1133;
	bra.uni 	BB0_1068;

BB0_1133:
	mov.u32 	%r5360, 16;
	// inline asm
	shf.r.wrap.b32 %r8766, %r20, %r21, %r5360;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8847, %r21, %r22, %r5360;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8846, %r22, %r15, %r5360;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8845, %r15, %r16, %r5360;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8852, %r16, %r17, %r5360;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8851, %r17, %r18, %r5360;
	// inline asm
	mov.u32 	%r8849, 0;
	// inline asm
	shf.r.wrap.b32 %r8850, %r18, %r8849, %r5360;
	// inline asm
	bra.uni 	BB0_1137;

BB0_463:
	setp.eq.s32	%p359, %r24, 6;
	@%p359 bra 	BB0_524;
	bra.uni 	BB0_464;

BB0_524:
	bfe.u32 	%r8720, %r20, 16, 8;
	bra.uni 	BB0_528;

BB0_345:
	setp.eq.s32	%p255, %r3445, 3;
	@%p255 bra 	BB0_346;
	bra.uni 	BB0_11;

BB0_346:
	and.b32  	%r3457, %r22, %r335;
	and.b32  	%r3458, %r3433, %r334;
	or.b32  	%r8845, %r3458, %r3457;
	bra.uni 	BB0_642;

BB0_1334:
	setp.gt.s32	%p915, %r6374, 13;
	@%p915 bra 	BB0_1338;

	setp.eq.s32	%p918, %r6374, 12;
	@%p918 bra 	BB0_1388;
	bra.uni 	BB0_1336;

BB0_1388:
	mov.u32 	%r8795, %r19;
	mov.u32 	%r8796, %r8803;
	mov.u32 	%r8797, %r8803;
	mov.u32 	%r8798, %r8803;
	mov.u32 	%r8799, %r15;
	mov.u32 	%r8800, %r22;
	mov.u32 	%r8801, %r21;
	mov.u32 	%r8802, %r20;
	bra.uni 	BB0_1394;

BB0_416:
	setp.eq.s32	%p303, %r3594, 3;
	@%p303 bra 	BB0_417;
	bra.uni 	BB0_11;

BB0_417:
	and.b32  	%r3614, %r22, %r384;
	and.b32  	%r3615, %r383, %r22;
	shr.u32 	%r3616, %r3615, 1;
	and.b32  	%r3617, %r3616, %r383;
	or.b32  	%r8845, %r3617, %r3614;
	bra.uni 	BB0_642;

BB0_1271:
	setp.eq.s32	%p836, %r6119, 3;
	@%p836 bra 	BB0_1272;
	bra.uni 	BB0_1281;

BB0_1272:
	and.b32  	%r6132, %r1210, %r22;
	and.b32  	%r6133, %r8845, %r1211;
	or.b32  	%r8845, %r6133, %r6132;

BB0_1287:
	mov.u32 	%r8846, %r21;

BB0_1288:
	mov.u32 	%r8847, %r20;
	mov.u32 	%r8848, %r19;
	bra.uni 	BB0_1278;

BB0_800:
	setp.eq.s32	%p572, %r24, 6;
	@%p572 bra 	BB0_865;
	bra.uni 	BB0_801;

BB0_865:
	mov.u32 	%r4402, 16;
	// inline asm
	shf.r.wrap.b32 %r18, %r16, %r17, %r4402;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r17, %r15, %r16, %r4402;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r16, %r22, %r15, %r4402;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r15, %r21, %r22, %r4402;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8845, %r20, %r21, %r4402;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8846, %r19, %r20, %r4402;
	// inline asm
	mov.u32 	%r8848, 0;
	// inline asm
	shf.r.wrap.b32 %r8847, %r8848, %r19, %r4402;
	// inline asm
	bra.uni 	BB0_874;

BB0_1293:
	setp.eq.s32	%p866, %r6221, 3;
	@%p866 bra 	BB0_1294;
	bra.uni 	BB0_132;

BB0_1294:
	and.b32  	%r8845, %r8845, %r1255;
	mov.u32 	%r8849, 0;
	mov.u32 	%r8850, %r8849;
	mov.u32 	%r8851, %r8849;
	mov.u32 	%r8852, %r8849;
	bra.uni 	BB0_1553;

BB0_1099:
	setp.eq.s32	%p725, %r26, 22;
	@%p725 bra 	BB0_1125;
	bra.uni 	BB0_1100;

BB0_1125:
	mov.u32 	%r5060, 16;
	// inline asm
	shf.r.wrap.b32 %r8766, %r16, %r17, %r5060;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8847, %r17, %r18, %r5060;
	// inline asm
	mov.u32 	%r8845, 0;
	// inline asm
	shf.r.wrap.b32 %r8846, %r18, %r8845, %r5060;
	// inline asm
	bra.uni 	BB0_1111;

BB0_494:
	setp.eq.s32	%p336, %r24, 22;
	@%p336 bra 	BB0_516;
	bra.uni 	BB0_495;

BB0_516:
	bfe.u32 	%r8720, %r16, 16, 8;
	bra.uni 	BB0_528;

BB0_832:
	setp.eq.s32	%p549, %r24, 22;
	@%p549 bra 	BB0_855;
	bra.uni 	BB0_833;

BB0_855:
	mov.u32 	%r4102, 16;
	// inline asm
	shf.r.wrap.b32 %r18, %r20, %r21, %r4102;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r17, %r19, %r20, %r4102;
	// inline asm
	mov.u32 	%r8845, 0;
	// inline asm
	shf.r.wrap.b32 %r16, %r8845, %r19, %r4102;
	// inline asm
	bra.uni 	BB0_835;

BB0_1082:
	setp.eq.s32	%p737, %r26, 14;
	@%p737 bra 	BB0_1129;
	bra.uni 	BB0_1083;

BB0_1129:
	mov.u32 	%r5194, 16;
	// inline asm
	shf.r.wrap.b32 %r8766, %r22, %r15, %r5194;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8847, %r15, %r16, %r5194;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8846, %r16, %r17, %r5194;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8845, %r17, %r18, %r5194;
	// inline asm
	mov.u32 	%r8849, 0;
	// inline asm
	shf.r.wrap.b32 %r8852, %r18, %r8849, %r5194;
	// inline asm
	bra.uni 	BB0_1085;

BB0_478:
	setp.eq.s32	%p348, %r24, 14;
	@%p348 bra 	BB0_520;
	bra.uni 	BB0_479;

BB0_520:
	bfe.u32 	%r8720, %r22, 16, 8;
	bra.uni 	BB0_528;

BB0_352:
	setp.ne.s32	%p250, %r3445, 7;
	@%p250 bra 	BB0_11;

	and.b32  	%r3449, %r18, %r335;
	and.b32  	%r3450, %r3417, %r334;
	or.b32  	%r8849, %r3450, %r3449;
	bra.uni 	BB0_683;

BB0_1370:
	setp.gt.s32	%p892, %r6374, 29;
	@%p892 bra 	BB0_1374;

	setp.eq.s32	%p895, %r6374, 28;
	@%p895 bra 	BB0_1379;
	bra.uni 	BB0_1372;

BB0_1379:
	mov.u32 	%r8795, %r8803;
	mov.u32 	%r8796, %r8803;
	mov.u32 	%r8797, %r8803;
	mov.u32 	%r8798, %r8803;
	mov.u32 	%r8799, %r19;
	mov.u32 	%r8800, %r8803;

BB0_1380:
	mov.u32 	%r8801, %r8803;
	mov.u32 	%r8802, %r8803;
	bra.uni 	BB0_1394;

BB0_423:
	setp.ne.s32	%p298, %r3594, 7;
	@%p298 bra 	BB0_11;

	and.b32  	%r3598, %r18, %r384;
	and.b32  	%r3599, %r383, %r18;
	shr.u32 	%r3600, %r3599, 1;
	and.b32  	%r3601, %r3600, %r383;
	or.b32  	%r8849, %r3601, %r3598;
	bra.uni 	BB0_683;

BB0_1280:
	setp.ne.s32	%p831, %r6119, 7;
	@%p831 bra 	BB0_1281;

	and.b32  	%r6124, %r1210, %r18;
	and.b32  	%r6125, %r8849, %r1211;
	or.b32  	%r8849, %r6125, %r6124;
	mov.u32 	%r8845, %r22;
	mov.u32 	%r8846, %r21;
	mov.u32 	%r8847, %r20;
	mov.u32 	%r8848, %r19;
	bra.uni 	BB0_1282;

BB0_1281:
	mov.u32 	%r8845, %r22;
	mov.u32 	%r8846, %r21;
	mov.u32 	%r8847, %r20;
	mov.u32 	%r8848, %r19;
	mov.u32 	%r8849, %r18;

BB0_1282:
	mov.u32 	%r8850, %r17;

BB0_1283:
	mov.u32 	%r8851, %r16;

BB0_1277:
	mov.u32 	%r8852, %r15;

BB0_1278:
	add.s32 	%r8853, %r14, -1;
	bra.uni 	BB0_1554;

BB0_815:
	setp.eq.s32	%p561, %r24, 14;
	@%p561 bra 	BB0_861;
	bra.uni 	BB0_816;

BB0_861:
	mov.u32 	%r4236, 16;
	// inline asm
	shf.r.wrap.b32 %r18, %r22, %r15, %r4236;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r17, %r21, %r22, %r4236;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r16, %r20, %r21, %r4236;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r15, %r19, %r20, %r4236;
	// inline asm
	mov.u32 	%r8846, 0;
	// inline asm
	shf.r.wrap.b32 %r8845, %r8846, %r19, %r4236;
	// inline asm
	bra.uni 	BB0_818;

BB0_1300:
	setp.ne.s32	%p861, %r6221, 7;
	@%p861 bra 	BB0_132;

	and.b32  	%r8849, %r6189, %r1255;
	bra.uni 	BB0_1553;

BB0_132:
	mov.u32 	%r8849, %r6189;
	bra.uni 	BB0_1553;

BB0_1116:
	setp.eq.s32	%p714, %r26, 30;
	@%p714 bra 	BB0_1120;
	bra.uni 	BB0_1117;

BB0_1120:
	mov.u32 	%r8845, 0;
	mov.u32 	%r4958, 16;
	// inline asm
	shf.r.wrap.b32 %r8766, %r18, %r8845, %r4958;
	// inline asm
	bra.uni 	BB0_1119;

BB0_509:
	setp.eq.s32	%p325, %r24, 30;
	@%p325 bra 	BB0_512;
	bra.uni 	BB0_510;

BB0_512:
	bfe.u32 	%r8720, %r18, 16, 8;
	bra.uni 	BB0_528;

BB0_849:
	setp.eq.s32	%p538, %r24, 31;
	@%p538 bra 	BB0_869;
	bra.uni 	BB0_850;

BB0_869:
	mov.u32 	%r8845, 0;
	mov.u32 	%r4533, 8;
	// inline asm
	shf.r.wrap.b32 %r18, %r8845, %r19, %r4533;
	// inline asm
	bra.uni 	BB0_870;

BB0_137:
	setp.eq.s32	%p170, %r24, 2;
	@%p170 bra 	BB0_214;
	bra.uni 	BB0_138;

BB0_214:
	mov.u32 	%r2775, 16;
	// inline asm
	shf.r.wrap.b32 %r8692, %r17, %r18, %r2775;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8693, %r16, %r17, %r2775;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8694, %r15, %r16, %r2775;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8695, %r22, %r15, %r2775;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8688, %r21, %r22, %r2775;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8689, %r20, %r21, %r2775;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8690, %r19, %r20, %r2775;
	// inline asm
	mov.u32 	%r2773, 0;
	// inline asm
	shf.r.wrap.b32 %r8691, %r2773, %r19, %r2775;
	// inline asm
	bra.uni 	BB0_215;

BB0_1196:
	setp.eq.s32	%p794, %r24, 17;
	@%p794 bra 	BB0_1197;
	bra.uni 	BB0_1191;

BB0_1197:
	mov.u32 	%r5698, 8;
	// inline asm
	shf.r.wrap.b32 %r22, %r15, %r16, %r5698;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8847, %r16, %r17, %r5698;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8846, %r17, %r18, %r5698;
	// inline asm
	mov.u32 	%r8849, 0;
	// inline asm
	shf.r.wrap.b32 %r8845, %r18, %r8849, %r5698;
	// inline asm
	bra.uni 	BB0_1231;

BB0_1479:
	setp.eq.s32	%p997, %r7499, 17;
	@%p997 bra 	BB0_1480;
	bra.uni 	BB0_1483;

BB0_1480:
	mov.u32 	%r7689, 24;
	// inline asm
	shf.r.wrap.b32 %r18, %r21, %r22, %r7689;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r17, %r20, %r21, %r7689;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r16, %r19, %r20, %r7689;
	// inline asm
	mov.u32 	%r8837, 0;
	// inline asm
	shf.r.wrap.b32 %r19, %r8837, %r19, %r7689;
	// inline asm
	bra.uni 	BB0_1514;

BB0_1180:
	setp.eq.s32	%p806, %r24, 9;
	@%p806 bra 	BB0_1181;
	bra.uni 	BB0_1191;

BB0_1181:
	mov.u32 	%r5854, 8;
	// inline asm
	shf.r.wrap.b32 %r5831, %r21, %r22, %r5854;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8847, %r22, %r15, %r5854;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8846, %r15, %r16, %r5854;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8845, %r16, %r17, %r5854;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5847, %r17, %r18, %r5854;
	// inline asm
	mov.u32 	%r8849, 0;
	// inline asm
	shf.r.wrap.b32 %r8851, %r18, %r8849, %r5854;
	// inline asm
	mov.u32 	%r22, %r5831;
	mov.u32 	%r8850, %r8849;
	mov.u32 	%r18, %r5847;
	bra.uni 	BB0_1245;

BB0_1463:
	setp.eq.s32	%p1009, %r7499, 9;
	@%p1009 bra 	BB0_1464;
	bra.uni 	BB0_1483;

BB0_1464:
	mov.u32 	%r7845, 24;
	// inline asm
	shf.r.wrap.b32 %r18, %r15, %r16, %r7845;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r17, %r22, %r15, %r7845;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r16, %r21, %r22, %r7845;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r7834, %r20, %r21, %r7845;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8837, %r19, %r20, %r7845;
	// inline asm
	mov.u32 	%r8839, 0;
	// inline asm
	shf.r.wrap.b32 %r8838, %r8839, %r19, %r7845;
	// inline asm
	mov.u32 	%r8840, %r8839;
	mov.u32 	%r19, %r7834;
	bra.uni 	BB0_1529;

BB0_169:
	setp.eq.s32	%p147, %r24, 18;
	@%p147 bra 	BB0_206;
	bra.uni 	BB0_170;

BB0_206:
	mov.u32 	%r2443, 16;
	// inline asm
	shf.r.wrap.b32 %r8692, %r21, %r22, %r2443;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8693, %r20, %r21, %r2443;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8694, %r19, %r20, %r2443;
	// inline asm
	mov.u32 	%r8688, 0;
	// inline asm
	shf.r.wrap.b32 %r8695, %r8688, %r19, %r2443;
	// inline asm
	bra.uni 	BB0_172;

BB0_1211:
	setp.eq.s32	%p783, %r24, 25;
	@%p783 bra 	BB0_1212;
	bra.uni 	BB0_1191;

BB0_1212:
	mov.u32 	%r5574, 8;
	// inline asm
	shf.r.wrap.b32 %r22, %r17, %r18, %r5574;
	// inline asm
	mov.u32 	%r8845, 0;
	// inline asm
	shf.r.wrap.b32 %r8847, %r18, %r8845, %r5574;
	// inline asm
	bra.uni 	BB0_1216;

BB0_1495:
	setp.eq.s32	%p986, %r7499, 25;
	@%p986 bra 	BB0_1496;
	bra.uni 	BB0_1483;

BB0_1496:
	mov.u32 	%r7565, 24;
	// inline asm
	shf.r.wrap.b32 %r18, %r19, %r20, %r7565;
	// inline asm
	mov.u32 	%r8837, 0;
	// inline asm
	shf.r.wrap.b32 %r17, %r8837, %r19, %r7565;
	// inline asm
	bra.uni 	BB0_1500;

BB0_1172:
	setp.eq.s32	%p812, %r24, 5;
	@%p812 bra 	BB0_1173;
	bra.uni 	BB0_1191;

BB0_1173:
	mov.u32 	%r5944, 8;
	// inline asm
	shf.r.wrap.b32 %r5917, %r20, %r21, %r5944;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8847, %r21, %r22, %r5944;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8846, %r22, %r15, %r5944;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8845, %r15, %r16, %r5944;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5933, %r16, %r17, %r5944;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8851, %r17, %r18, %r5944;
	// inline asm
	mov.u32 	%r8849, 0;
	// inline asm
	shf.r.wrap.b32 %r8850, %r18, %r8849, %r5944;
	// inline asm
	mov.u32 	%r22, %r5917;
	mov.u32 	%r18, %r5933;
	bra.uni 	BB0_1245;

BB0_714:
	setp.eq.s32	%p493, %r14, 11;
	@%p493 bra 	BB0_775;
	bra.uni 	BB0_715;

BB0_775:
	and.b32  	%r3870, %r21, 255;
	shl.b32 	%r3871, %r21, 8;
	and.b32  	%r3872, %r3871, 16711680;
	or.b32  	%r3873, %r3872, %r3870;
	shr.u32 	%r3874, %r21, 8;
	and.b32  	%r3875, %r3874, 65280;
	or.b32  	%r8846, %r3873, %r3875;
	mov.u32 	%r8853, 11;
	bra.uni 	BB0_776;

BB0_1455:
	setp.eq.s32	%p1015, %r7499, 5;
	@%p1015 bra 	BB0_1456;
	bra.uni 	BB0_1483;

BB0_1456:
	mov.u32 	%r7935, 24;
	// inline asm
	shf.r.wrap.b32 %r18, %r16, %r17, %r7935;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r17, %r15, %r16, %r7935;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r16, %r22, %r15, %r7935;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r7920, %r21, %r22, %r7935;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8837, %r20, %r21, %r7935;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8838, %r19, %r20, %r7935;
	// inline asm
	mov.u32 	%r8840, 0;
	// inline asm
	shf.r.wrap.b32 %r8839, %r8840, %r19, %r7935;
	// inline asm
	mov.u32 	%r19, %r7920;
	bra.uni 	BB0_1529;

BB0_152:
	setp.eq.s32	%p159, %r24, 10;
	@%p159 bra 	BB0_210;
	bra.uni 	BB0_153;

BB0_210:
	mov.u32 	%r2593, 16;
	// inline asm
	shf.r.wrap.b32 %r8692, %r15, %r16, %r2593;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8693, %r22, %r15, %r2593;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8694, %r21, %r22, %r2593;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8695, %r20, %r21, %r2593;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8688, %r19, %r20, %r2593;
	// inline asm
	mov.u32 	%r8690, 0;
	// inline asm
	shf.r.wrap.b32 %r8689, %r8690, %r19, %r2593;
	// inline asm
	mov.u32 	%r8691, %r8690;
	bra.uni 	BB0_215;

BB0_1203:
	setp.eq.s32	%p789, %r24, 21;
	@%p789 bra 	BB0_1204;
	bra.uni 	BB0_1191;

BB0_1204:
	mov.u32 	%r5632, 8;
	// inline asm
	shf.r.wrap.b32 %r22, %r16, %r17, %r5632;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8847, %r17, %r18, %r5632;
	// inline asm
	mov.u32 	%r8845, 0;
	// inline asm
	shf.r.wrap.b32 %r8846, %r18, %r8845, %r5632;
	// inline asm
	bra.uni 	BB0_1244;

BB0_1486:
	setp.eq.s32	%p992, %r7499, 21;
	@%p992 bra 	BB0_1487;
	bra.uni 	BB0_1483;

BB0_1487:
	mov.u32 	%r7623, 24;
	// inline asm
	shf.r.wrap.b32 %r18, %r20, %r21, %r7623;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r17, %r19, %r20, %r7623;
	// inline asm
	mov.u32 	%r8837, 0;
	// inline asm
	shf.r.wrap.b32 %r16, %r8837, %r19, %r7623;
	// inline asm
	bra.uni 	BB0_1491;

BB0_1187:
	setp.eq.s32	%p801, %r24, 13;
	@%p801 bra 	BB0_1188;
	bra.uni 	BB0_1191;

BB0_1188:
	mov.u32 	%r5772, 8;
	// inline asm
	shf.r.wrap.b32 %r22, %r22, %r15, %r5772;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8847, %r15, %r16, %r5772;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8846, %r16, %r17, %r5772;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8845, %r17, %r18, %r5772;
	// inline asm
	mov.u32 	%r8849, 0;
	// inline asm
	shf.r.wrap.b32 %r18, %r18, %r8849, %r5772;
	// inline asm
	bra.uni 	BB0_1235;

BB0_743:
	setp.eq.s32	%p472, %r14, 26;
	@%p472 bra 	BB0_756;
	bra.uni 	BB0_744;

BB0_756:
	shl.b32 	%r3793, %r17, 8;
	and.b32  	%r3794, %r3793, 65280;
	bfe.u32 	%r3795, %r17, 8, 8;
	or.b32  	%r8850, %r3794, %r3795;
	mov.u32 	%r8853, 26;
	bra.uni 	BB0_757;

BB0_1470:
	setp.eq.s32	%p1004, %r7499, 13;
	@%p1004 bra 	BB0_1471;
	bra.uni 	BB0_1483;

BB0_1471:
	mov.u32 	%r7763, 24;
	// inline asm
	shf.r.wrap.b32 %r18, %r22, %r15, %r7763;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r17, %r21, %r22, %r7763;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r16, %r20, %r21, %r7763;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r7756, %r19, %r20, %r7763;
	// inline asm
	mov.u32 	%r8838, 0;
	// inline asm
	shf.r.wrap.b32 %r8837, %r8838, %r19, %r7763;
	// inline asm
	mov.u32 	%r8839, %r8838;
	mov.u32 	%r8840, %r8838;
	mov.u32 	%r19, %r7756;
	bra.uni 	BB0_1529;

BB0_186:
	setp.eq.s32	%p136, %r24, 26;
	@%p136 bra 	BB0_202;
	bra.uni 	BB0_187;

BB0_202:
	mov.u32 	%r2325, 16;
	// inline asm
	shf.r.wrap.b32 %r8692, %r19, %r20, %r2325;
	// inline asm
	mov.u32 	%r8688, 0;
	// inline asm
	shf.r.wrap.b32 %r8693, %r8688, %r19, %r2325;
	// inline asm
	bra.uni 	BB0_189;

BB0_1219:
	setp.eq.s32	%p778, %r24, 29;
	@%p778 bra 	BB0_1220;
	bra.uni 	BB0_1191;

BB0_1220:
	mov.u32 	%r8845, 0;
	mov.u32 	%r5524, 8;
	// inline asm
	shf.r.wrap.b32 %r22, %r18, %r8845, %r5524;
	// inline asm
	bra.uni 	BB0_1243;

BB0_1503:
	setp.eq.s32	%p981, %r7499, 29;
	@%p981 bra 	BB0_1504;
	bra.uni 	BB0_1483;

BB0_1504:
	mov.u32 	%r8837, 0;
	mov.u32 	%r7515, 24;
	// inline asm
	shf.r.wrap.b32 %r18, %r8837, %r19, %r7515;
	// inline asm
	bra.uni 	BB0_1525;

BB0_706:
	setp.eq.s32	%p499, %r14, 7;
	@%p499 bra 	BB0_778;
	bra.uni 	BB0_707;

BB0_778:
	and.b32  	%r3891, %r20, 255;
	shl.b32 	%r3892, %r20, 8;
	and.b32  	%r3893, %r3892, 16711680;
	or.b32  	%r3894, %r3893, %r3891;
	shr.u32 	%r3895, %r20, 8;
	and.b32  	%r3896, %r3895, 65280;
	or.b32  	%r8847, %r3894, %r3896;
	mov.u32 	%r8853, 7;
	bra.uni 	BB0_779;

BB0_144:
	setp.eq.s32	%p165, %r24, 6;
	@%p165 bra 	BB0_212;
	bra.uni 	BB0_145;

BB0_212:
	mov.u32 	%r2680, 16;
	// inline asm
	shf.r.wrap.b32 %r8692, %r16, %r17, %r2680;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8693, %r15, %r16, %r2680;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8694, %r22, %r15, %r2680;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8695, %r21, %r22, %r2680;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8688, %r20, %r21, %r2680;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8689, %r19, %r20, %r2680;
	// inline asm
	mov.u32 	%r8691, 0;
	// inline asm
	shf.r.wrap.b32 %r8690, %r8691, %r19, %r2680;
	// inline asm
	bra.uni 	BB0_215;

BB0_1199:
	setp.eq.s32	%p792, %r24, 19;
	@%p792 bra 	BB0_1200;
	bra.uni 	BB0_1191;

BB0_1200:
	mov.u32 	%r5658, 24;
	// inline asm
	shf.r.wrap.b32 %r22, %r15, %r16, %r5658;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8847, %r16, %r17, %r5658;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8846, %r17, %r18, %r5658;
	// inline asm
	mov.u32 	%r8849, 0;
	// inline asm
	shf.r.wrap.b32 %r8845, %r18, %r8849, %r5658;
	// inline asm

BB0_1231:
	mov.u32 	%r8850, %r8849;
	mov.u32 	%r8851, %r8849;
	mov.u32 	%r18, %r8849;
	bra.uni 	BB0_1245;

BB0_1482:
	setp.eq.s32	%p995, %r7499, 19;
	@%p995 bra 	BB0_1513;
	bra.uni 	BB0_1483;

BB0_1513:
	mov.u32 	%r7649, 8;
	// inline asm
	shf.r.wrap.b32 %r18, %r21, %r22, %r7649;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r17, %r20, %r21, %r7649;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r16, %r19, %r20, %r7649;
	// inline asm
	mov.u32 	%r8837, 0;
	// inline asm
	shf.r.wrap.b32 %r19, %r8837, %r19, %r7649;
	// inline asm

BB0_1514:
	mov.u32 	%r8838, %r8837;
	mov.u32 	%r8839, %r8837;
	mov.u32 	%r8840, %r8837;
	bra.uni 	BB0_1529;

BB0_1183:
	setp.eq.s32	%p804, %r24, 11;
	@%p804 bra 	BB0_1184;
	bra.uni 	BB0_1191;

BB0_1184:
	mov.u32 	%r5802, 24;
	// inline asm
	shf.r.wrap.b32 %r5779, %r21, %r22, %r5802;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8847, %r22, %r15, %r5802;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8846, %r15, %r16, %r5802;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8845, %r16, %r17, %r5802;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5795, %r17, %r18, %r5802;
	// inline asm
	mov.u32 	%r8849, 0;
	// inline asm
	shf.r.wrap.b32 %r8851, %r18, %r8849, %r5802;
	// inline asm
	mov.u32 	%r22, %r5779;
	mov.u32 	%r8850, %r8849;
	mov.u32 	%r18, %r5795;
	bra.uni 	BB0_1245;

BB0_735:
	setp.eq.s32	%p478, %r14, 22;
	@%p478 bra 	BB0_759;
	bra.uni 	BB0_736;

BB0_759:
	shl.b32 	%r3814, %r16, 8;
	and.b32  	%r3815, %r3814, 65280;
	bfe.u32 	%r3816, %r16, 8, 8;
	or.b32  	%r8851, %r3815, %r3816;
	mov.u32 	%r8853, 22;
	bra.uni 	BB0_760;

BB0_1466:
	setp.eq.s32	%p1007, %r7499, 11;
	@%p1007 bra 	BB0_1467;
	bra.uni 	BB0_1483;

BB0_1467:
	mov.u32 	%r7793, 8;
	// inline asm
	shf.r.wrap.b32 %r18, %r15, %r16, %r7793;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r17, %r22, %r15, %r7793;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r16, %r21, %r22, %r7793;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r7782, %r20, %r21, %r7793;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8837, %r19, %r20, %r7793;
	// inline asm
	mov.u32 	%r8839, 0;
	// inline asm
	shf.r.wrap.b32 %r8838, %r8839, %r19, %r7793;
	// inline asm
	mov.u32 	%r8840, %r8839;
	mov.u32 	%r19, %r7782;
	bra.uni 	BB0_1529;

BB0_177:
	setp.eq.s32	%p142, %r24, 22;
	@%p142 bra 	BB0_204;
	bra.uni 	BB0_178;

BB0_204:
	mov.u32 	%r2380, 16;
	// inline asm
	shf.r.wrap.b32 %r8692, %r20, %r21, %r2380;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8693, %r19, %r20, %r2380;
	// inline asm
	mov.u32 	%r8688, 0;
	// inline asm
	shf.r.wrap.b32 %r8694, %r8688, %r19, %r2380;
	// inline asm
	bra.uni 	BB0_180;

BB0_1214:
	setp.eq.s32	%p781, %r24, 27;
	@%p781 bra 	BB0_1215;
	bra.uni 	BB0_1191;

BB0_1215:
	mov.u32 	%r5546, 24;
	// inline asm
	shf.r.wrap.b32 %r22, %r17, %r18, %r5546;
	// inline asm
	mov.u32 	%r8845, 0;
	// inline asm
	shf.r.wrap.b32 %r8847, %r18, %r8845, %r5546;
	// inline asm

BB0_1216:
	mov.u32 	%r8846, %r8845;
	bra.uni 	BB0_1244;

BB0_1498:
	setp.eq.s32	%p984, %r7499, 27;
	@%p984 bra 	BB0_1499;
	bra.uni 	BB0_1483;

BB0_1499:
	mov.u32 	%r7537, 8;
	// inline asm
	shf.r.wrap.b32 %r18, %r19, %r20, %r7537;
	// inline asm
	mov.u32 	%r8837, 0;
	// inline asm
	shf.r.wrap.b32 %r17, %r8837, %r19, %r7537;
	// inline asm

BB0_1500:
	mov.u32 	%r8838, %r8837;
	mov.u32 	%r8839, %r8837;
	mov.u32 	%r8840, %r8837;
	bra.uni 	BB0_1527;

BB0_1175:
	setp.eq.s32	%p810, %r24, 7;
	@%p810 bra 	BB0_1176;
	bra.uni 	BB0_1191;

BB0_1176:
	mov.u32 	%r5886, 24;
	// inline asm
	shf.r.wrap.b32 %r5859, %r20, %r21, %r5886;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8847, %r21, %r22, %r5886;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8846, %r22, %r15, %r5886;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8845, %r15, %r16, %r5886;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5875, %r16, %r17, %r5886;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8851, %r17, %r18, %r5886;
	// inline asm
	mov.u32 	%r8849, 0;
	// inline asm
	shf.r.wrap.b32 %r8850, %r18, %r8849, %r5886;
	// inline asm
	mov.u32 	%r22, %r5859;
	mov.u32 	%r18, %r5875;
	bra.uni 	BB0_1245;

BB0_721:
	setp.eq.s32	%p488, %r14, 15;
	@%p488 bra 	BB0_767;
	bra.uni 	BB0_722;

BB0_767:
	and.b32  	%r3849, %r22, 255;
	shl.b32 	%r3850, %r22, 8;
	and.b32  	%r3851, %r3850, 16711680;
	or.b32  	%r3852, %r3851, %r3849;
	shr.u32 	%r3853, %r22, 8;
	and.b32  	%r3854, %r3853, 65280;
	or.b32  	%r8845, %r3852, %r3854;
	mov.u32 	%r8853, 15;
	bra.uni 	BB0_768;

BB0_1458:
	setp.eq.s32	%p1013, %r7499, 7;
	@%p1013 bra 	BB0_1459;
	bra.uni 	BB0_1483;

BB0_1459:
	mov.u32 	%r7877, 8;
	// inline asm
	shf.r.wrap.b32 %r18, %r16, %r17, %r7877;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r17, %r15, %r16, %r7877;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r16, %r22, %r15, %r7877;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r7862, %r21, %r22, %r7877;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8837, %r20, %r21, %r7877;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8838, %r19, %r20, %r7877;
	// inline asm
	mov.u32 	%r8840, 0;
	// inline asm
	shf.r.wrap.b32 %r8839, %r8840, %r19, %r7877;
	// inline asm
	mov.u32 	%r19, %r7862;
	bra.uni 	BB0_1529;

BB0_159:
	setp.eq.s32	%p154, %r24, 14;
	@%p154 bra 	BB0_208;
	bra.uni 	BB0_160;

BB0_208:
	mov.u32 	%r2514, 16;
	// inline asm
	shf.r.wrap.b32 %r8692, %r22, %r15, %r2514;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8693, %r21, %r22, %r2514;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8694, %r20, %r21, %r2514;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8695, %r19, %r20, %r2514;
	// inline asm
	mov.u32 	%r8689, 0;
	// inline asm
	shf.r.wrap.b32 %r8688, %r8689, %r19, %r2514;
	// inline asm
	bra.uni 	BB0_162;

BB0_1206:
	setp.eq.s32	%p787, %r24, 23;
	@%p787 bra 	BB0_1207;
	bra.uni 	BB0_1191;

BB0_1207:
	mov.u32 	%r5598, 24;
	// inline asm
	shf.r.wrap.b32 %r22, %r16, %r17, %r5598;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8847, %r17, %r18, %r5598;
	// inline asm
	mov.u32 	%r8845, 0;
	// inline asm
	shf.r.wrap.b32 %r8846, %r18, %r8845, %r5598;
	// inline asm
	bra.uni 	BB0_1244;

BB0_1489:
	setp.eq.s32	%p990, %r7499, 23;
	@%p990 bra 	BB0_1490;
	bra.uni 	BB0_1483;

BB0_1490:
	mov.u32 	%r7589, 8;
	// inline asm
	shf.r.wrap.b32 %r18, %r20, %r21, %r7589;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r17, %r19, %r20, %r7589;
	// inline asm
	mov.u32 	%r8837, 0;
	// inline asm
	shf.r.wrap.b32 %r16, %r8837, %r19, %r7589;
	// inline asm

BB0_1491:
	mov.u32 	%r8838, %r8837;
	mov.u32 	%r8839, %r8837;
	mov.u32 	%r8840, %r8837;
	bra.uni 	BB0_1528;

BB0_1190:
	setp.eq.s32	%p799, %r24, 15;
	@%p799 bra 	BB0_1232;
	bra.uni 	BB0_1191;

BB0_1232:
	mov.u32 	%r5726, 24;
	// inline asm
	shf.r.wrap.b32 %r22, %r22, %r15, %r5726;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8847, %r15, %r16, %r5726;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8846, %r16, %r17, %r5726;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8845, %r17, %r18, %r5726;
	// inline asm
	mov.u32 	%r8849, 0;
	// inline asm
	shf.r.wrap.b32 %r18, %r18, %r8849, %r5726;
	// inline asm

BB0_1235:
	mov.u32 	%r8850, %r8849;
	mov.u32 	%r8851, %r8849;
	bra.uni 	BB0_1245;

BB0_750:
	setp.eq.s32	%p467, %r14, 30;
	@%p467 bra 	BB0_753;
	bra.uni 	BB0_751;

BB0_753:
	shl.b32 	%r3772, %r18, 8;
	and.b32  	%r3773, %r3772, 65280;
	bfe.u32 	%r3774, %r18, 8, 8;
	or.b32  	%r8849, %r3773, %r3774;
	mov.u32 	%r8853, 30;
	bra.uni 	BB0_754;

BB0_1473:
	setp.eq.s32	%p1002, %r7499, 15;
	@%p1002 bra 	BB0_1474;
	bra.uni 	BB0_1483;

BB0_1474:
	mov.u32 	%r7717, 8;
	// inline asm
	shf.r.wrap.b32 %r18, %r22, %r15, %r7717;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r17, %r21, %r22, %r7717;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r16, %r20, %r21, %r7717;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r7710, %r19, %r20, %r7717;
	// inline asm
	mov.u32 	%r8838, 0;
	// inline asm
	shf.r.wrap.b32 %r8837, %r8838, %r19, %r7717;
	// inline asm
	mov.u32 	%r8839, %r8838;
	mov.u32 	%r8840, %r8838;
	mov.u32 	%r19, %r7710;
	bra.uni 	BB0_1529;

BB0_195:
	setp.eq.s32	%p131, %r24, 30;
	@%p131 bra 	BB0_199;
	bra.uni 	BB0_196;

BB0_199:
	mov.u32 	%r8688, 0;
	mov.u32 	%r2278, 16;
	// inline asm
	shf.r.wrap.b32 %r8692, %r8688, %r19, %r2278;
	// inline asm
	bra.uni 	BB0_198;

BB0_289:
	setp.eq.s32	%p219, %r24, 18;
	@%p219 bra 	BB0_323;
	bra.uni 	BB0_290;

BB0_323:
	mov.u32 	%r3041, 16;
	// inline asm
	shf.r.wrap.b32 %r18, %r21, %r22, %r3041;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r17, %r20, %r21, %r3041;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r16, %r19, %r20, %r3041;
	// inline asm
	mov.u32 	%r8712, 0;
	// inline asm
	shf.r.wrap.b32 %r19, %r8712, %r19, %r3041;
	// inline asm
	bra.uni 	BB0_322;

BB0_273:
	setp.eq.s32	%p231, %r24, 10;
	@%p231 bra 	BB0_327;
	bra.uni 	BB0_274;

BB0_327:
	mov.u32 	%r3191, 16;
	// inline asm
	shf.r.wrap.b32 %r18, %r15, %r16, %r3191;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r17, %r22, %r15, %r3191;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r16, %r21, %r22, %r3191;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r3180, %r20, %r21, %r3191;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8712, %r19, %r20, %r3191;
	// inline asm
	mov.u32 	%r8714, 0;
	// inline asm
	shf.r.wrap.b32 %r8713, %r8714, %r19, %r3191;
	// inline asm
	mov.u32 	%r8715, %r8714;
	mov.u32 	%r19, %r3180;
	bra.uni 	BB0_338;

BB0_305:
	setp.eq.s32	%p208, %r24, 26;
	@%p208 bra 	BB0_317;
	bra.uni 	BB0_306;

BB0_317:
	mov.u32 	%r2923, 16;
	// inline asm
	shf.r.wrap.b32 %r18, %r19, %r20, %r2923;
	// inline asm
	mov.u32 	%r8712, 0;
	// inline asm
	shf.r.wrap.b32 %r17, %r8712, %r19, %r2923;
	// inline asm
	bra.uni 	BB0_308;

BB0_1222:
	setp.ne.s32	%p776, %r24, 30;
	@%p776 bra 	BB0_1191;

	mov.u32 	%r8845, 0;
	mov.u32 	%r5513, 16;
	// inline asm
	shf.r.wrap.b32 %r22, %r18, %r8845, %r5513;
	// inline asm

BB0_1243:
	mov.u32 	%r8846, %r8845;
	mov.u32 	%r8847, %r8845;

BB0_1244:
	mov.u32 	%r8849, %r8845;
	mov.u32 	%r8850, %r8845;
	mov.u32 	%r8851, %r8845;
	mov.u32 	%r18, %r8845;
	bra.uni 	BB0_1245;

BB0_1191:
	mov.u32 	%r8845, %r22;
	mov.u32 	%r8846, %r21;
	mov.u32 	%r8847, %r20;
	mov.u32 	%r22, %r19;
	mov.u32 	%r8849, %r18;
	mov.u32 	%r8850, %r17;
	mov.u32 	%r8851, %r16;
	mov.u32 	%r18, %r15;

BB0_1245:
	and.b32  	%r6055, %r25, 3;
	shl.b32 	%r6056, %r6055, 3;
	mov.u32 	%r6057, 1;
	shl.b32 	%r6058, %r6057, %r6056;
	add.s32 	%r1193, %r6058, -1;
	shr.u32 	%r6054, %r26, 2;
	setp.gt.s32	%p816, %r6054, 3;
	@%p816 bra 	BB0_1253;

	setp.gt.s32	%p822, %r6054, 1;
	@%p822 bra 	BB0_1250;

	setp.eq.s32	%p825, %r6054, 0;
	@%p825 bra 	BB0_1267;
	bra.uni 	BB0_1248;

BB0_1267:
	and.b32  	%r8848, %r22, %r1193;
	mov.u32 	%r8845, 0;
	mov.u32 	%r8846, %r8845;
	mov.u32 	%r8847, %r8845;
	bra.uni 	BB0_1266;

BB0_1253:
	setp.gt.s32	%p817, %r6054, 5;
	@%p817 bra 	BB0_1257;

	setp.eq.s32	%p820, %r6054, 4;
	@%p820 bra 	BB0_1263;
	bra.uni 	BB0_1255;

BB0_1263:
	and.b32  	%r8852, %r18, %r1193;
	mov.u32 	%r8849, 0;
	mov.u32 	%r8848, %r22;
	mov.u32 	%r8850, %r8849;
	mov.u32 	%r8851, %r8849;
	mov.u32 	%r8853, %r26;
	bra.uni 	BB0_1554;

BB0_1250:
	setp.eq.s32	%p823, %r6054, 2;
	@%p823 bra 	BB0_1264;
	bra.uni 	BB0_1251;

BB0_1264:
	and.b32  	%r8846, %r8846, %r1193;
	mov.u32 	%r8845, 0;
	bra.uni 	BB0_1265;

BB0_1257:
	setp.eq.s32	%p818, %r6054, 6;
	@%p818 bra 	BB0_1262;
	bra.uni 	BB0_1258;

BB0_1262:
	and.b32  	%r8850, %r8850, %r1193;
	mov.u32 	%r8849, 0;
	bra.uni 	BB0_1260;

BB0_1248:
	setp.eq.s32	%p826, %r6054, 1;
	@%p826 bra 	BB0_1249;
	bra.uni 	BB0_1260;

BB0_1249:
	and.b32  	%r8847, %r8847, %r1193;
	mov.u32 	%r8845, 0;
	mov.u32 	%r8846, %r8845;

BB0_1265:
	mov.u32 	%r8848, %r22;

BB0_1266:
	mov.u32 	%r8849, %r8845;
	mov.u32 	%r8850, %r8845;
	mov.u32 	%r8851, %r8845;
	mov.u32 	%r8852, %r8845;
	mov.u32 	%r8853, %r26;
	bra.uni 	BB0_1554;

BB0_1255:
	setp.eq.s32	%p821, %r6054, 5;
	@%p821 bra 	BB0_1256;
	bra.uni 	BB0_1260;

BB0_1256:
	and.b32  	%r8851, %r8851, %r1193;
	mov.u32 	%r8849, 0;
	mov.u32 	%r8848, %r22;
	mov.u32 	%r8850, %r8849;
	bra.uni 	BB0_1261;

BB0_1251:
	setp.eq.s32	%p824, %r6054, 3;
	@%p824 bra 	BB0_1252;
	bra.uni 	BB0_1260;

BB0_1252:
	and.b32  	%r8845, %r8845, %r1193;
	mov.u32 	%r8849, 0;
	mov.u32 	%r8848, %r22;
	mov.u32 	%r8850, %r8849;
	mov.u32 	%r8851, %r8849;
	mov.u32 	%r8852, %r8849;
	mov.u32 	%r8853, %r26;
	bra.uni 	BB0_1554;

BB0_1258:
	setp.ne.s32	%p819, %r6054, 7;
	@%p819 bra 	BB0_1260;

	and.b32  	%r8849, %r8849, %r1193;

BB0_1260:
	mov.u32 	%r8848, %r22;

BB0_1261:
	mov.u32 	%r8852, %r18;
	mov.u32 	%r8853, %r26;
	bra.uni 	BB0_1554;

BB0_1506:
	setp.ne.s32	%p979, %r7499, 30;
	@%p979 bra 	BB0_1483;

	mov.u32 	%r8837, 0;
	mov.u32 	%r7504, 16;
	// inline asm
	shf.r.wrap.b32 %r18, %r8837, %r19, %r7504;
	// inline asm

BB0_1525:
	mov.u32 	%r8838, %r8837;
	mov.u32 	%r8839, %r8837;
	mov.u32 	%r8840, %r8837;

BB0_1526:
	mov.u32 	%r17, %r8837;

BB0_1527:
	mov.u32 	%r16, %r8837;

BB0_1528:
	mov.u32 	%r19, %r8837;
	bra.uni 	BB0_1529;

BB0_1483:
	mov.u32 	%r8837, %r22;
	mov.u32 	%r8838, %r21;
	mov.u32 	%r8839, %r20;
	mov.u32 	%r8840, %r19;
	mov.u32 	%r19, %r15;

BB0_1529:
	// inline asm
	prmt.b32 %r8848, %r18, 0, 0x0123;
	// inline asm
	// inline asm
	prmt.b32 %r8847, %r17, 0, 0x0123;
	// inline asm
	// inline asm
	prmt.b32 %r8846, %r16, 0, 0x0123;
	// inline asm
	// inline asm
	prmt.b32 %r8845, %r19, 0, 0x0123;
	// inline asm
	// inline asm
	prmt.b32 %r8852, %r8837, 0, 0x0123;
	// inline asm
	// inline asm
	prmt.b32 %r8851, %r8838, 0, 0x0123;
	// inline asm
	// inline asm
	prmt.b32 %r8850, %r8839, 0, 0x0123;
	// inline asm
	// inline asm
	prmt.b32 %r8849, %r8840, 0, 0x0123;
	// inline asm
	bra.uni 	BB0_1553;

BB0_265:
	setp.eq.s32	%p237, %r24, 6;
	@%p237 bra 	BB0_329;
	bra.uni 	BB0_266;

BB0_329:
	mov.u32 	%r3278, 16;
	// inline asm
	shf.r.wrap.b32 %r18, %r16, %r17, %r3278;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r17, %r15, %r16, %r3278;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r16, %r22, %r15, %r3278;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r3263, %r21, %r22, %r3278;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8712, %r20, %r21, %r3278;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8713, %r19, %r20, %r3278;
	// inline asm
	mov.u32 	%r8715, 0;
	// inline asm
	shf.r.wrap.b32 %r8714, %r8715, %r19, %r3278;
	// inline asm
	mov.u32 	%r19, %r3263;
	bra.uni 	BB0_338;

BB0_296:
	setp.eq.s32	%p214, %r24, 22;
	@%p214 bra 	BB0_319;
	bra.uni 	BB0_297;

BB0_319:
	mov.u32 	%r2978, 16;
	// inline asm
	shf.r.wrap.b32 %r18, %r20, %r21, %r2978;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r17, %r19, %r20, %r2978;
	// inline asm
	mov.u32 	%r8712, 0;
	// inline asm
	shf.r.wrap.b32 %r16, %r8712, %r19, %r2978;
	// inline asm
	bra.uni 	BB0_299;

BB0_280:
	setp.eq.s32	%p226, %r24, 14;
	@%p226 bra 	BB0_325;
	bra.uni 	BB0_281;

BB0_325:
	mov.u32 	%r3112, 16;
	// inline asm
	shf.r.wrap.b32 %r18, %r22, %r15, %r3112;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r17, %r21, %r22, %r3112;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r16, %r20, %r21, %r3112;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r3105, %r19, %r20, %r3112;
	// inline asm
	mov.u32 	%r8713, 0;
	// inline asm
	shf.r.wrap.b32 %r8712, %r8713, %r19, %r3112;
	// inline asm
	mov.u32 	%r8714, %r8713;
	mov.u32 	%r8715, %r8713;
	mov.u32 	%r19, %r3105;
	bra.uni 	BB0_338;

BB0_313:
	setp.eq.s32	%p203, %r24, 31;
	@%p203 bra 	BB0_333;
	bra.uni 	BB0_314;

BB0_333:
	mov.u32 	%r8712, 0;
	mov.u32 	%r3409, 8;
	// inline asm
	shf.r.wrap.b32 %r18, %r8712, %r19, %r3409;
	// inline asm
	bra.uni 	BB0_334;

BB0_868:
	mov.u32 	%r4529, 24;
	// inline asm
	shf.r.wrap.b32 %r18, %r17, %r18, %r4529;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r17, %r16, %r17, %r4529;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r16, %r15, %r16, %r4529;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r15, %r22, %r15, %r4529;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8845, %r21, %r22, %r4529;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8846, %r20, %r21, %r4529;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8847, %r19, %r20, %r4529;
	// inline asm
	mov.u32 	%r4527, 0;
	// inline asm
	shf.r.wrap.b32 %r8848, %r4527, %r19, %r4529;
	// inline asm
	bra.uni 	BB0_874;

BB0_794:
	setp.eq.s32	%p578, %r24, 3;
	@%p578 bra 	BB0_795;
	bra.uni 	BB0_827;

BB0_795:
	mov.u32 	%r4465, 8;
	// inline asm
	shf.r.wrap.b32 %r18, %r17, %r18, %r4465;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r17, %r16, %r17, %r4465;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r16, %r15, %r16, %r4465;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r15, %r22, %r15, %r4465;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8845, %r21, %r22, %r4465;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8846, %r20, %r21, %r4465;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8847, %r19, %r20, %r4465;
	// inline asm
	mov.u32 	%r4463, 0;
	// inline asm
	shf.r.wrap.b32 %r8848, %r4463, %r19, %r4465;
	// inline asm
	bra.uni 	BB0_874;

BB0_1058:
	setp.eq.s32	%p756, %r26, 1;
	mov.u32 	%r8845, %r8849;
	mov.u32 	%r8846, %r8849;
	mov.u32 	%r8847, %r8849;
	mov.u32 	%r8766, %r8849;
	mov.u32 	%r8850, %r8849;
	mov.u32 	%r8851, %r8849;
	mov.u32 	%r8852, %r8849;
	@%p756 bra 	BB0_1059;
	bra.uni 	BB0_1137;

BB0_1059:
	mov.u32 	%r5487, 8;
	// inline asm
	shf.r.wrap.b32 %r8766, %r19, %r20, %r5487;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8847, %r20, %r21, %r5487;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8846, %r21, %r22, %r5487;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8845, %r22, %r15, %r5487;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8852, %r15, %r16, %r5487;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8851, %r16, %r17, %r5487;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8850, %r17, %r18, %r5487;
	// inline asm
	mov.u32 	%r5486, 0;
	// inline asm
	shf.r.wrap.b32 %r8849, %r18, %r5486, %r5487;
	// inline asm
	bra.uni 	BB0_1137;

BB0_781:
	shl.b32 	%r3919, %r19, 8;
	and.b32  	%r3920, %r3919, 65280;
	bfe.u32 	%r3921, %r19, 8, 8;
	or.b32  	%r8848, %r3920, %r3921;
	mov.u32 	%r8853, 2;
	bra.uni 	BB0_782;

BB0_700:
	setp.eq.s32	%p505, %r14, 4;
	@%p505 bra 	BB0_701;
	bra.uni 	BB0_11;

BB0_701:
	and.b32  	%r3905, %r19, 65535;
	shl.b32 	%r3906, %r19, 8;
	and.b32  	%r3907, %r3906, -16777216;
	or.b32  	%r3908, %r3907, %r3905;
	shr.u32 	%r3909, %r19, 8;
	and.b32  	%r3910, %r3909, 16711680;
	or.b32  	%r8848, %r3908, %r3910;
	mov.u32 	%r8853, 4;

BB0_782:
	mov.u32 	%r8845, %r22;
	mov.u32 	%r8846, %r21;
	mov.u32 	%r8847, %r20;
	bra.uni 	BB0_771;

BB0_454:
	setp.eq.s32	%p367, %r24, 1;
	mov.u32 	%r8720, %r8729;
	@%p367 bra 	BB0_455;
	bra.uni 	BB0_528;

BB0_455:
	bfe.u32 	%r8720, %r19, 8, 8;
	bra.uni 	BB0_528;

BB0_1316:
	setp.eq.s32	%p932, %r6374, 2;
	@%p932 bra 	BB0_1393;
	bra.uni 	BB0_1317;

BB0_1393:
	mov.u32 	%r6887, 16;
	// inline asm
	shf.r.wrap.b32 %r8799, %r17, %r18, %r6887;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8800, %r16, %r17, %r6887;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8801, %r15, %r16, %r6887;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8802, %r22, %r15, %r6887;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8795, %r21, %r22, %r6887;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8796, %r20, %r21, %r6887;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8797, %r19, %r20, %r6887;
	// inline asm
	mov.u32 	%r6885, 0;
	// inline asm
	shf.r.wrap.b32 %r8798, %r6885, %r19, %r6887;
	// inline asm
	bra.uni 	BB0_1394;

BB0_1090:
	setp.eq.s32	%p733, %r26, 17;
	mov.u32 	%r8845, %r8849;
	mov.u32 	%r8846, %r8849;
	mov.u32 	%r8847, %r8849;
	mov.u32 	%r8766, %r8849;
	mov.u32 	%r8850, %r8849;
	mov.u32 	%r8851, %r8849;
	mov.u32 	%r8852, %r8849;
	@%p733 bra 	BB0_1091;
	bra.uni 	BB0_1137;

BB0_1091:
	mov.u32 	%r5143, 8;
	// inline asm
	shf.r.wrap.b32 %r8766, %r15, %r16, %r5143;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8847, %r16, %r17, %r5143;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8846, %r17, %r18, %r5143;
	// inline asm
	mov.u32 	%r8849, 0;
	// inline asm
	shf.r.wrap.b32 %r8845, %r18, %r8849, %r5143;
	// inline asm
	bra.uni 	BB0_1122;

BB0_485:
	setp.eq.s32	%p344, %r24, 17;
	mov.u32 	%r8720, %r8729;
	@%p344 bra 	BB0_486;
	bra.uni 	BB0_528;

BB0_486:
	bfe.u32 	%r8720, %r15, 8, 8;
	bra.uni 	BB0_528;

BB0_823:
	setp.eq.s32	%p557, %r24, 17;
	@%p557 bra 	BB0_824;
	bra.uni 	BB0_827;

BB0_824:
	mov.u32 	%r4185, 24;
	// inline asm
	shf.r.wrap.b32 %r18, %r21, %r22, %r4185;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r17, %r20, %r21, %r4185;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r16, %r19, %r20, %r4185;
	// inline asm
	mov.u32 	%r8845, 0;
	// inline asm
	shf.r.wrap.b32 %r15, %r8845, %r19, %r4185;
	// inline asm
	bra.uni 	BB0_858;

BB0_766:
	or.b32  	%r3839, %r15, %r22;
	and.b32  	%r3840, %r22, 16777215;
	prmt.b32 	%r8845, %r15, %r3840, 1620;
	shr.u32 	%r8852, %r3839, 24;
	mov.u32 	%r8853, 17;
	bra.uni 	BB0_764;

BB0_728:
	setp.eq.s32	%p484, %r14, 19;
	@%p484 bra 	BB0_729;
	bra.uni 	BB0_11;

BB0_729:
	and.b32  	%r3828, %r15, 255;
	shl.b32 	%r3829, %r15, 8;
	and.b32  	%r3830, %r3829, 16711680;
	or.b32  	%r3831, %r3830, %r3828;
	shr.u32 	%r3832, %r15, 8;
	and.b32  	%r3833, %r3832, 65280;
	or.b32  	%r8852, %r3831, %r3833;
	mov.u32 	%r8853, 19;

BB0_763:
	mov.u32 	%r8845, %r22;

BB0_764:
	mov.u32 	%r8846, %r21;
	mov.u32 	%r8847, %r20;
	mov.u32 	%r8848, %r19;
	bra.uni 	BB0_765;

BB0_1073:
	setp.eq.s32	%p745, %r26, 9;
	mov.u32 	%r8845, %r8849;
	mov.u32 	%r8846, %r8849;
	mov.u32 	%r8847, %r8849;
	mov.u32 	%r8766, %r8849;
	mov.u32 	%r8850, %r8849;
	mov.u32 	%r8851, %r8849;
	mov.u32 	%r8852, %r8849;
	@%p745 bra 	BB0_1074;
	bra.uni 	BB0_1137;

BB0_1074:
	mov.u32 	%r5299, 8;
	// inline asm
	shf.r.wrap.b32 %r8766, %r21, %r22, %r5299;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8847, %r22, %r15, %r5299;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8846, %r15, %r16, %r5299;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8845, %r16, %r17, %r5299;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8852, %r17, %r18, %r5299;
	// inline asm
	mov.u32 	%r8849, 0;
	// inline asm
	shf.r.wrap.b32 %r8851, %r18, %r8849, %r5299;
	// inline asm
	mov.u32 	%r8850, %r8849;
	bra.uni 	BB0_1137;

BB0_469:
	setp.eq.s32	%p356, %r24, 9;
	mov.u32 	%r8720, %r8729;
	@%p356 bra 	BB0_470;
	bra.uni 	BB0_528;

BB0_470:
	bfe.u32 	%r8720, %r21, 8, 8;
	bra.uni 	BB0_528;

BB0_1348:
	setp.eq.s32	%p909, %r6374, 18;
	@%p909 bra 	BB0_1385;
	bra.uni 	BB0_1349;

BB0_1385:
	mov.u32 	%r6555, 16;
	// inline asm
	shf.r.wrap.b32 %r8799, %r21, %r22, %r6555;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8800, %r20, %r21, %r6555;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8801, %r19, %r20, %r6555;
	// inline asm
	mov.u32 	%r8795, 0;
	// inline asm
	shf.r.wrap.b32 %r8802, %r8795, %r19, %r6555;
	// inline asm
	bra.uni 	BB0_1351;

BB0_806:
	setp.eq.s32	%p569, %r24, 9;
	@%p569 bra 	BB0_807;
	bra.uni 	BB0_827;

BB0_807:
	mov.u32 	%r4341, 24;
	// inline asm
	shf.r.wrap.b32 %r18, %r15, %r16, %r4341;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r17, %r22, %r15, %r4341;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r16, %r21, %r22, %r4341;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r15, %r20, %r21, %r4341;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8845, %r19, %r20, %r4341;
	// inline asm
	mov.u32 	%r8847, 0;
	// inline asm
	shf.r.wrap.b32 %r8846, %r8847, %r19, %r4341;
	// inline asm
	mov.u32 	%r8848, %r8847;
	bra.uni 	BB0_874;

BB0_1105:
	setp.eq.s32	%p722, %r26, 25;
	mov.u32 	%r8845, %r8849;
	mov.u32 	%r8846, %r8849;
	mov.u32 	%r8847, %r8849;
	mov.u32 	%r8766, %r8849;
	mov.u32 	%r8850, %r8849;
	mov.u32 	%r8851, %r8849;
	mov.u32 	%r8852, %r8849;
	@%p722 bra 	BB0_1106;
	bra.uni 	BB0_1137;

BB0_1106:
	mov.u32 	%r5019, 8;
	// inline asm
	shf.r.wrap.b32 %r8766, %r17, %r18, %r5019;
	// inline asm
	mov.u32 	%r8845, 0;
	// inline asm
	shf.r.wrap.b32 %r8847, %r18, %r8845, %r5019;
	// inline asm
	bra.uni 	BB0_1110;

BB0_500:
	setp.eq.s32	%p333, %r24, 25;
	mov.u32 	%r8720, %r8729;
	@%p333 bra 	BB0_501;
	bra.uni 	BB0_528;

BB0_501:
	bfe.u32 	%r8720, %r17, 8, 8;
	bra.uni 	BB0_528;

BB0_839:
	setp.eq.s32	%p546, %r24, 25;
	@%p546 bra 	BB0_840;
	bra.uni 	BB0_827;

BB0_840:
	mov.u32 	%r4061, 24;
	// inline asm
	shf.r.wrap.b32 %r18, %r19, %r20, %r4061;
	// inline asm
	mov.u32 	%r8845, 0;
	// inline asm
	shf.r.wrap.b32 %r17, %r8845, %r19, %r4061;
	// inline asm
	bra.uni 	BB0_844;

BB0_1065:
	setp.eq.s32	%p751, %r26, 5;
	mov.u32 	%r8845, %r8849;
	mov.u32 	%r8846, %r8849;
	mov.u32 	%r8847, %r8849;
	mov.u32 	%r8766, %r8849;
	mov.u32 	%r8850, %r8849;
	mov.u32 	%r8851, %r8849;
	mov.u32 	%r8852, %r8849;
	@%p751 bra 	BB0_1066;
	bra.uni 	BB0_1137;

BB0_1066:
	mov.u32 	%r5389, 8;
	// inline asm
	shf.r.wrap.b32 %r8766, %r20, %r21, %r5389;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8847, %r21, %r22, %r5389;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8846, %r22, %r15, %r5389;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8845, %r15, %r16, %r5389;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8852, %r16, %r17, %r5389;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8851, %r17, %r18, %r5389;
	// inline asm
	mov.u32 	%r8849, 0;
	// inline asm
	shf.r.wrap.b32 %r8850, %r18, %r8849, %r5389;
	// inline asm
	bra.uni 	BB0_1137;

BB0_461:
	setp.eq.s32	%p362, %r24, 5;
	mov.u32 	%r8720, %r8729;
	@%p362 bra 	BB0_462;
	bra.uni 	BB0_528;

BB0_462:
	bfe.u32 	%r8720, %r20, 8, 8;
	bra.uni 	BB0_528;

BB0_1331:
	setp.eq.s32	%p921, %r6374, 10;
	@%p921 bra 	BB0_1389;
	bra.uni 	BB0_1332;

BB0_1389:
	mov.u32 	%r6705, 16;
	// inline asm
	shf.r.wrap.b32 %r8799, %r15, %r16, %r6705;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8800, %r22, %r15, %r6705;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8801, %r21, %r22, %r6705;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8802, %r20, %r21, %r6705;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8795, %r19, %r20, %r6705;
	// inline asm
	mov.u32 	%r8797, 0;
	// inline asm
	shf.r.wrap.b32 %r8796, %r8797, %r19, %r6705;
	// inline asm
	mov.u32 	%r8798, %r8797;
	bra.uni 	BB0_1394;

BB0_798:
	setp.eq.s32	%p575, %r24, 5;
	@%p575 bra 	BB0_799;
	bra.uni 	BB0_827;

BB0_799:
	mov.u32 	%r4431, 24;
	// inline asm
	shf.r.wrap.b32 %r18, %r16, %r17, %r4431;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r17, %r15, %r16, %r4431;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r16, %r22, %r15, %r4431;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r15, %r21, %r22, %r4431;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8845, %r20, %r21, %r4431;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8846, %r19, %r20, %r4431;
	// inline asm
	mov.u32 	%r8848, 0;
	// inline asm
	shf.r.wrap.b32 %r8847, %r8848, %r19, %r4431;
	// inline asm
	bra.uni 	BB0_874;

BB0_1097:
	setp.eq.s32	%p728, %r26, 21;
	mov.u32 	%r8845, %r8849;
	mov.u32 	%r8846, %r8849;
	mov.u32 	%r8847, %r8849;
	mov.u32 	%r8766, %r8849;
	mov.u32 	%r8850, %r8849;
	mov.u32 	%r8851, %r8849;
	mov.u32 	%r8852, %r8849;
	@%p728 bra 	BB0_1098;
	bra.uni 	BB0_1137;

BB0_1098:
	mov.u32 	%r5077, 8;
	// inline asm
	shf.r.wrap.b32 %r8766, %r16, %r17, %r5077;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8847, %r17, %r18, %r5077;
	// inline asm
	mov.u32 	%r8845, 0;
	// inline asm
	shf.r.wrap.b32 %r8846, %r18, %r8845, %r5077;
	// inline asm
	bra.uni 	BB0_1111;

BB0_492:
	setp.eq.s32	%p339, %r24, 21;
	mov.u32 	%r8720, %r8729;
	@%p339 bra 	BB0_493;
	bra.uni 	BB0_528;

BB0_493:
	bfe.u32 	%r8720, %r16, 8, 8;
	bra.uni 	BB0_528;

BB0_830:
	setp.eq.s32	%p552, %r24, 21;
	@%p552 bra 	BB0_831;
	bra.uni 	BB0_827;

BB0_831:
	mov.u32 	%r4119, 24;
	// inline asm
	shf.r.wrap.b32 %r18, %r20, %r21, %r4119;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r17, %r19, %r20, %r4119;
	// inline asm
	mov.u32 	%r8845, 0;
	// inline asm
	shf.r.wrap.b32 %r16, %r8845, %r19, %r4119;
	// inline asm
	bra.uni 	BB0_835;

BB0_1080:
	setp.eq.s32	%p740, %r26, 13;
	mov.u32 	%r8845, %r8849;
	mov.u32 	%r8846, %r8849;
	mov.u32 	%r8847, %r8849;
	mov.u32 	%r8766, %r8849;
	mov.u32 	%r8850, %r8849;
	mov.u32 	%r8851, %r8849;
	mov.u32 	%r8852, %r8849;
	@%p740 bra 	BB0_1081;
	bra.uni 	BB0_1137;

BB0_1081:
	mov.u32 	%r5217, 8;
	// inline asm
	shf.r.wrap.b32 %r8766, %r22, %r15, %r5217;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8847, %r15, %r16, %r5217;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8846, %r16, %r17, %r5217;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8845, %r17, %r18, %r5217;
	// inline asm
	mov.u32 	%r8849, 0;
	// inline asm
	shf.r.wrap.b32 %r8852, %r18, %r8849, %r5217;
	// inline asm
	bra.uni 	BB0_1085;

BB0_476:
	setp.eq.s32	%p351, %r24, 13;
	mov.u32 	%r8720, %r8729;
	@%p351 bra 	BB0_477;
	bra.uni 	BB0_528;

BB0_477:
	bfe.u32 	%r8720, %r22, 8, 8;
	bra.uni 	BB0_528;

BB0_1365:
	setp.eq.s32	%p898, %r6374, 26;
	@%p898 bra 	BB0_1381;
	bra.uni 	BB0_1366;

BB0_1381:
	mov.u32 	%r6437, 16;
	// inline asm
	shf.r.wrap.b32 %r8799, %r19, %r20, %r6437;
	// inline asm
	mov.u32 	%r8795, 0;
	// inline asm
	shf.r.wrap.b32 %r8800, %r8795, %r19, %r6437;
	// inline asm
	bra.uni 	BB0_1368;

BB0_813:
	setp.eq.s32	%p564, %r24, 13;
	@%p564 bra 	BB0_814;
	bra.uni 	BB0_827;

BB0_814:
	mov.u32 	%r4259, 24;
	// inline asm
	shf.r.wrap.b32 %r18, %r22, %r15, %r4259;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r17, %r21, %r22, %r4259;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r16, %r20, %r21, %r4259;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r15, %r19, %r20, %r4259;
	// inline asm
	mov.u32 	%r8846, 0;
	// inline asm
	shf.r.wrap.b32 %r8845, %r8846, %r19, %r4259;
	// inline asm
	bra.uni 	BB0_818;

BB0_1114:
	setp.eq.s32	%p717, %r26, 29;
	mov.u32 	%r8845, %r8849;
	mov.u32 	%r8846, %r8849;
	mov.u32 	%r8847, %r8849;
	mov.u32 	%r8766, %r8849;
	mov.u32 	%r8850, %r8849;
	mov.u32 	%r8851, %r8849;
	mov.u32 	%r8852, %r8849;
	@%p717 bra 	BB0_1115;
	bra.uni 	BB0_1137;

BB0_1115:
	mov.u32 	%r8845, 0;
	mov.u32 	%r4969, 8;
	// inline asm
	shf.r.wrap.b32 %r8766, %r18, %r8845, %r4969;
	// inline asm
	bra.uni 	BB0_1119;

BB0_507:
	setp.eq.s32	%p328, %r24, 29;
	mov.u32 	%r8720, %r8729;
	@%p328 bra 	BB0_508;
	bra.uni 	BB0_528;

BB0_508:
	bfe.u32 	%r8720, %r18, 8, 8;
	bra.uni 	BB0_528;

BB0_847:
	setp.eq.s32	%p541, %r24, 29;
	mov.u32 	%r8845, %r22;
	mov.u32 	%r8846, %r21;
	mov.u32 	%r8847, %r20;
	mov.u32 	%r8848, %r19;
	@%p541 bra 	BB0_848;
	bra.uni 	BB0_874;

BB0_848:
	mov.u32 	%r8845, 0;
	mov.u32 	%r4011, 24;
	// inline asm
	shf.r.wrap.b32 %r18, %r8845, %r19, %r4011;
	// inline asm
	bra.uni 	BB0_870;

BB0_332:
	mov.u32 	%r3405, 24;
	// inline asm
	shf.r.wrap.b32 %r18, %r17, %r18, %r3405;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r17, %r16, %r17, %r3405;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r16, %r15, %r16, %r3405;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r3386, %r22, %r15, %r3405;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8712, %r21, %r22, %r3405;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8713, %r20, %r21, %r3405;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8714, %r19, %r20, %r3405;
	// inline asm
	mov.u32 	%r3403, 0;
	// inline asm
	shf.r.wrap.b32 %r8715, %r3403, %r19, %r3405;
	// inline asm
	mov.u32 	%r19, %r3386;
	bra.uni 	BB0_338;

BB0_259:
	setp.eq.s32	%p243, %r24, 3;
	@%p243 bra 	BB0_260;
	bra.uni 	BB0_291;

BB0_260:
	mov.u32 	%r3341, 8;
	// inline asm
	shf.r.wrap.b32 %r18, %r17, %r18, %r3341;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r17, %r16, %r17, %r3341;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r16, %r15, %r16, %r3341;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r3322, %r22, %r15, %r3341;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8712, %r21, %r22, %r3341;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8713, %r20, %r21, %r3341;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8714, %r19, %r20, %r3341;
	// inline asm
	mov.u32 	%r3339, 0;
	// inline asm
	shf.r.wrap.b32 %r8715, %r3339, %r19, %r3341;
	// inline asm
	mov.u32 	%r19, %r3322;
	bra.uni 	BB0_338;

BB0_1061:
	setp.eq.s32	%p754, %r26, 3;
	mov.u32 	%r8845, %r8849;
	mov.u32 	%r8846, %r8849;
	mov.u32 	%r8847, %r8849;
	mov.u32 	%r8766, %r8849;
	mov.u32 	%r8850, %r8849;
	mov.u32 	%r8851, %r8849;
	mov.u32 	%r8852, %r8849;
	@%p754 bra 	BB0_1062;
	bra.uni 	BB0_1137;

BB0_1062:
	mov.u32 	%r5423, 24;
	// inline asm
	shf.r.wrap.b32 %r8766, %r19, %r20, %r5423;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8847, %r20, %r21, %r5423;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8846, %r21, %r22, %r5423;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8845, %r22, %r15, %r5423;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8852, %r15, %r16, %r5423;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8851, %r16, %r17, %r5423;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8850, %r17, %r18, %r5423;
	// inline asm
	mov.u32 	%r5422, 0;
	// inline asm
	shf.r.wrap.b32 %r8849, %r18, %r5422, %r5423;
	// inline asm
	bra.uni 	BB0_1137;

BB0_457:
	setp.eq.s32	%p365, %r24, 3;
	mov.u32 	%r8720, %r8729;
	@%p365 bra 	BB0_458;
	bra.uni 	BB0_528;

BB0_458:
	shr.u32 	%r8720, %r19, 24;
	bra.uni 	BB0_528;

BB0_1323:
	setp.eq.s32	%p927, %r6374, 6;
	@%p927 bra 	BB0_1391;
	bra.uni 	BB0_1324;

BB0_1391:
	mov.u32 	%r6792, 16;
	// inline asm
	shf.r.wrap.b32 %r8799, %r16, %r17, %r6792;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8800, %r15, %r16, %r6792;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8801, %r22, %r15, %r6792;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8802, %r21, %r22, %r6792;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8795, %r20, %r21, %r6792;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8796, %r19, %r20, %r6792;
	// inline asm
	mov.u32 	%r8798, 0;
	// inline asm
	shf.r.wrap.b32 %r8797, %r8798, %r19, %r6792;
	// inline asm
	bra.uni 	BB0_1394;

BB0_1093:
	setp.eq.s32	%p731, %r26, 19;
	mov.u32 	%r8845, %r8849;
	mov.u32 	%r8846, %r8849;
	mov.u32 	%r8847, %r8849;
	mov.u32 	%r8766, %r8849;
	mov.u32 	%r8850, %r8849;
	mov.u32 	%r8851, %r8849;
	mov.u32 	%r8852, %r8849;
	@%p731 bra 	BB0_1094;
	bra.uni 	BB0_1137;

BB0_1094:
	mov.u32 	%r5103, 24;
	// inline asm
	shf.r.wrap.b32 %r8766, %r15, %r16, %r5103;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8847, %r16, %r17, %r5103;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8846, %r17, %r18, %r5103;
	// inline asm
	mov.u32 	%r8849, 0;
	// inline asm
	shf.r.wrap.b32 %r8845, %r18, %r8849, %r5103;
	// inline asm

BB0_1122:
	mov.u32 	%r8850, %r8849;
	mov.u32 	%r8851, %r8849;
	mov.u32 	%r8852, %r8849;
	bra.uni 	BB0_1137;

BB0_488:
	setp.eq.s32	%p342, %r24, 19;
	mov.u32 	%r8720, %r8729;
	@%p342 bra 	BB0_489;
	bra.uni 	BB0_528;

BB0_489:
	shr.u32 	%r8720, %r15, 24;
	bra.uni 	BB0_528;

BB0_826:
	setp.eq.s32	%p555, %r24, 19;
	@%p555 bra 	BB0_857;
	bra.uni 	BB0_827;

BB0_857:
	mov.u32 	%r4145, 8;
	// inline asm
	shf.r.wrap.b32 %r18, %r21, %r22, %r4145;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r17, %r20, %r21, %r4145;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r16, %r19, %r20, %r4145;
	// inline asm
	mov.u32 	%r8845, 0;
	// inline asm
	shf.r.wrap.b32 %r15, %r8845, %r19, %r4145;
	// inline asm

BB0_858:
	mov.u32 	%r8846, %r8845;
	mov.u32 	%r8847, %r8845;
	mov.u32 	%r8848, %r8845;
	bra.uni 	BB0_874;

BB0_1076:
	setp.eq.s32	%p743, %r26, 11;
	mov.u32 	%r8845, %r8849;
	mov.u32 	%r8846, %r8849;
	mov.u32 	%r8847, %r8849;
	mov.u32 	%r8766, %r8849;
	mov.u32 	%r8850, %r8849;
	mov.u32 	%r8851, %r8849;
	mov.u32 	%r8852, %r8849;
	@%p743 bra 	BB0_1077;
	bra.uni 	BB0_1137;

BB0_1077:
	mov.u32 	%r5247, 24;
	// inline asm
	shf.r.wrap.b32 %r8766, %r21, %r22, %r5247;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8847, %r22, %r15, %r5247;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8846, %r15, %r16, %r5247;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8845, %r16, %r17, %r5247;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8852, %r17, %r18, %r5247;
	// inline asm
	mov.u32 	%r8849, 0;
	// inline asm
	shf.r.wrap.b32 %r8851, %r18, %r8849, %r5247;
	// inline asm
	mov.u32 	%r8850, %r8849;
	bra.uni 	BB0_1137;

BB0_472:
	setp.eq.s32	%p354, %r24, 11;
	mov.u32 	%r8720, %r8729;
	@%p354 bra 	BB0_473;
	bra.uni 	BB0_528;

BB0_473:
	shr.u32 	%r8720, %r21, 24;
	bra.uni 	BB0_528;

BB0_1356:
	setp.eq.s32	%p904, %r6374, 22;
	@%p904 bra 	BB0_1383;
	bra.uni 	BB0_1357;

BB0_1383:
	mov.u32 	%r6492, 16;
	// inline asm
	shf.r.wrap.b32 %r8799, %r20, %r21, %r6492;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8800, %r19, %r20, %r6492;
	// inline asm
	mov.u32 	%r8795, 0;
	// inline asm
	shf.r.wrap.b32 %r8801, %r8795, %r19, %r6492;
	// inline asm
	bra.uni 	BB0_1359;

BB0_809:
	setp.eq.s32	%p567, %r24, 11;
	@%p567 bra 	BB0_810;
	bra.uni 	BB0_827;

BB0_810:
	mov.u32 	%r4289, 8;
	// inline asm
	shf.r.wrap.b32 %r18, %r15, %r16, %r4289;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r17, %r22, %r15, %r4289;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r16, %r21, %r22, %r4289;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r15, %r20, %r21, %r4289;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8845, %r19, %r20, %r4289;
	// inline asm
	mov.u32 	%r8847, 0;
	// inline asm
	shf.r.wrap.b32 %r8846, %r8847, %r19, %r4289;
	// inline asm
	mov.u32 	%r8848, %r8847;
	bra.uni 	BB0_874;

BB0_1108:
	setp.eq.s32	%p720, %r26, 27;
	mov.u32 	%r8845, %r8849;
	mov.u32 	%r8846, %r8849;
	mov.u32 	%r8847, %r8849;
	mov.u32 	%r8766, %r8849;
	mov.u32 	%r8850, %r8849;
	mov.u32 	%r8851, %r8849;
	mov.u32 	%r8852, %r8849;
	@%p720 bra 	BB0_1109;
	bra.uni 	BB0_1137;

BB0_1109:
	mov.u32 	%r4991, 24;
	// inline asm
	shf.r.wrap.b32 %r8766, %r17, %r18, %r4991;
	// inline asm
	mov.u32 	%r8845, 0;
	// inline asm
	shf.r.wrap.b32 %r8847, %r18, %r8845, %r4991;
	// inline asm

BB0_1110:
	mov.u32 	%r8846, %r8845;
	bra.uni 	BB0_1111;

BB0_503:
	setp.eq.s32	%p331, %r24, 27;
	mov.u32 	%r8720, %r8729;
	@%p331 bra 	BB0_504;
	bra.uni 	BB0_528;

BB0_504:
	shr.u32 	%r8720, %r17, 24;
	bra.uni 	BB0_528;

BB0_842:
	setp.eq.s32	%p544, %r24, 27;
	@%p544 bra 	BB0_843;
	bra.uni 	BB0_827;

BB0_843:
	mov.u32 	%r4033, 8;
	// inline asm
	shf.r.wrap.b32 %r18, %r19, %r20, %r4033;
	// inline asm
	mov.u32 	%r8845, 0;
	// inline asm
	shf.r.wrap.b32 %r17, %r8845, %r19, %r4033;
	// inline asm

BB0_844:
	mov.u32 	%r8846, %r8845;
	mov.u32 	%r8847, %r8845;
	mov.u32 	%r8848, %r8845;
	bra.uni 	BB0_872;

BB0_1068:
	setp.eq.s32	%p749, %r26, 7;
	mov.u32 	%r8845, %r8849;
	mov.u32 	%r8846, %r8849;
	mov.u32 	%r8847, %r8849;
	mov.u32 	%r8766, %r8849;
	mov.u32 	%r8850, %r8849;
	mov.u32 	%r8851, %r8849;
	mov.u32 	%r8852, %r8849;
	@%p749 bra 	BB0_1069;
	bra.uni 	BB0_1137;

BB0_1069:
	mov.u32 	%r5331, 24;
	// inline asm
	shf.r.wrap.b32 %r8766, %r20, %r21, %r5331;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8847, %r21, %r22, %r5331;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8846, %r22, %r15, %r5331;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8845, %r15, %r16, %r5331;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8852, %r16, %r17, %r5331;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8851, %r17, %r18, %r5331;
	// inline asm
	mov.u32 	%r8849, 0;
	// inline asm
	shf.r.wrap.b32 %r8850, %r18, %r8849, %r5331;
	// inline asm
	bra.uni 	BB0_1137;

BB0_464:
	setp.eq.s32	%p360, %r24, 7;
	mov.u32 	%r8720, %r8729;
	@%p360 bra 	BB0_465;
	bra.uni 	BB0_528;

BB0_465:
	shr.u32 	%r8720, %r20, 24;
	bra.uni 	BB0_528;

BB0_1338:
	setp.eq.s32	%p916, %r6374, 14;
	@%p916 bra 	BB0_1387;
	bra.uni 	BB0_1339;

BB0_1387:
	mov.u32 	%r6626, 16;
	// inline asm
	shf.r.wrap.b32 %r8799, %r22, %r15, %r6626;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8800, %r21, %r22, %r6626;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8801, %r20, %r21, %r6626;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8802, %r19, %r20, %r6626;
	// inline asm
	mov.u32 	%r8796, 0;
	// inline asm
	shf.r.wrap.b32 %r8795, %r8796, %r19, %r6626;
	// inline asm
	bra.uni 	BB0_1341;

BB0_801:
	setp.eq.s32	%p573, %r24, 7;
	@%p573 bra 	BB0_802;
	bra.uni 	BB0_827;

BB0_802:
	mov.u32 	%r4373, 8;
	// inline asm
	shf.r.wrap.b32 %r18, %r16, %r17, %r4373;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r17, %r15, %r16, %r4373;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r16, %r22, %r15, %r4373;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r15, %r21, %r22, %r4373;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8845, %r20, %r21, %r4373;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8846, %r19, %r20, %r4373;
	// inline asm
	mov.u32 	%r8848, 0;
	// inline asm
	shf.r.wrap.b32 %r8847, %r8848, %r19, %r4373;
	// inline asm
	bra.uni 	BB0_874;

BB0_1100:
	setp.eq.s32	%p726, %r26, 23;
	mov.u32 	%r8845, %r8849;
	mov.u32 	%r8846, %r8849;
	mov.u32 	%r8847, %r8849;
	mov.u32 	%r8766, %r8849;
	mov.u32 	%r8850, %r8849;
	mov.u32 	%r8851, %r8849;
	mov.u32 	%r8852, %r8849;
	@%p726 bra 	BB0_1101;
	bra.uni 	BB0_1137;

BB0_1101:
	mov.u32 	%r5043, 24;
	// inline asm
	shf.r.wrap.b32 %r8766, %r16, %r17, %r5043;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8847, %r17, %r18, %r5043;
	// inline asm
	mov.u32 	%r8845, 0;
	// inline asm
	shf.r.wrap.b32 %r8846, %r18, %r8845, %r5043;
	// inline asm
	bra.uni 	BB0_1111;

BB0_495:
	setp.eq.s32	%p337, %r24, 23;
	mov.u32 	%r8720, %r8729;
	@%p337 bra 	BB0_496;
	bra.uni 	BB0_528;

BB0_496:
	shr.u32 	%r8720, %r16, 24;
	bra.uni 	BB0_528;

BB0_833:
	setp.eq.s32	%p550, %r24, 23;
	@%p550 bra 	BB0_834;
	bra.uni 	BB0_827;

BB0_834:
	mov.u32 	%r4085, 8;
	// inline asm
	shf.r.wrap.b32 %r18, %r20, %r21, %r4085;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r17, %r19, %r20, %r4085;
	// inline asm
	mov.u32 	%r8845, 0;
	// inline asm
	shf.r.wrap.b32 %r16, %r8845, %r19, %r4085;
	// inline asm

BB0_835:
	mov.u32 	%r8846, %r8845;
	mov.u32 	%r8847, %r8845;
	mov.u32 	%r8848, %r8845;
	bra.uni 	BB0_873;

BB0_1083:
	setp.eq.s32	%p738, %r26, 15;
	mov.u32 	%r8845, %r8849;
	mov.u32 	%r8846, %r8849;
	mov.u32 	%r8847, %r8849;
	mov.u32 	%r8766, %r8849;
	mov.u32 	%r8850, %r8849;
	mov.u32 	%r8851, %r8849;
	mov.u32 	%r8852, %r8849;
	@%p738 bra 	BB0_1084;
	bra.uni 	BB0_1137;

BB0_1084:
	mov.u32 	%r5171, 24;
	// inline asm
	shf.r.wrap.b32 %r8766, %r22, %r15, %r5171;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8847, %r15, %r16, %r5171;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8846, %r16, %r17, %r5171;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8845, %r17, %r18, %r5171;
	// inline asm
	mov.u32 	%r8849, 0;
	// inline asm
	shf.r.wrap.b32 %r8852, %r18, %r8849, %r5171;
	// inline asm

BB0_1085:
	mov.u32 	%r8850, %r8849;
	mov.u32 	%r8851, %r8849;
	bra.uni 	BB0_1137;

BB0_479:
	setp.eq.s32	%p349, %r24, 15;
	mov.u32 	%r8720, %r8729;
	@%p349 bra 	BB0_480;
	bra.uni 	BB0_528;

BB0_480:
	shr.u32 	%r8720, %r22, 24;
	bra.uni 	BB0_528;

BB0_1374:
	setp.eq.s32	%p893, %r6374, 30;
	@%p893 bra 	BB0_1378;
	bra.uni 	BB0_1375;

BB0_1378:
	mov.u32 	%r8795, 0;
	mov.u32 	%r6390, 16;
	// inline asm
	shf.r.wrap.b32 %r8799, %r8795, %r19, %r6390;
	// inline asm
	bra.uni 	BB0_1377;

BB0_816:
	setp.eq.s32	%p562, %r24, 15;
	@%p562 bra 	BB0_817;
	bra.uni 	BB0_827;

BB0_817:
	mov.u32 	%r4213, 8;
	// inline asm
	shf.r.wrap.b32 %r18, %r22, %r15, %r4213;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r17, %r21, %r22, %r4213;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r16, %r20, %r21, %r4213;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r15, %r19, %r20, %r4213;
	// inline asm
	mov.u32 	%r8846, 0;
	// inline asm
	shf.r.wrap.b32 %r8845, %r8846, %r19, %r4213;
	// inline asm

BB0_818:
	mov.u32 	%r8847, %r8846;
	mov.u32 	%r8848, %r8846;
	bra.uni 	BB0_874;

BB0_827:
	mov.u32 	%r8845, %r22;
	mov.u32 	%r8846, %r21;
	mov.u32 	%r8847, %r20;
	mov.u32 	%r8848, %r19;
	bra.uni 	BB0_874;

BB0_1117:
	setp.ne.s32	%p715, %r26, 31;
	mov.u32 	%r8845, %r8849;
	mov.u32 	%r8846, %r8849;
	mov.u32 	%r8847, %r8849;
	mov.u32 	%r8766, %r8849;
	mov.u32 	%r8850, %r8849;
	mov.u32 	%r8851, %r8849;
	mov.u32 	%r8852, %r8849;
	@%p715 bra 	BB0_1137;

	mov.u32 	%r8845, 0;
	mov.u32 	%r4947, 24;
	// inline asm
	shf.r.wrap.b32 %r8766, %r18, %r8845, %r4947;
	// inline asm

BB0_1119:
	mov.u32 	%r8846, %r8845;
	mov.u32 	%r8847, %r8845;

BB0_1111:
	mov.u32 	%r8849, %r8845;
	mov.u32 	%r8850, %r8845;
	mov.u32 	%r8851, %r8845;
	mov.u32 	%r8852, %r8845;

BB0_1137:
	and.b32  	%r5489, %r23, 3;
	shl.b32 	%r5490, %r5489, 3;
	mov.u32 	%r5491, 1;
	shl.b32 	%r5492, %r5491, %r5490;
	add.s32 	%r1058, %r5492, -1;
	neg.s32 	%r1059, %r5492;
	shr.u32 	%r5488, %r24, 2;
	setp.gt.s32	%p757, %r5488, 3;
	@%p757 bra 	BB0_1145;

	setp.gt.s32	%p763, %r5488, 1;
	@%p763 bra 	BB0_1142;

	setp.eq.s32	%p766, %r5488, 0;
	@%p766 bra 	BB0_1160;
	bra.uni 	BB0_1140;

BB0_1160:
	and.b32  	%r5507, %r1058, %r19;
	and.b32  	%r5508, %r8766, %r1059;
	or.b32  	%r8848, %r5508, %r5507;
	bra.uni 	BB0_1161;

BB0_1145:
	setp.gt.s32	%p758, %r5488, 5;
	@%p758 bra 	BB0_1149;

	setp.eq.s32	%p761, %r5488, 4;
	@%p761 bra 	BB0_1156;
	bra.uni 	BB0_1147;

BB0_1156:
	and.b32  	%r5499, %r1058, %r15;
	and.b32  	%r5500, %r8852, %r1059;
	or.b32  	%r8852, %r5500, %r5499;
	mov.u32 	%r8845, %r22;
	bra.uni 	BB0_1157;

BB0_1142:
	setp.eq.s32	%p764, %r5488, 2;
	@%p764 bra 	BB0_1159;
	bra.uni 	BB0_1143;

BB0_1159:
	and.b32  	%r5503, %r1058, %r21;
	and.b32  	%r5504, %r8846, %r1059;
	or.b32  	%r8846, %r5504, %r5503;
	bra.uni 	BB0_1158;

BB0_1149:
	setp.eq.s32	%p759, %r5488, 6;
	@%p759 bra 	BB0_1155;
	bra.uni 	BB0_1150;

BB0_1155:
	and.b32  	%r5495, %r1058, %r17;
	and.b32  	%r5496, %r8850, %r1059;
	or.b32  	%r8850, %r5496, %r5495;
	mov.u32 	%r8845, %r22;
	mov.u32 	%r8846, %r21;
	mov.u32 	%r8847, %r20;
	mov.u32 	%r8848, %r19;
	bra.uni 	BB0_1153;

BB0_1140:
	setp.eq.s32	%p767, %r5488, 1;
	@%p767 bra 	BB0_1141;
	bra.uni 	BB0_1151;

BB0_1141:
	and.b32  	%r5505, %r1058, %r20;
	and.b32  	%r5506, %r8847, %r1059;
	or.b32  	%r8847, %r5506, %r5505;
	mov.u32 	%r8848, %r19;
	bra.uni 	BB0_1161;

BB0_1147:
	setp.eq.s32	%p762, %r5488, 5;
	@%p762 bra 	BB0_1148;
	bra.uni 	BB0_1151;

BB0_1148:
	and.b32  	%r5497, %r1058, %r16;
	and.b32  	%r5498, %r8851, %r1059;
	or.b32  	%r8851, %r5498, %r5497;
	mov.u32 	%r8845, %r22;
	mov.u32 	%r8846, %r21;
	mov.u32 	%r8847, %r20;
	mov.u32 	%r8848, %r19;
	mov.u32 	%r8852, %r15;
	bra.uni 	BB0_1161;

BB0_1143:
	setp.eq.s32	%p765, %r5488, 3;
	@%p765 bra 	BB0_1144;
	bra.uni 	BB0_1151;

BB0_1144:
	and.b32  	%r5501, %r1058, %r22;
	and.b32  	%r5502, %r8845, %r1059;
	or.b32  	%r8845, %r5502, %r5501;

BB0_1157:
	mov.u32 	%r8846, %r21;

BB0_1158:
	mov.u32 	%r8847, %r20;
	mov.u32 	%r8848, %r19;
	bra.uni 	BB0_1161;

BB0_1150:
	setp.ne.s32	%p760, %r5488, 7;
	@%p760 bra 	BB0_1151;

	and.b32  	%r5493, %r1058, %r18;
	and.b32  	%r5494, %r8849, %r1059;
	or.b32  	%r8849, %r5494, %r5493;
	mov.u32 	%r8845, %r22;
	mov.u32 	%r8846, %r21;
	mov.u32 	%r8847, %r20;
	mov.u32 	%r8848, %r19;
	bra.uni 	BB0_1152;

BB0_1151:
	mov.u32 	%r8845, %r22;
	mov.u32 	%r8846, %r21;
	mov.u32 	%r8847, %r20;
	mov.u32 	%r8848, %r19;
	mov.u32 	%r8849, %r18;

BB0_1152:
	mov.u32 	%r8850, %r17;

BB0_1153:
	mov.u32 	%r8851, %r16;
	mov.u32 	%r8852, %r15;

BB0_1161:
	sub.s32 	%r8853, %r14, %r26;
	bra.uni 	BB0_1554;

BB0_510:
	setp.ne.s32	%p326, %r24, 31;
	mov.u32 	%r8720, %r8729;
	@%p326 bra 	BB0_528;

	shr.u32 	%r8720, %r18, 24;

BB0_528:
	setp.gt.s32	%p368, %r26, 15;
	@%p368 bra 	BB0_560;

	setp.gt.s32	%p392, %r26, 7;
	@%p392 bra 	BB0_545;

	setp.gt.s32	%p404, %r26, 3;
	@%p404 bra 	BB0_538;

	setp.gt.s32	%p410, %r26, 1;
	@%p410 bra 	BB0_535;

	setp.eq.s32	%p413, %r26, 0;
	@%p413 bra 	BB0_606;
	bra.uni 	BB0_533;

BB0_606:
	and.b32  	%r8729, %r19, 255;
	and.b32  	%r3715, %r19, -256;
	or.b32  	%r19, %r8720, %r3715;
	bra.uni 	BB0_607;

BB0_560:
	setp.gt.s32	%p369, %r26, 23;
	@%p369 bra 	BB0_576;

	setp.gt.s32	%p381, %r26, 19;
	@%p381 bra 	BB0_569;

	setp.gt.s32	%p387, %r26, 17;
	@%p387 bra 	BB0_566;

	setp.eq.s32	%p390, %r26, 16;
	@%p390 bra 	BB0_598;
	bra.uni 	BB0_564;

BB0_598:
	and.b32  	%r8729, %r15, 255;
	and.b32  	%r3691, %r15, -256;
	or.b32  	%r15, %r8720, %r3691;
	bra.uni 	BB0_607;

BB0_545:
	setp.gt.s32	%p393, %r26, 11;
	@%p393 bra 	BB0_553;

	setp.gt.s32	%p399, %r26, 9;
	@%p399 bra 	BB0_550;

	setp.eq.s32	%p402, %r26, 8;
	@%p402 bra 	BB0_602;
	bra.uni 	BB0_548;

BB0_602:
	and.b32  	%r8729, %r21, 255;
	and.b32  	%r3703, %r21, -256;
	or.b32  	%r21, %r8720, %r3703;
	bra.uni 	BB0_607;

BB0_576:
	setp.gt.s32	%p370, %r26, 27;
	@%p370 bra 	BB0_584;

	setp.gt.s32	%p376, %r26, 25;
	@%p376 bra 	BB0_581;

	setp.eq.s32	%p379, %r26, 24;
	@%p379 bra 	BB0_594;
	bra.uni 	BB0_579;

BB0_594:
	and.b32  	%r8729, %r17, 255;
	and.b32  	%r3679, %r17, -256;
	or.b32  	%r17, %r8720, %r3679;
	bra.uni 	BB0_607;

BB0_538:
	setp.gt.s32	%p405, %r26, 5;
	@%p405 bra 	BB0_542;

	setp.eq.s32	%p408, %r26, 4;
	@%p408 bra 	BB0_604;
	bra.uni 	BB0_540;

BB0_604:
	and.b32  	%r8729, %r20, 255;
	and.b32  	%r3709, %r20, -256;
	or.b32  	%r20, %r8720, %r3709;
	bra.uni 	BB0_607;

BB0_569:
	setp.gt.s32	%p382, %r26, 21;
	@%p382 bra 	BB0_573;

	setp.eq.s32	%p385, %r26, 20;
	@%p385 bra 	BB0_596;
	bra.uni 	BB0_571;

BB0_596:
	and.b32  	%r8729, %r16, 255;
	and.b32  	%r3685, %r16, -256;
	or.b32  	%r16, %r8720, %r3685;
	bra.uni 	BB0_607;

BB0_553:
	setp.gt.s32	%p394, %r26, 13;
	@%p394 bra 	BB0_557;

	setp.eq.s32	%p397, %r26, 12;
	@%p397 bra 	BB0_600;
	bra.uni 	BB0_555;

BB0_600:
	and.b32  	%r8729, %r22, 255;
	and.b32  	%r3697, %r22, -256;
	or.b32  	%r22, %r8720, %r3697;
	bra.uni 	BB0_607;

BB0_584:
	setp.gt.s32	%p371, %r26, 29;
	@%p371 bra 	BB0_588;

	setp.eq.s32	%p374, %r26, 28;
	@%p374 bra 	BB0_592;
	bra.uni 	BB0_586;

BB0_592:
	and.b32  	%r8729, %r18, 255;
	and.b32  	%r3673, %r18, -256;
	or.b32  	%r18, %r8720, %r3673;
	bra.uni 	BB0_607;

BB0_535:
	setp.eq.s32	%p411, %r26, 2;
	@%p411 bra 	BB0_605;
	bra.uni 	BB0_536;

BB0_605:
	bfe.u32 	%r8729, %r19, 16, 8;
	shl.b32 	%r3711, %r8720, 16;
	and.b32  	%r3712, %r19, -16711681;
	or.b32  	%r19, %r3711, %r3712;
	bra.uni 	BB0_607;

BB0_566:
	setp.eq.s32	%p388, %r26, 18;
	@%p388 bra 	BB0_597;
	bra.uni 	BB0_567;

BB0_597:
	bfe.u32 	%r8729, %r15, 16, 8;
	shl.b32 	%r3687, %r8720, 16;
	and.b32  	%r3688, %r15, -16711681;
	or.b32  	%r15, %r3687, %r3688;
	bra.uni 	BB0_607;

BB0_550:
	setp.eq.s32	%p400, %r26, 10;
	@%p400 bra 	BB0_601;
	bra.uni 	BB0_551;

BB0_601:
	bfe.u32 	%r8729, %r21, 16, 8;
	shl.b32 	%r3699, %r8720, 16;
	and.b32  	%r3700, %r21, -16711681;
	or.b32  	%r21, %r3699, %r3700;
	bra.uni 	BB0_607;

BB0_581:
	setp.eq.s32	%p377, %r26, 26;
	@%p377 bra 	BB0_593;
	bra.uni 	BB0_582;

BB0_593:
	bfe.u32 	%r8729, %r17, 16, 8;
	shl.b32 	%r3675, %r8720, 16;
	and.b32  	%r3676, %r17, -16711681;
	or.b32  	%r17, %r3675, %r3676;
	bra.uni 	BB0_607;

BB0_542:
	setp.eq.s32	%p406, %r26, 6;
	@%p406 bra 	BB0_603;
	bra.uni 	BB0_543;

BB0_603:
	bfe.u32 	%r8729, %r20, 16, 8;
	shl.b32 	%r3705, %r8720, 16;
	and.b32  	%r3706, %r20, -16711681;
	or.b32  	%r20, %r3705, %r3706;
	bra.uni 	BB0_607;

BB0_573:
	setp.eq.s32	%p383, %r26, 22;
	@%p383 bra 	BB0_595;
	bra.uni 	BB0_574;

BB0_595:
	bfe.u32 	%r8729, %r16, 16, 8;
	shl.b32 	%r3681, %r8720, 16;
	and.b32  	%r3682, %r16, -16711681;
	or.b32  	%r16, %r3681, %r3682;
	bra.uni 	BB0_607;

BB0_557:
	setp.eq.s32	%p395, %r26, 14;
	@%p395 bra 	BB0_599;
	bra.uni 	BB0_558;

BB0_599:
	bfe.u32 	%r8729, %r22, 16, 8;
	shl.b32 	%r3693, %r8720, 16;
	and.b32  	%r3694, %r22, -16711681;
	or.b32  	%r22, %r3693, %r3694;
	bra.uni 	BB0_607;

BB0_588:
	setp.eq.s32	%p372, %r26, 30;
	@%p372 bra 	BB0_591;
	bra.uni 	BB0_589;

BB0_591:
	bfe.u32 	%r8729, %r18, 16, 8;
	shl.b32 	%r3669, %r8720, 16;
	and.b32  	%r3670, %r18, -16711681;
	or.b32  	%r18, %r3669, %r3670;
	bra.uni 	BB0_607;

BB0_850:
	setp.ne.s32	%p539, %r24, 30;
	mov.u32 	%r8845, %r22;
	mov.u32 	%r8846, %r21;
	mov.u32 	%r8847, %r20;
	mov.u32 	%r8848, %r19;
	@%p539 bra 	BB0_874;

	mov.u32 	%r8845, 0;
	mov.u32 	%r4000, 16;
	// inline asm
	shf.r.wrap.b32 %r18, %r8845, %r19, %r4000;
	// inline asm

BB0_870:
	mov.u32 	%r8846, %r8845;
	mov.u32 	%r8847, %r8845;
	mov.u32 	%r8848, %r8845;

BB0_871:
	mov.u32 	%r17, %r8845;

BB0_872:
	mov.u32 	%r16, %r8845;

BB0_873:
	mov.u32 	%r15, %r8845;

BB0_874:
	@%p534 bra 	BB0_903;

	setp.gt.s32	%p603, %r24, 7;
	@%p603 bra 	BB0_888;

	setp.gt.s32	%p615, %r24, 3;
	@%p615 bra 	BB0_881;

	setp.eq.s32	%p621, %r24, 1;
	@%p621 bra 	BB0_950;

	setp.eq.s32	%p622, %r24, 2;
	@%p622 bra 	BB0_949;
	bra.uni 	BB0_879;

BB0_949:
	shl.b32 	%r4755, %r610, 8;
	or.b32  	%r4756, %r4755, %r610;
	or.b32  	%r8848, %r4756, %r8848;
	bra.uni 	BB0_771;

BB0_903:
	setp.gt.s32	%p580, %r24, 23;
	@%p580 bra 	BB0_919;

	setp.gt.s32	%p592, %r24, 19;
	@%p592 bra 	BB0_912;

	setp.gt.s32	%p598, %r24, 17;
	@%p598 bra 	BB0_909;

	setp.eq.s32	%p601, %r24, 16;
	@%p601 bra 	BB0_942;
	bra.uni 	BB0_907;

BB0_942:
	mov.u32 	%r4655, 64;
	prmt.b32 	%r4656, %r19, %r19, %r4655;
	mov.u32 	%r4657, 1040;
	prmt.b32 	%r4658, %r4656, %r19, %r4657;
	mov.u32 	%r4659, 16912;
	prmt.b32 	%r4660, %r4658, %r19, %r4659;
	or.b32  	%r8848, %r4660, %r8848;
	or.b32  	%r8847, %r4660, %r8847;
	or.b32  	%r8846, %r4660, %r8846;
	or.b32  	%r8845, %r4660, %r8845;
	bra.uni 	BB0_771;

BB0_888:
	setp.gt.s32	%p604, %r24, 11;
	@%p604 bra 	BB0_896;

	setp.gt.s32	%p610, %r24, 9;
	@%p610 bra 	BB0_893;

	setp.eq.s32	%p613, %r24, 8;
	@%p613 bra 	BB0_946;
	bra.uni 	BB0_891;

BB0_946:
	mov.u32 	%r4715, 64;
	prmt.b32 	%r4716, %r19, %r19, %r4715;
	mov.u32 	%r4717, 1040;
	prmt.b32 	%r4718, %r4716, %r19, %r4717;
	mov.u32 	%r4719, 16912;
	prmt.b32 	%r4720, %r4718, %r19, %r4719;
	or.b32  	%r8848, %r4720, %r8848;
	or.b32  	%r8847, %r4720, %r8847;
	bra.uni 	BB0_771;

BB0_919:
	setp.gt.s32	%p581, %r24, 27;
	@%p581 bra 	BB0_927;

	setp.gt.s32	%p587, %r24, 25;
	@%p587 bra 	BB0_924;

	setp.eq.s32	%p590, %r24, 24;
	@%p590 bra 	BB0_938;
	bra.uni 	BB0_922;

BB0_938:
	mov.u32 	%r4595, 64;
	prmt.b32 	%r4596, %r19, %r19, %r4595;
	mov.u32 	%r4597, 1040;
	prmt.b32 	%r4598, %r4596, %r19, %r4597;
	mov.u32 	%r4599, 16912;
	prmt.b32 	%r4600, %r4598, %r19, %r4599;
	or.b32  	%r8848, %r4600, %r8848;
	or.b32  	%r8847, %r4600, %r8847;
	or.b32  	%r8846, %r4600, %r8846;
	or.b32  	%r8845, %r4600, %r8845;
	or.b32  	%r8852, %r4600, %r15;
	or.b32  	%r8851, %r4600, %r16;
	bra.uni 	BB0_734;

BB0_881:
	setp.gt.s32	%p616, %r24, 5;
	@%p616 bra 	BB0_885;

	setp.eq.s32	%p619, %r24, 4;
	@%p619 bra 	BB0_948;
	bra.uni 	BB0_883;

BB0_948:
	mov.u32 	%r4745, 64;
	prmt.b32 	%r4746, %r19, %r19, %r4745;
	mov.u32 	%r4747, 1040;
	prmt.b32 	%r4748, %r4746, %r19, %r4747;
	mov.u32 	%r4749, 16912;
	prmt.b32 	%r4750, %r4748, %r19, %r4749;
	or.b32  	%r8848, %r4750, %r8848;
	bra.uni 	BB0_771;

BB0_912:
	setp.gt.s32	%p593, %r24, 21;
	@%p593 bra 	BB0_916;

	setp.eq.s32	%p596, %r24, 20;
	@%p596 bra 	BB0_940;
	bra.uni 	BB0_914;

BB0_940:
	mov.u32 	%r4625, 64;
	prmt.b32 	%r4626, %r19, %r19, %r4625;
	mov.u32 	%r4627, 1040;
	prmt.b32 	%r4628, %r4626, %r19, %r4627;
	mov.u32 	%r4629, 16912;
	prmt.b32 	%r4630, %r4628, %r19, %r4629;
	or.b32  	%r8848, %r4630, %r8848;
	or.b32  	%r8847, %r4630, %r8847;
	or.b32  	%r8846, %r4630, %r8846;
	or.b32  	%r8845, %r4630, %r8845;
	or.b32  	%r8852, %r4630, %r15;
	bra.uni 	BB0_765;

BB0_896:
	setp.gt.s32	%p605, %r24, 13;
	@%p605 bra 	BB0_900;

	setp.eq.s32	%p608, %r24, 12;
	@%p608 bra 	BB0_944;
	bra.uni 	BB0_898;

BB0_944:
	mov.u32 	%r4685, 64;
	prmt.b32 	%r4686, %r19, %r19, %r4685;
	mov.u32 	%r4687, 1040;
	prmt.b32 	%r4688, %r4686, %r19, %r4687;
	mov.u32 	%r4689, 16912;
	prmt.b32 	%r4690, %r4688, %r19, %r4689;
	or.b32  	%r8848, %r4690, %r8848;
	or.b32  	%r8847, %r4690, %r8847;
	or.b32  	%r8846, %r4690, %r8846;
	bra.uni 	BB0_771;

BB0_927:
	setp.gt.s32	%p582, %r24, 29;
	@%p582 bra 	BB0_931;

	setp.eq.s32	%p585, %r24, 28;
	@%p585 bra 	BB0_935;
	bra.uni 	BB0_929;

BB0_935:
	mov.u32 	%r4565, 64;
	prmt.b32 	%r4566, %r19, %r19, %r4565;
	mov.u32 	%r4567, 1040;
	prmt.b32 	%r4568, %r4566, %r19, %r4567;
	mov.u32 	%r4569, 16912;
	prmt.b32 	%r4570, %r4568, %r19, %r4569;
	or.b32  	%r8848, %r4570, %r8848;
	or.b32  	%r8847, %r4570, %r8847;
	or.b32  	%r8846, %r4570, %r8846;
	or.b32  	%r8845, %r4570, %r8845;
	or.b32  	%r8852, %r4570, %r15;
	or.b32  	%r8851, %r4570, %r16;
	or.b32  	%r8850, %r4570, %r17;
	mov.u32 	%r8849, %r18;
	bra.uni 	BB0_1554;

BB0_909:
	setp.eq.s32	%p599, %r24, 18;
	@%p599 bra 	BB0_941;
	bra.uni 	BB0_910;

BB0_941:
	mov.u32 	%r4641, 64;
	prmt.b32 	%r4642, %r19, %r19, %r4641;
	mov.u32 	%r4643, 1040;
	prmt.b32 	%r4644, %r4642, %r19, %r4643;
	mov.u32 	%r4645, 16912;
	prmt.b32 	%r4646, %r4644, %r19, %r4645;
	or.b32  	%r8848, %r4646, %r8848;
	or.b32  	%r8847, %r4646, %r8847;
	or.b32  	%r8846, %r4646, %r8846;
	or.b32  	%r8845, %r4646, %r8845;
	shl.b32 	%r4647, %r610, 8;
	or.b32  	%r4648, %r4647, %r610;
	or.b32  	%r8852, %r4648, %r15;
	bra.uni 	BB0_765;

BB0_893:
	setp.eq.s32	%p611, %r24, 10;
	@%p611 bra 	BB0_945;
	bra.uni 	BB0_894;

BB0_945:
	mov.u32 	%r4701, 64;
	prmt.b32 	%r4702, %r19, %r19, %r4701;
	mov.u32 	%r4703, 1040;
	prmt.b32 	%r4704, %r4702, %r19, %r4703;
	mov.u32 	%r4705, 16912;
	prmt.b32 	%r4706, %r4704, %r19, %r4705;
	or.b32  	%r8848, %r4706, %r8848;
	or.b32  	%r8847, %r4706, %r8847;
	shl.b32 	%r4707, %r610, 8;
	or.b32  	%r4708, %r4707, %r610;
	or.b32  	%r8846, %r4708, %r8846;
	bra.uni 	BB0_771;

BB0_924:
	setp.eq.s32	%p588, %r24, 26;
	@%p588 bra 	BB0_936;
	bra.uni 	BB0_925;

BB0_936:
	mov.u32 	%r4581, 64;
	prmt.b32 	%r4582, %r19, %r19, %r4581;
	mov.u32 	%r4583, 1040;
	prmt.b32 	%r4584, %r4582, %r19, %r4583;
	mov.u32 	%r4585, 16912;
	prmt.b32 	%r4586, %r4584, %r19, %r4585;
	or.b32  	%r8848, %r4586, %r8848;
	or.b32  	%r8847, %r4586, %r8847;
	or.b32  	%r8846, %r4586, %r8846;
	or.b32  	%r8845, %r4586, %r8845;
	or.b32  	%r8852, %r4586, %r15;
	or.b32  	%r8851, %r4586, %r16;
	shl.b32 	%r4587, %r610, 8;
	or.b32  	%r4588, %r4587, %r610;
	or.b32  	%r8850, %r4588, %r17;
	mov.u32 	%r8849, %r18;
	bra.uni 	BB0_1554;

BB0_885:
	setp.eq.s32	%p617, %r24, 6;
	@%p617 bra 	BB0_947;
	bra.uni 	BB0_886;

BB0_947:
	mov.u32 	%r4731, 64;
	prmt.b32 	%r4732, %r19, %r19, %r4731;
	mov.u32 	%r4733, 1040;
	prmt.b32 	%r4734, %r4732, %r19, %r4733;
	mov.u32 	%r4735, 16912;
	prmt.b32 	%r4736, %r4734, %r19, %r4735;
	or.b32  	%r8848, %r4736, %r8848;
	shl.b32 	%r4737, %r610, 8;
	or.b32  	%r4738, %r4737, %r610;
	or.b32  	%r8847, %r4738, %r8847;
	bra.uni 	BB0_771;

BB0_916:
	setp.eq.s32	%p594, %r24, 22;
	@%p594 bra 	BB0_939;
	bra.uni 	BB0_917;

BB0_939:
	mov.u32 	%r4611, 64;
	prmt.b32 	%r4612, %r19, %r19, %r4611;
	mov.u32 	%r4613, 1040;
	prmt.b32 	%r4614, %r4612, %r19, %r4613;
	mov.u32 	%r4615, 16912;
	prmt.b32 	%r4616, %r4614, %r19, %r4615;
	or.b32  	%r8848, %r4616, %r8848;
	or.b32  	%r8847, %r4616, %r8847;
	or.b32  	%r8846, %r4616, %r8846;
	or.b32  	%r8845, %r4616, %r8845;
	or.b32  	%r8852, %r4616, %r15;
	shl.b32 	%r4617, %r610, 8;
	or.b32  	%r4618, %r4617, %r610;
	or.b32  	%r8851, %r4618, %r16;
	bra.uni 	BB0_734;

BB0_900:
	setp.eq.s32	%p606, %r24, 14;
	@%p606 bra 	BB0_943;
	bra.uni 	BB0_901;

BB0_943:
	mov.u32 	%r4671, 64;
	prmt.b32 	%r4672, %r19, %r19, %r4671;
	mov.u32 	%r4673, 1040;
	prmt.b32 	%r4674, %r4672, %r19, %r4673;
	mov.u32 	%r4675, 16912;
	prmt.b32 	%r4676, %r4674, %r19, %r4675;
	or.b32  	%r8848, %r4676, %r8848;
	or.b32  	%r8847, %r4676, %r8847;
	or.b32  	%r8846, %r4676, %r8846;
	shl.b32 	%r4677, %r610, 8;
	or.b32  	%r4678, %r4677, %r610;
	or.b32  	%r8845, %r4678, %r8845;
	bra.uni 	BB0_771;

BB0_931:
	setp.eq.s32	%p583, %r24, 30;
	@%p583 bra 	BB0_934;
	bra.uni 	BB0_932;

BB0_934:
	mov.u32 	%r4551, 64;
	prmt.b32 	%r4552, %r19, %r19, %r4551;
	mov.u32 	%r4553, 1040;
	prmt.b32 	%r4554, %r4552, %r19, %r4553;
	mov.u32 	%r4555, 16912;
	prmt.b32 	%r4556, %r4554, %r19, %r4555;
	or.b32  	%r8848, %r4556, %r8848;
	or.b32  	%r8847, %r4556, %r8847;
	or.b32  	%r8846, %r4556, %r8846;
	or.b32  	%r8845, %r4556, %r8845;
	or.b32  	%r8852, %r4556, %r15;
	or.b32  	%r8851, %r4556, %r16;
	or.b32  	%r8850, %r4556, %r17;
	shl.b32 	%r4557, %r610, 8;
	or.b32  	%r4558, %r4557, %r610;
	or.b32  	%r8849, %r4558, %r18;
	bra.uni 	BB0_1554;

BB0_950:
	or.b32  	%r8848, %r8848, %r610;
	bra.uni 	BB0_771;

BB0_879:
	setp.eq.s32	%p623, %r24, 3;
	@%p623 bra 	BB0_880;
	bra.uni 	BB0_771;

BB0_880:
	shl.b32 	%r4751, %r610, 8;
	or.b32  	%r4752, %r4751, %r610;
	shl.b32 	%r4753, %r610, 16;
	or.b32  	%r4754, %r4752, %r4753;
	or.b32  	%r8848, %r4754, %r8848;
	bra.uni 	BB0_771;

BB0_533:
	setp.eq.s32	%p414, %r26, 1;
	@%p414 bra 	BB0_534;
	bra.uni 	BB0_607;

BB0_534:
	bfe.u32 	%r8729, %r19, 8, 8;
	shl.b32 	%r3713, %r8720, 8;
	and.b32  	%r3714, %r19, -65281;
	or.b32  	%r19, %r3713, %r3714;
	bra.uni 	BB0_607;

BB0_564:
	setp.eq.s32	%p391, %r26, 17;
	@%p391 bra 	BB0_565;
	bra.uni 	BB0_607;

BB0_565:
	bfe.u32 	%r8729, %r15, 8, 8;
	shl.b32 	%r3689, %r8720, 8;
	and.b32  	%r3690, %r15, -65281;
	or.b32  	%r15, %r3689, %r3690;
	bra.uni 	BB0_607;

BB0_548:
	setp.eq.s32	%p403, %r26, 9;
	@%p403 bra 	BB0_549;
	bra.uni 	BB0_607;

BB0_549:
	bfe.u32 	%r8729, %r21, 8, 8;
	shl.b32 	%r3701, %r8720, 8;
	and.b32  	%r3702, %r21, -65281;
	or.b32  	%r21, %r3701, %r3702;
	bra.uni 	BB0_607;

BB0_579:
	setp.eq.s32	%p380, %r26, 25;
	@%p380 bra 	BB0_580;
	bra.uni 	BB0_607;

BB0_580:
	bfe.u32 	%r8729, %r17, 8, 8;
	shl.b32 	%r3677, %r8720, 8;
	and.b32  	%r3678, %r17, -65281;
	or.b32  	%r17, %r3677, %r3678;
	bra.uni 	BB0_607;

BB0_540:
	setp.eq.s32	%p409, %r26, 5;
	@%p409 bra 	BB0_541;
	bra.uni 	BB0_607;

BB0_541:
	bfe.u32 	%r8729, %r20, 8, 8;
	shl.b32 	%r3707, %r8720, 8;
	and.b32  	%r3708, %r20, -65281;
	or.b32  	%r20, %r3707, %r3708;
	bra.uni 	BB0_607;

BB0_571:
	setp.eq.s32	%p386, %r26, 21;
	@%p386 bra 	BB0_572;
	bra.uni 	BB0_607;

BB0_572:
	bfe.u32 	%r8729, %r16, 8, 8;
	shl.b32 	%r3683, %r8720, 8;
	and.b32  	%r3684, %r16, -65281;
	or.b32  	%r16, %r3683, %r3684;
	bra.uni 	BB0_607;

BB0_555:
	setp.eq.s32	%p398, %r26, 13;
	@%p398 bra 	BB0_556;
	bra.uni 	BB0_607;

BB0_556:
	bfe.u32 	%r8729, %r22, 8, 8;
	shl.b32 	%r3695, %r8720, 8;
	and.b32  	%r3696, %r22, -65281;
	or.b32  	%r22, %r3695, %r3696;
	bra.uni 	BB0_607;

BB0_586:
	setp.eq.s32	%p375, %r26, 29;
	@%p375 bra 	BB0_587;
	bra.uni 	BB0_607;

BB0_587:
	bfe.u32 	%r8729, %r18, 8, 8;
	shl.b32 	%r3671, %r8720, 8;
	and.b32  	%r3672, %r18, -65281;
	or.b32  	%r18, %r3671, %r3672;
	bra.uni 	BB0_607;

BB0_536:
	setp.eq.s32	%p412, %r26, 3;
	@%p412 bra 	BB0_537;
	bra.uni 	BB0_607;

BB0_537:
	shr.u32 	%r8729, %r19, 24;
	and.b32  	%r3710, %r19, 16777215;
	prmt.b32 	%r19, %r8720, %r3710, 1620;
	bra.uni 	BB0_607;

BB0_567:
	setp.eq.s32	%p389, %r26, 19;
	@%p389 bra 	BB0_568;
	bra.uni 	BB0_607;

BB0_568:
	shr.u32 	%r8729, %r15, 24;
	and.b32  	%r3686, %r15, 16777215;
	prmt.b32 	%r15, %r8720, %r3686, 1620;
	bra.uni 	BB0_607;

BB0_551:
	setp.eq.s32	%p401, %r26, 11;
	@%p401 bra 	BB0_552;
	bra.uni 	BB0_607;

BB0_552:
	shr.u32 	%r8729, %r21, 24;
	and.b32  	%r3698, %r21, 16777215;
	prmt.b32 	%r21, %r8720, %r3698, 1620;
	bra.uni 	BB0_607;

BB0_582:
	setp.eq.s32	%p378, %r26, 27;
	@%p378 bra 	BB0_583;
	bra.uni 	BB0_607;

BB0_583:
	shr.u32 	%r8729, %r17, 24;
	and.b32  	%r3674, %r17, 16777215;
	prmt.b32 	%r17, %r8720, %r3674, 1620;
	bra.uni 	BB0_607;

BB0_543:
	setp.eq.s32	%p407, %r26, 7;
	@%p407 bra 	BB0_544;
	bra.uni 	BB0_607;

BB0_544:
	shr.u32 	%r8729, %r20, 24;
	and.b32  	%r3704, %r20, 16777215;
	prmt.b32 	%r20, %r8720, %r3704, 1620;
	bra.uni 	BB0_607;

BB0_574:
	setp.eq.s32	%p384, %r26, 23;
	@%p384 bra 	BB0_575;
	bra.uni 	BB0_607;

BB0_575:
	shr.u32 	%r8729, %r16, 24;
	and.b32  	%r3680, %r16, 16777215;
	prmt.b32 	%r16, %r8720, %r3680, 1620;
	bra.uni 	BB0_607;

BB0_558:
	setp.eq.s32	%p396, %r26, 15;
	@%p396 bra 	BB0_559;
	bra.uni 	BB0_607;

BB0_559:
	shr.u32 	%r8729, %r22, 24;
	and.b32  	%r3692, %r22, 16777215;
	prmt.b32 	%r22, %r8720, %r3692, 1620;
	bra.uni 	BB0_607;

BB0_589:
	setp.ne.s32	%p373, %r26, 31;
	@%p373 bra 	BB0_607;

	shr.u32 	%r8729, %r18, 24;
	and.b32  	%r3668, %r18, 16777215;
	prmt.b32 	%r18, %r8720, %r3668, 1620;

BB0_607:
	@%p321 bra 	BB0_649;

	setp.gt.s32	%p439, %r24, 7;
	@%p439 bra 	BB0_626;

	setp.gt.s32	%p451, %r24, 3;
	@%p451 bra 	BB0_618;

	setp.gt.s32	%p457, %r24, 1;
	@%p457 bra 	BB0_614;

	setp.eq.s32	%p460, %r24, 0;
	@%p460 bra 	BB0_699;
	bra.uni 	BB0_612;

BB0_699:
	and.b32  	%r3763, %r19, -256;
	or.b32  	%r8848, %r8729, %r3763;
	bra.uni 	BB0_617;

BB0_649:
	setp.gt.s32	%p416, %r24, 23;
	@%p416 bra 	BB0_667;

	setp.gt.s32	%p428, %r24, 19;
	@%p428 bra 	BB0_659;

	setp.gt.s32	%p434, %r24, 17;
	@%p434 bra 	BB0_655;

	setp.eq.s32	%p437, %r24, 16;
	@%p437 bra 	BB0_691;
	bra.uni 	BB0_653;

BB0_691:
	and.b32  	%r3739, %r15, -256;
	or.b32  	%r8852, %r3739, %r8729;
	bra.uni 	BB0_658;

BB0_626:
	setp.gt.s32	%p440, %r24, 11;
	@%p440 bra 	BB0_635;

	setp.gt.s32	%p446, %r24, 9;
	@%p446 bra 	BB0_631;

	setp.eq.s32	%p449, %r24, 8;
	@%p449 bra 	BB0_695;
	bra.uni 	BB0_629;

BB0_695:
	and.b32  	%r3751, %r21, -256;
	or.b32  	%r8846, %r8729, %r3751;
	bra.uni 	BB0_634;

BB0_667:
	setp.gt.s32	%p417, %r24, 27;
	@%p417 bra 	BB0_676;

	setp.gt.s32	%p423, %r24, 25;
	@%p423 bra 	BB0_672;

	setp.eq.s32	%p426, %r24, 24;
	@%p426 bra 	BB0_687;
	bra.uni 	BB0_670;

BB0_687:
	and.b32  	%r3727, %r17, -256;
	or.b32  	%r8850, %r8729, %r3727;
	bra.uni 	BB0_675;

BB0_618:
	setp.gt.s32	%p452, %r24, 5;
	@%p452 bra 	BB0_622;

	setp.eq.s32	%p455, %r24, 4;
	@%p455 bra 	BB0_697;
	bra.uni 	BB0_620;

BB0_697:
	and.b32  	%r3757, %r20, -256;
	or.b32  	%r8847, %r8729, %r3757;
	bra.uni 	BB0_625;

BB0_659:
	setp.gt.s32	%p429, %r24, 21;
	@%p429 bra 	BB0_663;

	setp.eq.s32	%p432, %r24, 20;
	@%p432 bra 	BB0_689;
	bra.uni 	BB0_661;

BB0_689:
	and.b32  	%r3733, %r16, -256;
	or.b32  	%r8851, %r8729, %r3733;
	bra.uni 	BB0_666;

BB0_635:
	setp.gt.s32	%p441, %r24, 13;
	@%p441 bra 	BB0_639;

	setp.eq.s32	%p444, %r24, 12;
	@%p444 bra 	BB0_693;
	bra.uni 	BB0_637;

BB0_693:
	and.b32  	%r3745, %r22, -256;
	or.b32  	%r8845, %r8729, %r3745;
	bra.uni 	BB0_642;

BB0_676:
	setp.gt.s32	%p418, %r24, 29;
	@%p418 bra 	BB0_680;

	setp.eq.s32	%p421, %r24, 28;
	@%p421 bra 	BB0_685;
	bra.uni 	BB0_678;

BB0_685:
	and.b32  	%r3721, %r18, -256;
	or.b32  	%r8849, %r8729, %r3721;
	bra.uni 	BB0_683;

BB0_614:
	setp.eq.s32	%p458, %r24, 2;
	@%p458 bra 	BB0_698;
	bra.uni 	BB0_615;

BB0_698:
	and.b32  	%r3759, %r19, -16711681;
	shl.b32 	%r3760, %r8729, 16;
	or.b32  	%r8848, %r3760, %r3759;
	bra.uni 	BB0_617;

BB0_655:
	setp.eq.s32	%p435, %r24, 18;
	@%p435 bra 	BB0_690;
	bra.uni 	BB0_656;

BB0_690:
	and.b32  	%r3735, %r15, -16711681;
	shl.b32 	%r3736, %r8729, 16;
	or.b32  	%r8852, %r3736, %r3735;
	bra.uni 	BB0_658;

BB0_631:
	setp.eq.s32	%p447, %r24, 10;
	@%p447 bra 	BB0_694;
	bra.uni 	BB0_632;

BB0_694:
	and.b32  	%r3747, %r21, -16711681;
	shl.b32 	%r3748, %r8729, 16;
	or.b32  	%r8846, %r3748, %r3747;
	bra.uni 	BB0_634;

BB0_672:
	setp.eq.s32	%p424, %r24, 26;
	@%p424 bra 	BB0_686;
	bra.uni 	BB0_673;

BB0_686:
	and.b32  	%r3723, %r17, -16711681;
	shl.b32 	%r3724, %r8729, 16;
	or.b32  	%r8850, %r3724, %r3723;
	bra.uni 	BB0_675;

BB0_622:
	setp.eq.s32	%p453, %r24, 6;
	@%p453 bra 	BB0_696;
	bra.uni 	BB0_623;

BB0_696:
	and.b32  	%r3753, %r20, -16711681;
	shl.b32 	%r3754, %r8729, 16;
	or.b32  	%r8847, %r3754, %r3753;
	bra.uni 	BB0_625;

BB0_663:
	setp.eq.s32	%p430, %r24, 22;
	@%p430 bra 	BB0_688;
	bra.uni 	BB0_664;

BB0_688:
	and.b32  	%r3729, %r16, -16711681;
	shl.b32 	%r3730, %r8729, 16;
	or.b32  	%r8851, %r3730, %r3729;
	bra.uni 	BB0_666;

BB0_639:
	setp.eq.s32	%p442, %r24, 14;
	@%p442 bra 	BB0_692;
	bra.uni 	BB0_640;

BB0_692:
	and.b32  	%r3741, %r22, -16711681;
	shl.b32 	%r3742, %r8729, 16;
	or.b32  	%r8845, %r3742, %r3741;
	bra.uni 	BB0_642;

BB0_680:
	setp.eq.s32	%p419, %r24, 30;
	@%p419 bra 	BB0_684;
	bra.uni 	BB0_681;

BB0_684:
	and.b32  	%r3717, %r18, -16711681;
	shl.b32 	%r3718, %r8729, 16;
	or.b32  	%r8849, %r3718, %r3717;
	bra.uni 	BB0_683;

BB0_907:
	setp.eq.s32	%p602, %r24, 17;
	@%p602 bra 	BB0_908;
	bra.uni 	BB0_771;

BB0_908:
	mov.u32 	%r4649, 64;
	prmt.b32 	%r4650, %r19, %r19, %r4649;
	mov.u32 	%r4651, 1040;
	prmt.b32 	%r4652, %r4650, %r19, %r4651;
	mov.u32 	%r4653, 16912;
	prmt.b32 	%r4654, %r4652, %r19, %r4653;
	or.b32  	%r8848, %r4654, %r8848;
	or.b32  	%r8847, %r4654, %r8847;
	or.b32  	%r8846, %r4654, %r8846;
	or.b32  	%r8845, %r4654, %r8845;
	or.b32  	%r8852, %r15, %r610;
	bra.uni 	BB0_765;

BB0_891:
	setp.eq.s32	%p614, %r24, 9;
	@%p614 bra 	BB0_892;
	bra.uni 	BB0_771;

BB0_892:
	mov.u32 	%r4709, 64;
	prmt.b32 	%r4710, %r19, %r19, %r4709;
	mov.u32 	%r4711, 1040;
	prmt.b32 	%r4712, %r4710, %r19, %r4711;
	mov.u32 	%r4713, 16912;
	prmt.b32 	%r4714, %r4712, %r19, %r4713;
	or.b32  	%r8848, %r4714, %r8848;
	or.b32  	%r8847, %r4714, %r8847;
	or.b32  	%r8846, %r8846, %r610;
	bra.uni 	BB0_771;

BB0_922:
	setp.eq.s32	%p591, %r24, 25;
	@%p591 bra 	BB0_937;
	bra.uni 	BB0_923;

BB0_937:
	mov.u32 	%r4589, 64;
	prmt.b32 	%r4590, %r19, %r19, %r4589;
	mov.u32 	%r4591, 1040;
	prmt.b32 	%r4592, %r4590, %r19, %r4591;
	mov.u32 	%r4593, 16912;
	prmt.b32 	%r4594, %r4592, %r19, %r4593;
	or.b32  	%r8848, %r4594, %r8848;
	or.b32  	%r8847, %r4594, %r8847;
	or.b32  	%r8846, %r4594, %r8846;
	or.b32  	%r8845, %r4594, %r8845;
	or.b32  	%r8852, %r4594, %r15;
	or.b32  	%r8851, %r4594, %r16;
	or.b32  	%r8850, %r17, %r610;
	mov.u32 	%r8849, %r18;
	bra.uni 	BB0_1554;

BB0_883:
	setp.eq.s32	%p620, %r24, 5;
	@%p620 bra 	BB0_884;
	bra.uni 	BB0_771;

BB0_884:
	mov.u32 	%r4739, 64;
	prmt.b32 	%r4740, %r19, %r19, %r4739;
	mov.u32 	%r4741, 1040;
	prmt.b32 	%r4742, %r4740, %r19, %r4741;
	mov.u32 	%r4743, 16912;
	prmt.b32 	%r4744, %r4742, %r19, %r4743;
	or.b32  	%r8848, %r4744, %r8848;
	or.b32  	%r8847, %r8847, %r610;
	bra.uni 	BB0_771;

BB0_914:
	setp.eq.s32	%p597, %r24, 21;
	@%p597 bra 	BB0_915;
	bra.uni 	BB0_771;

BB0_915:
	mov.u32 	%r4619, 64;
	prmt.b32 	%r4620, %r19, %r19, %r4619;
	mov.u32 	%r4621, 1040;
	prmt.b32 	%r4622, %r4620, %r19, %r4621;
	mov.u32 	%r4623, 16912;
	prmt.b32 	%r4624, %r4622, %r19, %r4623;
	or.b32  	%r8848, %r4624, %r8848;
	or.b32  	%r8847, %r4624, %r8847;
	or.b32  	%r8846, %r4624, %r8846;
	or.b32  	%r8845, %r4624, %r8845;
	or.b32  	%r8852, %r4624, %r15;
	or.b32  	%r8851, %r16, %r610;
	bra.uni 	BB0_734;

BB0_898:
	setp.eq.s32	%p609, %r24, 13;
	@%p609 bra 	BB0_899;
	bra.uni 	BB0_771;

BB0_899:
	mov.u32 	%r4679, 64;
	prmt.b32 	%r4680, %r19, %r19, %r4679;
	mov.u32 	%r4681, 1040;
	prmt.b32 	%r4682, %r4680, %r19, %r4681;
	mov.u32 	%r4683, 16912;
	prmt.b32 	%r4684, %r4682, %r19, %r4683;
	or.b32  	%r8848, %r4684, %r8848;
	or.b32  	%r8847, %r4684, %r8847;
	or.b32  	%r8846, %r4684, %r8846;
	or.b32  	%r8845, %r8845, %r610;
	bra.uni 	BB0_771;

BB0_929:
	setp.eq.s32	%p586, %r24, 29;
	@%p586 bra 	BB0_930;
	bra.uni 	BB0_923;

BB0_930:
	mov.u32 	%r4559, 64;
	prmt.b32 	%r4560, %r19, %r19, %r4559;
	mov.u32 	%r4561, 1040;
	prmt.b32 	%r4562, %r4560, %r19, %r4561;
	mov.u32 	%r4563, 16912;
	prmt.b32 	%r4564, %r4562, %r19, %r4563;
	or.b32  	%r8848, %r4564, %r8848;
	or.b32  	%r8847, %r4564, %r8847;
	or.b32  	%r8846, %r4564, %r8846;
	or.b32  	%r8845, %r4564, %r8845;
	or.b32  	%r8852, %r4564, %r15;
	or.b32  	%r8851, %r4564, %r16;
	or.b32  	%r8850, %r4564, %r17;
	or.b32  	%r8849, %r18, %r610;
	bra.uni 	BB0_1554;

BB0_910:
	setp.eq.s32	%p600, %r24, 19;
	@%p600 bra 	BB0_911;
	bra.uni 	BB0_771;

BB0_911:
	mov.u32 	%r4631, 64;
	prmt.b32 	%r4632, %r19, %r19, %r4631;
	mov.u32 	%r4633, 1040;
	prmt.b32 	%r4634, %r4632, %r19, %r4633;
	mov.u32 	%r4635, 16912;
	prmt.b32 	%r4636, %r4634, %r19, %r4635;
	or.b32  	%r8848, %r4636, %r8848;
	or.b32  	%r8847, %r4636, %r8847;
	or.b32  	%r8846, %r4636, %r8846;
	or.b32  	%r8845, %r4636, %r8845;
	shl.b32 	%r4637, %r610, 8;
	or.b32  	%r4638, %r4637, %r610;
	shl.b32 	%r4639, %r610, 16;
	or.b32  	%r4640, %r4638, %r4639;
	or.b32  	%r8852, %r4640, %r15;

BB0_765:
	mov.u32 	%r8849, %r18;
	mov.u32 	%r8850, %r17;
	mov.u32 	%r8851, %r16;
	bra.uni 	BB0_1554;

BB0_894:
	setp.eq.s32	%p612, %r24, 11;
	@%p612 bra 	BB0_895;
	bra.uni 	BB0_771;

BB0_895:
	mov.u32 	%r4691, 64;
	prmt.b32 	%r4692, %r19, %r19, %r4691;
	mov.u32 	%r4693, 1040;
	prmt.b32 	%r4694, %r4692, %r19, %r4693;
	mov.u32 	%r4695, 16912;
	prmt.b32 	%r4696, %r4694, %r19, %r4695;
	or.b32  	%r8848, %r4696, %r8848;
	or.b32  	%r8847, %r4696, %r8847;
	shl.b32 	%r4697, %r610, 8;
	or.b32  	%r4698, %r4697, %r610;
	shl.b32 	%r4699, %r610, 16;
	or.b32  	%r4700, %r4698, %r4699;
	or.b32  	%r8846, %r4700, %r8846;
	bra.uni 	BB0_771;

BB0_925:
	setp.eq.s32	%p589, %r24, 27;
	@%p589 bra 	BB0_926;
	bra.uni 	BB0_923;

BB0_926:
	mov.u32 	%r4571, 64;
	prmt.b32 	%r4572, %r19, %r19, %r4571;
	mov.u32 	%r4573, 1040;
	prmt.b32 	%r4574, %r4572, %r19, %r4573;
	mov.u32 	%r4575, 16912;
	prmt.b32 	%r4576, %r4574, %r19, %r4575;
	or.b32  	%r8848, %r4576, %r8848;
	or.b32  	%r8847, %r4576, %r8847;
	or.b32  	%r8846, %r4576, %r8846;
	or.b32  	%r8845, %r4576, %r8845;
	or.b32  	%r8852, %r4576, %r15;
	or.b32  	%r8851, %r4576, %r16;
	shl.b32 	%r4577, %r610, 8;
	or.b32  	%r4578, %r4577, %r610;
	shl.b32 	%r4579, %r610, 16;
	or.b32  	%r4580, %r4578, %r4579;
	or.b32  	%r8850, %r4580, %r17;
	mov.u32 	%r8849, %r18;
	bra.uni 	BB0_1554;

BB0_886:
	setp.eq.s32	%p618, %r24, 7;
	@%p618 bra 	BB0_887;
	bra.uni 	BB0_771;

BB0_887:
	mov.u32 	%r4721, 64;
	prmt.b32 	%r4722, %r19, %r19, %r4721;
	mov.u32 	%r4723, 1040;
	prmt.b32 	%r4724, %r4722, %r19, %r4723;
	mov.u32 	%r4725, 16912;
	prmt.b32 	%r4726, %r4724, %r19, %r4725;
	or.b32  	%r8848, %r4726, %r8848;
	shl.b32 	%r4727, %r610, 8;
	or.b32  	%r4728, %r4727, %r610;
	shl.b32 	%r4729, %r610, 16;
	or.b32  	%r4730, %r4728, %r4729;
	or.b32  	%r8847, %r4730, %r8847;
	bra.uni 	BB0_771;

BB0_917:
	setp.eq.s32	%p595, %r24, 23;
	@%p595 bra 	BB0_918;
	bra.uni 	BB0_771;

BB0_918:
	mov.u32 	%r4601, 64;
	prmt.b32 	%r4602, %r19, %r19, %r4601;
	mov.u32 	%r4603, 1040;
	prmt.b32 	%r4604, %r4602, %r19, %r4603;
	mov.u32 	%r4605, 16912;
	prmt.b32 	%r4606, %r4604, %r19, %r4605;
	or.b32  	%r8848, %r4606, %r8848;
	or.b32  	%r8847, %r4606, %r8847;
	or.b32  	%r8846, %r4606, %r8846;
	or.b32  	%r8845, %r4606, %r8845;
	or.b32  	%r8852, %r4606, %r15;
	shl.b32 	%r4607, %r610, 8;
	or.b32  	%r4608, %r4607, %r610;
	shl.b32 	%r4609, %r610, 16;
	or.b32  	%r4610, %r4608, %r4609;
	or.b32  	%r8851, %r4610, %r16;
	bra.uni 	BB0_734;

BB0_901:
	setp.eq.s32	%p607, %r24, 15;
	@%p607 bra 	BB0_902;
	bra.uni 	BB0_771;

BB0_902:
	mov.u32 	%r4661, 64;
	prmt.b32 	%r4662, %r19, %r19, %r4661;
	mov.u32 	%r4663, 1040;
	prmt.b32 	%r4664, %r4662, %r19, %r4663;
	mov.u32 	%r4665, 16912;
	prmt.b32 	%r4666, %r4664, %r19, %r4665;
	or.b32  	%r8848, %r4666, %r8848;
	or.b32  	%r8847, %r4666, %r8847;
	or.b32  	%r8846, %r4666, %r8846;
	shl.b32 	%r4667, %r610, 8;
	or.b32  	%r4668, %r4667, %r610;
	shl.b32 	%r4669, %r610, 16;
	or.b32  	%r4670, %r4668, %r4669;
	or.b32  	%r8845, %r4670, %r8845;
	bra.uni 	BB0_771;

BB0_932:
	setp.ne.s32	%p584, %r24, 31;
	@%p584 bra 	BB0_923;

	mov.u32 	%r4541, 64;
	prmt.b32 	%r4542, %r19, %r19, %r4541;
	mov.u32 	%r4543, 1040;
	prmt.b32 	%r4544, %r4542, %r19, %r4543;
	mov.u32 	%r4545, 16912;
	prmt.b32 	%r4546, %r4544, %r19, %r4545;
	or.b32  	%r8848, %r4546, %r8848;
	or.b32  	%r8847, %r4546, %r8847;
	or.b32  	%r8846, %r4546, %r8846;
	or.b32  	%r8845, %r4546, %r8845;
	or.b32  	%r8852, %r4546, %r15;
	or.b32  	%r8851, %r4546, %r16;
	or.b32  	%r8850, %r4546, %r17;
	shl.b32 	%r4547, %r610, 8;
	or.b32  	%r4548, %r4547, %r610;
	shl.b32 	%r4549, %r610, 16;
	or.b32  	%r4550, %r4548, %r4549;
	or.b32  	%r8849, %r4550, %r18;
	bra.uni 	BB0_1554;

BB0_923:
	mov.u32 	%r8849, %r18;
	bra.uni 	BB0_772;

BB0_612:
	setp.eq.s32	%p461, %r24, 1;
	@%p461 bra 	BB0_613;
	bra.uni 	BB0_11;

BB0_613:
	and.b32  	%r3761, %r19, -65281;
	shl.b32 	%r3762, %r8729, 8;
	or.b32  	%r8848, %r3762, %r3761;
	bra.uni 	BB0_617;

BB0_653:
	setp.eq.s32	%p438, %r24, 17;
	@%p438 bra 	BB0_654;
	bra.uni 	BB0_11;

BB0_654:
	and.b32  	%r3737, %r15, -65281;
	shl.b32 	%r3738, %r8729, 8;
	or.b32  	%r8852, %r3738, %r3737;
	bra.uni 	BB0_658;

BB0_629:
	setp.eq.s32	%p450, %r24, 9;
	@%p450 bra 	BB0_630;
	bra.uni 	BB0_11;

BB0_630:
	and.b32  	%r3749, %r21, -65281;
	shl.b32 	%r3750, %r8729, 8;
	or.b32  	%r8846, %r3750, %r3749;
	bra.uni 	BB0_634;

BB0_670:
	setp.eq.s32	%p427, %r24, 25;
	@%p427 bra 	BB0_671;
	bra.uni 	BB0_11;

BB0_671:
	and.b32  	%r3725, %r17, -65281;
	shl.b32 	%r3726, %r8729, 8;
	or.b32  	%r8850, %r3726, %r3725;
	bra.uni 	BB0_675;

BB0_620:
	setp.eq.s32	%p456, %r24, 5;
	@%p456 bra 	BB0_621;
	bra.uni 	BB0_11;

BB0_621:
	and.b32  	%r3755, %r20, -65281;
	shl.b32 	%r3756, %r8729, 8;
	or.b32  	%r8847, %r3756, %r3755;
	bra.uni 	BB0_625;

BB0_661:
	setp.eq.s32	%p433, %r24, 21;
	@%p433 bra 	BB0_662;
	bra.uni 	BB0_11;

BB0_662:
	and.b32  	%r3731, %r16, -65281;
	shl.b32 	%r3732, %r8729, 8;
	or.b32  	%r8851, %r3732, %r3731;
	bra.uni 	BB0_666;

BB0_637:
	setp.eq.s32	%p445, %r24, 13;
	@%p445 bra 	BB0_638;
	bra.uni 	BB0_11;

BB0_638:
	and.b32  	%r3743, %r22, -65281;
	shl.b32 	%r3744, %r8729, 8;
	or.b32  	%r8845, %r3744, %r3743;
	bra.uni 	BB0_642;

BB0_678:
	setp.eq.s32	%p422, %r24, 29;
	@%p422 bra 	BB0_679;
	bra.uni 	BB0_11;

BB0_679:
	and.b32  	%r3719, %r18, -65281;
	shl.b32 	%r3720, %r8729, 8;
	or.b32  	%r8849, %r3720, %r3719;
	bra.uni 	BB0_683;

BB0_615:
	setp.eq.s32	%p459, %r24, 3;
	@%p459 bra 	BB0_616;
	bra.uni 	BB0_11;

BB0_616:
	and.b32  	%r3758, %r19, 16777215;
	prmt.b32 	%r8848, %r8729, %r3758, 1620;
	bra.uni 	BB0_617;

BB0_656:
	setp.eq.s32	%p436, %r24, 19;
	@%p436 bra 	BB0_657;
	bra.uni 	BB0_11;

BB0_657:
	and.b32  	%r3734, %r15, 16777215;
	prmt.b32 	%r8852, %r8729, %r3734, 1620;

BB0_658:
	mov.u32 	%r8845, %r22;
	mov.u32 	%r8846, %r21;
	mov.u32 	%r8847, %r20;
	mov.u32 	%r8848, %r19;
	mov.u32 	%r8849, %r18;
	mov.u32 	%r8850, %r17;
	mov.u32 	%r8851, %r16;
	bra.uni 	BB0_1553;

BB0_632:
	setp.eq.s32	%p448, %r24, 11;
	@%p448 bra 	BB0_633;
	bra.uni 	BB0_11;

BB0_633:
	and.b32  	%r3746, %r21, 16777215;
	prmt.b32 	%r8846, %r8729, %r3746, 1620;

BB0_634:
	mov.u32 	%r8845, %r22;
	bra.uni 	BB0_643;

BB0_673:
	setp.eq.s32	%p425, %r24, 27;
	@%p425 bra 	BB0_674;
	bra.uni 	BB0_11;

BB0_674:
	and.b32  	%r3722, %r17, 16777215;
	prmt.b32 	%r8850, %r8729, %r3722, 1620;

BB0_675:
	mov.u32 	%r8845, %r22;
	mov.u32 	%r8846, %r21;
	mov.u32 	%r8847, %r20;
	mov.u32 	%r8848, %r19;
	mov.u32 	%r8849, %r18;
	bra.uni 	BB0_647;

BB0_623:
	setp.eq.s32	%p454, %r24, 7;
	@%p454 bra 	BB0_624;
	bra.uni 	BB0_11;

BB0_624:
	and.b32  	%r3752, %r20, 16777215;
	prmt.b32 	%r8847, %r8729, %r3752, 1620;

BB0_625:
	mov.u32 	%r8845, %r22;
	mov.u32 	%r8846, %r21;
	bra.uni 	BB0_644;

BB0_664:
	setp.eq.s32	%p431, %r24, 23;
	@%p431 bra 	BB0_665;
	bra.uni 	BB0_11;

BB0_665:
	and.b32  	%r3728, %r16, 16777215;
	prmt.b32 	%r8851, %r8729, %r3728, 1620;

BB0_666:
	mov.u32 	%r8845, %r22;
	mov.u32 	%r8846, %r21;
	mov.u32 	%r8847, %r20;
	mov.u32 	%r8848, %r19;
	mov.u32 	%r8849, %r18;
	mov.u32 	%r8850, %r17;
	bra.uni 	BB0_648;

BB0_640:
	setp.eq.s32	%p443, %r24, 15;
	@%p443 bra 	BB0_641;
	bra.uni 	BB0_11;

BB0_641:
	and.b32  	%r3740, %r22, 16777215;
	prmt.b32 	%r8845, %r8729, %r3740, 1620;
	bra.uni 	BB0_642;

BB0_681:
	setp.ne.s32	%p420, %r24, 31;
	@%p420 bra 	BB0_11;

	and.b32  	%r3716, %r18, 16777215;
	prmt.b32 	%r8849, %r8729, %r3716, 1620;

BB0_683:
	mov.u32 	%r8845, %r22;
	mov.u32 	%r8846, %r21;
	mov.u32 	%r8847, %r20;
	mov.u32 	%r8848, %r19;
	bra.uni 	BB0_646;

BB0_135:
	setp.eq.s32	%p173, %r24, 1;
	mov.u32 	%r8688, %r8691;
	mov.u32 	%r8689, %r8691;
	mov.u32 	%r8690, %r8691;
	mov.u32 	%r8692, %r8691;
	mov.u32 	%r8693, %r8691;
	mov.u32 	%r8694, %r8691;
	mov.u32 	%r8695, %r8691;
	@%p173 bra 	BB0_136;
	bra.uni 	BB0_215;

BB0_136:
	mov.u32 	%r2807, 24;
	// inline asm
	shf.r.wrap.b32 %r8692, %r17, %r18, %r2807;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8693, %r16, %r17, %r2807;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8694, %r15, %r16, %r2807;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8695, %r22, %r15, %r2807;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8688, %r21, %r22, %r2807;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8689, %r20, %r21, %r2807;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8690, %r19, %r20, %r2807;
	// inline asm
	mov.u32 	%r2805, 0;
	// inline asm
	shf.r.wrap.b32 %r8691, %r2805, %r19, %r2807;
	// inline asm
	bra.uni 	BB0_215;

BB0_167:
	setp.eq.s32	%p150, %r24, 17;
	mov.u32 	%r8688, %r8691;
	mov.u32 	%r8689, %r8691;
	mov.u32 	%r8690, %r8691;
	mov.u32 	%r8692, %r8691;
	mov.u32 	%r8693, %r8691;
	mov.u32 	%r8694, %r8691;
	mov.u32 	%r8695, %r8691;
	@%p150 bra 	BB0_168;
	bra.uni 	BB0_215;

BB0_168:
	mov.u32 	%r2463, 24;
	// inline asm
	shf.r.wrap.b32 %r8692, %r21, %r22, %r2463;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8693, %r20, %r21, %r2463;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8694, %r19, %r20, %r2463;
	// inline asm
	mov.u32 	%r8688, 0;
	// inline asm
	shf.r.wrap.b32 %r8695, %r8688, %r19, %r2463;
	// inline asm
	bra.uni 	BB0_172;

BB0_712:
	setp.eq.s32	%p496, %r14, 10;
	@%p496 bra 	BB0_713;
	bra.uni 	BB0_11;

BB0_713:
	shl.b32 	%r3877, %r21, 8;
	and.b32  	%r3878, %r3877, 65280;
	bfe.u32 	%r3879, %r21, 8, 8;
	or.b32  	%r8846, %r3878, %r3879;
	mov.u32 	%r8853, 10;
	bra.uni 	BB0_776;

BB0_150:
	setp.eq.s32	%p162, %r24, 9;
	mov.u32 	%r8688, %r8691;
	mov.u32 	%r8689, %r8691;
	mov.u32 	%r8690, %r8691;
	mov.u32 	%r8692, %r8691;
	mov.u32 	%r8693, %r8691;
	mov.u32 	%r8694, %r8691;
	mov.u32 	%r8695, %r8691;
	@%p162 bra 	BB0_151;
	bra.uni 	BB0_215;

BB0_151:
	mov.u32 	%r2619, 24;
	// inline asm
	shf.r.wrap.b32 %r8692, %r15, %r16, %r2619;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8693, %r22, %r15, %r2619;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8694, %r21, %r22, %r2619;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8695, %r20, %r21, %r2619;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8688, %r19, %r20, %r2619;
	// inline asm
	mov.u32 	%r8690, 0;
	// inline asm
	shf.r.wrap.b32 %r8689, %r8690, %r19, %r2619;
	// inline asm
	mov.u32 	%r8691, %r8690;
	bra.uni 	BB0_215;

BB0_741:
	setp.eq.s32	%p475, %r14, 25;
	@%p475 bra 	BB0_742;
	bra.uni 	BB0_11;

BB0_742:
	or.b32  	%r3797, %r16, %r17;
	and.b32  	%r3798, %r16, 16777215;
	prmt.b32 	%r8851, %r17, %r3798, 1620;
	shr.u32 	%r8850, %r3797, 24;
	mov.u32 	%r8853, 25;
	mov.u32 	%r8845, %r22;
	mov.u32 	%r8846, %r21;
	mov.u32 	%r8847, %r20;
	mov.u32 	%r8848, %r19;
	mov.u32 	%r8849, %r18;
	mov.u32 	%r8852, %r15;
	bra.uni 	BB0_1554;

BB0_184:
	setp.eq.s32	%p139, %r24, 25;
	mov.u32 	%r8688, %r8691;
	mov.u32 	%r8689, %r8691;
	mov.u32 	%r8690, %r8691;
	mov.u32 	%r8692, %r8691;
	mov.u32 	%r8693, %r8691;
	mov.u32 	%r8694, %r8691;
	mov.u32 	%r8695, %r8691;
	@%p139 bra 	BB0_185;
	bra.uni 	BB0_215;

BB0_185:
	mov.u32 	%r2339, 24;
	// inline asm
	shf.r.wrap.b32 %r8692, %r19, %r20, %r2339;
	// inline asm
	mov.u32 	%r8688, 0;
	// inline asm
	shf.r.wrap.b32 %r8693, %r8688, %r19, %r2339;
	// inline asm
	bra.uni 	BB0_189;

BB0_704:
	setp.eq.s32	%p502, %r14, 6;
	@%p502 bra 	BB0_705;
	bra.uni 	BB0_11;

BB0_705:
	shl.b32 	%r3898, %r20, 8;
	and.b32  	%r3899, %r3898, 65280;
	bfe.u32 	%r3900, %r20, 8, 8;
	or.b32  	%r8847, %r3899, %r3900;
	mov.u32 	%r8853, 6;
	bra.uni 	BB0_779;

BB0_142:
	setp.eq.s32	%p168, %r24, 5;
	mov.u32 	%r8688, %r8691;
	mov.u32 	%r8689, %r8691;
	mov.u32 	%r8690, %r8691;
	mov.u32 	%r8692, %r8691;
	mov.u32 	%r8693, %r8691;
	mov.u32 	%r8694, %r8691;
	mov.u32 	%r8695, %r8691;
	@%p168 bra 	BB0_143;
	bra.uni 	BB0_215;

BB0_143:
	mov.u32 	%r2709, 24;
	// inline asm
	shf.r.wrap.b32 %r8692, %r16, %r17, %r2709;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8693, %r15, %r16, %r2709;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8694, %r22, %r15, %r2709;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8695, %r21, %r22, %r2709;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8688, %r20, %r21, %r2709;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8689, %r19, %r20, %r2709;
	// inline asm
	mov.u32 	%r8691, 0;
	// inline asm
	shf.r.wrap.b32 %r8690, %r8691, %r19, %r2709;
	// inline asm
	bra.uni 	BB0_215;

BB0_732:
	setp.eq.s32	%p481, %r14, 21;
	@%p481 bra 	BB0_733;
	bra.uni 	BB0_11;

BB0_733:
	or.b32  	%r3818, %r15, %r16;
	and.b32  	%r3819, %r15, 16777215;
	prmt.b32 	%r8852, %r16, %r3819, 1620;
	shr.u32 	%r8851, %r3818, 24;
	mov.u32 	%r8853, 21;
	mov.u32 	%r8845, %r22;
	mov.u32 	%r8846, %r21;
	mov.u32 	%r8847, %r20;
	mov.u32 	%r8848, %r19;

BB0_734:
	mov.u32 	%r8849, %r18;
	mov.u32 	%r8850, %r17;
	bra.uni 	BB0_1554;

BB0_175:
	setp.eq.s32	%p145, %r24, 21;
	mov.u32 	%r8688, %r8691;
	mov.u32 	%r8689, %r8691;
	mov.u32 	%r8690, %r8691;
	mov.u32 	%r8692, %r8691;
	mov.u32 	%r8693, %r8691;
	mov.u32 	%r8694, %r8691;
	mov.u32 	%r8695, %r8691;
	@%p145 bra 	BB0_176;
	bra.uni 	BB0_215;

BB0_176:
	mov.u32 	%r2397, 24;
	// inline asm
	shf.r.wrap.b32 %r8692, %r20, %r21, %r2397;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8693, %r19, %r20, %r2397;
	// inline asm
	mov.u32 	%r8688, 0;
	// inline asm
	shf.r.wrap.b32 %r8694, %r8688, %r19, %r2397;
	// inline asm
	bra.uni 	BB0_180;

BB0_719:
	setp.eq.s32	%p491, %r14, 14;
	@%p491 bra 	BB0_720;
	bra.uni 	BB0_11;

BB0_720:
	shl.b32 	%r3856, %r22, 8;
	and.b32  	%r3857, %r3856, 65280;
	bfe.u32 	%r3858, %r22, 8, 8;
	or.b32  	%r8845, %r3857, %r3858;
	mov.u32 	%r8853, 14;
	bra.uni 	BB0_768;

BB0_157:
	setp.eq.s32	%p157, %r24, 13;
	mov.u32 	%r8688, %r8691;
	mov.u32 	%r8689, %r8691;
	mov.u32 	%r8690, %r8691;
	mov.u32 	%r8692, %r8691;
	mov.u32 	%r8693, %r8691;
	mov.u32 	%r8694, %r8691;
	mov.u32 	%r8695, %r8691;
	@%p157 bra 	BB0_158;
	bra.uni 	BB0_215;

BB0_158:
	mov.u32 	%r2537, 24;
	// inline asm
	shf.r.wrap.b32 %r8692, %r22, %r15, %r2537;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8693, %r21, %r22, %r2537;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8694, %r20, %r21, %r2537;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8695, %r19, %r20, %r2537;
	// inline asm
	mov.u32 	%r8689, 0;
	// inline asm
	shf.r.wrap.b32 %r8688, %r8689, %r19, %r2537;
	// inline asm
	bra.uni 	BB0_162;

BB0_748:
	setp.eq.s32	%p470, %r14, 29;
	@%p470 bra 	BB0_749;
	bra.uni 	BB0_11;

BB0_749:
	or.b32  	%r3776, %r17, %r18;
	and.b32  	%r3777, %r17, 16777215;
	prmt.b32 	%r8850, %r18, %r3777, 1620;
	shr.u32 	%r8849, %r3776, 24;
	mov.u32 	%r8853, 29;
	mov.u32 	%r8845, %r22;
	mov.u32 	%r8846, %r21;
	mov.u32 	%r8847, %r20;
	mov.u32 	%r8848, %r19;
	bra.uni 	BB0_773;

BB0_193:
	setp.eq.s32	%p134, %r24, 29;
	mov.u32 	%r8688, %r8691;
	mov.u32 	%r8689, %r8691;
	mov.u32 	%r8690, %r8691;
	mov.u32 	%r8692, %r8691;
	mov.u32 	%r8693, %r8691;
	mov.u32 	%r8694, %r8691;
	mov.u32 	%r8695, %r8691;
	@%p134 bra 	BB0_194;
	bra.uni 	BB0_215;

BB0_194:
	mov.u32 	%r8688, 0;
	mov.u32 	%r2289, 24;
	// inline asm
	shf.r.wrap.b32 %r8692, %r8688, %r19, %r2289;
	// inline asm
	bra.uni 	BB0_198;

BB0_287:
	setp.eq.s32	%p222, %r24, 17;
	@%p222 bra 	BB0_288;
	bra.uni 	BB0_291;

BB0_288:
	mov.u32 	%r3061, 24;
	// inline asm
	shf.r.wrap.b32 %r18, %r21, %r22, %r3061;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r17, %r20, %r21, %r3061;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r16, %r19, %r20, %r3061;
	// inline asm
	mov.u32 	%r8712, 0;
	// inline asm
	shf.r.wrap.b32 %r19, %r8712, %r19, %r3061;
	// inline asm
	bra.uni 	BB0_322;

BB0_271:
	setp.eq.s32	%p234, %r24, 9;
	@%p234 bra 	BB0_272;
	bra.uni 	BB0_291;

BB0_272:
	mov.u32 	%r3217, 24;
	// inline asm
	shf.r.wrap.b32 %r18, %r15, %r16, %r3217;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r17, %r22, %r15, %r3217;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r16, %r21, %r22, %r3217;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r3206, %r20, %r21, %r3217;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8712, %r19, %r20, %r3217;
	// inline asm
	mov.u32 	%r8714, 0;
	// inline asm
	shf.r.wrap.b32 %r8713, %r8714, %r19, %r3217;
	// inline asm
	mov.u32 	%r8715, %r8714;
	mov.u32 	%r19, %r3206;
	bra.uni 	BB0_338;

BB0_303:
	setp.eq.s32	%p211, %r24, 25;
	@%p211 bra 	BB0_304;
	bra.uni 	BB0_291;

BB0_304:
	mov.u32 	%r2937, 24;
	// inline asm
	shf.r.wrap.b32 %r18, %r19, %r20, %r2937;
	// inline asm
	mov.u32 	%r8712, 0;
	// inline asm
	shf.r.wrap.b32 %r17, %r8712, %r19, %r2937;
	// inline asm
	bra.uni 	BB0_308;

BB0_263:
	setp.eq.s32	%p240, %r24, 5;
	@%p240 bra 	BB0_264;
	bra.uni 	BB0_291;

BB0_264:
	mov.u32 	%r3307, 24;
	// inline asm
	shf.r.wrap.b32 %r18, %r16, %r17, %r3307;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r17, %r15, %r16, %r3307;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r16, %r22, %r15, %r3307;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r3292, %r21, %r22, %r3307;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8712, %r20, %r21, %r3307;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8713, %r19, %r20, %r3307;
	// inline asm
	mov.u32 	%r8715, 0;
	// inline asm
	shf.r.wrap.b32 %r8714, %r8715, %r19, %r3307;
	// inline asm
	mov.u32 	%r19, %r3292;
	bra.uni 	BB0_338;

BB0_294:
	setp.eq.s32	%p217, %r24, 21;
	@%p217 bra 	BB0_295;
	bra.uni 	BB0_291;

BB0_295:
	mov.u32 	%r2995, 24;
	// inline asm
	shf.r.wrap.b32 %r18, %r20, %r21, %r2995;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r17, %r19, %r20, %r2995;
	// inline asm
	mov.u32 	%r8712, 0;
	// inline asm
	shf.r.wrap.b32 %r16, %r8712, %r19, %r2995;
	// inline asm
	bra.uni 	BB0_299;

BB0_278:
	setp.eq.s32	%p229, %r24, 13;
	@%p229 bra 	BB0_279;
	bra.uni 	BB0_291;

BB0_279:
	mov.u32 	%r3135, 24;
	// inline asm
	shf.r.wrap.b32 %r18, %r22, %r15, %r3135;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r17, %r21, %r22, %r3135;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r16, %r20, %r21, %r3135;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r3128, %r19, %r20, %r3135;
	// inline asm
	mov.u32 	%r8713, 0;
	// inline asm
	shf.r.wrap.b32 %r8712, %r8713, %r19, %r3135;
	// inline asm
	mov.u32 	%r8714, %r8713;
	mov.u32 	%r8715, %r8713;
	mov.u32 	%r19, %r3128;
	bra.uni 	BB0_338;

BB0_311:
	setp.eq.s32	%p206, %r24, 29;
	@%p206 bra 	BB0_312;
	bra.uni 	BB0_291;

BB0_312:
	mov.u32 	%r8712, 0;
	mov.u32 	%r2887, 24;
	// inline asm
	shf.r.wrap.b32 %r18, %r8712, %r19, %r2887;
	// inline asm
	bra.uni 	BB0_334;

BB0_138:
	setp.eq.s32	%p171, %r24, 3;
	mov.u32 	%r8688, %r8691;
	mov.u32 	%r8689, %r8691;
	mov.u32 	%r8690, %r8691;
	mov.u32 	%r8692, %r8691;
	mov.u32 	%r8693, %r8691;
	mov.u32 	%r8694, %r8691;
	mov.u32 	%r8695, %r8691;
	@%p171 bra 	BB0_139;
	bra.uni 	BB0_215;

BB0_139:
	mov.u32 	%r2743, 8;
	// inline asm
	shf.r.wrap.b32 %r8692, %r17, %r18, %r2743;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8693, %r16, %r17, %r2743;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8694, %r15, %r16, %r2743;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8695, %r22, %r15, %r2743;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8688, %r21, %r22, %r2743;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8689, %r20, %r21, %r2743;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8690, %r19, %r20, %r2743;
	// inline asm
	mov.u32 	%r2741, 0;
	// inline asm
	shf.r.wrap.b32 %r8691, %r2741, %r19, %r2743;
	// inline asm
	bra.uni 	BB0_215;

BB0_170:
	setp.eq.s32	%p148, %r24, 19;
	mov.u32 	%r8688, %r8691;
	mov.u32 	%r8689, %r8691;
	mov.u32 	%r8690, %r8691;
	mov.u32 	%r8692, %r8691;
	mov.u32 	%r8693, %r8691;
	mov.u32 	%r8694, %r8691;
	mov.u32 	%r8695, %r8691;
	@%p148 bra 	BB0_171;
	bra.uni 	BB0_215;

BB0_171:
	mov.u32 	%r2423, 8;
	// inline asm
	shf.r.wrap.b32 %r8692, %r21, %r22, %r2423;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8693, %r20, %r21, %r2423;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8694, %r19, %r20, %r2423;
	// inline asm
	mov.u32 	%r8688, 0;
	// inline asm
	shf.r.wrap.b32 %r8695, %r8688, %r19, %r2423;
	// inline asm

BB0_172:
	mov.u32 	%r8689, %r8688;
	mov.u32 	%r8690, %r8688;
	mov.u32 	%r8691, %r8688;
	bra.uni 	BB0_215;

BB0_715:
	setp.eq.s32	%p494, %r14, 12;
	@%p494 bra 	BB0_716;
	bra.uni 	BB0_11;

BB0_716:
	and.b32  	%r3863, %r21, 65535;
	shl.b32 	%r3864, %r21, 8;
	and.b32  	%r3865, %r3864, -16777216;
	or.b32  	%r3866, %r3865, %r3863;
	shr.u32 	%r3867, %r21, 8;
	and.b32  	%r3868, %r3867, 16711680;
	or.b32  	%r8846, %r3866, %r3868;
	mov.u32 	%r8853, 12;

BB0_776:
	mov.u32 	%r8845, %r22;
	bra.uni 	BB0_769;

BB0_153:
	setp.eq.s32	%p160, %r24, 11;
	mov.u32 	%r8688, %r8691;
	mov.u32 	%r8689, %r8691;
	mov.u32 	%r8690, %r8691;
	mov.u32 	%r8692, %r8691;
	mov.u32 	%r8693, %r8691;
	mov.u32 	%r8694, %r8691;
	mov.u32 	%r8695, %r8691;
	@%p160 bra 	BB0_154;
	bra.uni 	BB0_215;

BB0_154:
	mov.u32 	%r2567, 8;
	// inline asm
	shf.r.wrap.b32 %r8692, %r15, %r16, %r2567;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8693, %r22, %r15, %r2567;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8694, %r21, %r22, %r2567;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8695, %r20, %r21, %r2567;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8688, %r19, %r20, %r2567;
	// inline asm
	mov.u32 	%r8690, 0;
	// inline asm
	shf.r.wrap.b32 %r8689, %r8690, %r19, %r2567;
	// inline asm
	mov.u32 	%r8691, %r8690;
	bra.uni 	BB0_215;

BB0_744:
	setp.eq.s32	%p473, %r14, 27;
	@%p473 bra 	BB0_745;
	bra.uni 	BB0_11;

BB0_745:
	and.b32  	%r3786, %r17, 255;
	shl.b32 	%r3787, %r17, 8;
	and.b32  	%r3788, %r3787, 16711680;
	or.b32  	%r3789, %r3788, %r3786;
	shr.u32 	%r3790, %r17, 8;
	and.b32  	%r3791, %r3790, 65280;
	or.b32  	%r8850, %r3789, %r3791;
	mov.u32 	%r8853, 27;

BB0_757:
	mov.u32 	%r8845, %r22;
	mov.u32 	%r8846, %r21;
	mov.u32 	%r8847, %r20;
	mov.u32 	%r8848, %r19;
	mov.u32 	%r8849, %r18;
	bra.uni 	BB0_773;

BB0_187:
	setp.eq.s32	%p137, %r24, 27;
	mov.u32 	%r8688, %r8691;
	mov.u32 	%r8689, %r8691;
	mov.u32 	%r8690, %r8691;
	mov.u32 	%r8692, %r8691;
	mov.u32 	%r8693, %r8691;
	mov.u32 	%r8694, %r8691;
	mov.u32 	%r8695, %r8691;
	@%p137 bra 	BB0_188;
	bra.uni 	BB0_215;

BB0_188:
	mov.u32 	%r2311, 8;
	// inline asm
	shf.r.wrap.b32 %r8692, %r19, %r20, %r2311;
	// inline asm
	mov.u32 	%r8688, 0;
	// inline asm
	shf.r.wrap.b32 %r8693, %r8688, %r19, %r2311;
	// inline asm

BB0_189:
	mov.u32 	%r8689, %r8688;
	mov.u32 	%r8690, %r8688;
	mov.u32 	%r8691, %r8688;
	bra.uni 	BB0_190;

BB0_707:
	setp.eq.s32	%p500, %r14, 8;
	@%p500 bra 	BB0_708;
	bra.uni 	BB0_11;

BB0_708:
	and.b32  	%r3884, %r20, 65535;
	shl.b32 	%r3885, %r20, 8;
	and.b32  	%r3886, %r3885, -16777216;
	or.b32  	%r3887, %r3886, %r3884;
	shr.u32 	%r3888, %r20, 8;
	and.b32  	%r3889, %r3888, 16711680;
	or.b32  	%r8847, %r3887, %r3889;
	mov.u32 	%r8853, 8;

BB0_779:
	mov.u32 	%r8845, %r22;
	mov.u32 	%r8846, %r21;
	bra.uni 	BB0_770;

BB0_145:
	setp.eq.s32	%p166, %r24, 7;
	mov.u32 	%r8688, %r8691;
	mov.u32 	%r8689, %r8691;
	mov.u32 	%r8690, %r8691;
	mov.u32 	%r8692, %r8691;
	mov.u32 	%r8693, %r8691;
	mov.u32 	%r8694, %r8691;
	mov.u32 	%r8695, %r8691;
	@%p166 bra 	BB0_146;
	bra.uni 	BB0_215;

BB0_146:
	mov.u32 	%r2651, 8;
	// inline asm
	shf.r.wrap.b32 %r8692, %r16, %r17, %r2651;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8693, %r15, %r16, %r2651;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8694, %r22, %r15, %r2651;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8695, %r21, %r22, %r2651;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8688, %r20, %r21, %r2651;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8689, %r19, %r20, %r2651;
	// inline asm
	mov.u32 	%r8691, 0;
	// inline asm
	shf.r.wrap.b32 %r8690, %r8691, %r19, %r2651;
	// inline asm
	bra.uni 	BB0_215;

BB0_736:
	setp.eq.s32	%p479, %r14, 23;
	@%p479 bra 	BB0_737;
	bra.uni 	BB0_11;

BB0_737:
	and.b32  	%r3807, %r16, 255;
	shl.b32 	%r3808, %r16, 8;
	and.b32  	%r3809, %r3808, 16711680;
	or.b32  	%r3810, %r3809, %r3807;
	shr.u32 	%r3811, %r16, 8;
	and.b32  	%r3812, %r3811, 65280;
	or.b32  	%r8851, %r3810, %r3812;
	mov.u32 	%r8853, 23;

BB0_760:
	mov.u32 	%r8845, %r22;
	mov.u32 	%r8846, %r21;
	mov.u32 	%r8847, %r20;
	mov.u32 	%r8848, %r19;
	mov.u32 	%r8849, %r18;
	mov.u32 	%r8850, %r17;
	mov.u32 	%r8852, %r15;
	bra.uni 	BB0_1554;

BB0_178:
	setp.eq.s32	%p143, %r24, 23;
	mov.u32 	%r8688, %r8691;
	mov.u32 	%r8689, %r8691;
	mov.u32 	%r8690, %r8691;
	mov.u32 	%r8692, %r8691;
	mov.u32 	%r8693, %r8691;
	mov.u32 	%r8694, %r8691;
	mov.u32 	%r8695, %r8691;
	@%p143 bra 	BB0_179;
	bra.uni 	BB0_215;

BB0_179:
	mov.u32 	%r2363, 8;
	// inline asm
	shf.r.wrap.b32 %r8692, %r20, %r21, %r2363;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8693, %r19, %r20, %r2363;
	// inline asm
	mov.u32 	%r8688, 0;
	// inline asm
	shf.r.wrap.b32 %r8694, %r8688, %r19, %r2363;
	// inline asm

BB0_180:
	mov.u32 	%r8689, %r8688;
	mov.u32 	%r8690, %r8688;
	mov.u32 	%r8691, %r8688;
	mov.u32 	%r8695, %r8688;
	bra.uni 	BB0_215;

BB0_722:
	setp.eq.s32	%p489, %r14, 16;
	@%p489 bra 	BB0_723;
	bra.uni 	BB0_11;

BB0_723:
	and.b32  	%r3842, %r22, 65535;
	shl.b32 	%r3843, %r22, 8;
	and.b32  	%r3844, %r3843, -16777216;
	or.b32  	%r3845, %r3844, %r3842;
	shr.u32 	%r3846, %r22, 8;
	and.b32  	%r3847, %r3846, 16711680;
	or.b32  	%r8845, %r3845, %r3847;
	mov.u32 	%r8853, 16;
	bra.uni 	BB0_768;

BB0_160:
	setp.eq.s32	%p155, %r24, 15;
	mov.u32 	%r8688, %r8691;
	mov.u32 	%r8689, %r8691;
	mov.u32 	%r8690, %r8691;
	mov.u32 	%r8692, %r8691;
	mov.u32 	%r8693, %r8691;
	mov.u32 	%r8694, %r8691;
	mov.u32 	%r8695, %r8691;
	@%p155 bra 	BB0_161;
	bra.uni 	BB0_215;

BB0_161:
	mov.u32 	%r2491, 8;
	// inline asm
	shf.r.wrap.b32 %r8692, %r22, %r15, %r2491;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8693, %r21, %r22, %r2491;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8694, %r20, %r21, %r2491;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r8695, %r19, %r20, %r2491;
	// inline asm
	mov.u32 	%r8689, 0;
	// inline asm
	shf.r.wrap.b32 %r8688, %r8689, %r19, %r2491;
	// inline asm

BB0_162:
	mov.u32 	%r8690, %r8689;
	mov.u32 	%r8691, %r8689;
	bra.uni 	BB0_215;

BB0_751:
	setp.ne.s32	%p468, %r14, 31;
	@%p468 bra 	BB0_11;

	and.b32  	%r3765, %r18, 255;
	shl.b32 	%r3766, %r18, 8;
	and.b32  	%r3767, %r3766, 16711680;
	or.b32  	%r3768, %r3767, %r3765;
	shr.u32 	%r3769, %r18, 8;
	and.b32  	%r3770, %r3769, 65280;
	or.b32  	%r8849, %r3768, %r3770;
	mov.u32 	%r8853, 31;

BB0_754:
	mov.u32 	%r8845, %r22;
	mov.u32 	%r8846, %r21;
	mov.u32 	%r8847, %r20;
	mov.u32 	%r8848, %r19;
	bra.uni 	BB0_772;

BB0_11:
	mov.u32 	%r8845, %r22;

BB0_12:
	mov.u32 	%r8846, %r21;

BB0_13:
	mov.u32 	%r8847, %r20;

BB0_14:
	mov.u32 	%r8848, %r19;

BB0_15:
	mov.u32 	%r8849, %r18;

BB0_16:
	mov.u32 	%r8850, %r17;

BB0_17:
	mov.u32 	%r8851, %r16;

BB0_18:
	mov.u32 	%r8852, %r15;

BB0_1553:
	mov.u32 	%r8853, %r14;

BB0_1554:
	ld.param.u64 	%rd42, [amp_param_2];
	add.s32 	%r8678, %r8678, 1;
	mul.wide.u32 	%rd40, %r8678, 4;
	add.s64 	%rd41, %rd42, %rd40;
	ld.global.u32 	%r8677, [%rd41];
	setp.ne.s32	%p1031, %r8677, 0;
	@%p1031 bra 	BB0_5;

BB0_1555:
	st.global.u32 	[%rd3], %r8848;
	st.global.u32 	[%rd3+4], %r8847;
	st.global.u32 	[%rd3+8], %r8846;
	st.global.u32 	[%rd3+12], %r8845;
	st.global.u32 	[%rd3+16], %r8852;
	st.global.u32 	[%rd3+20], %r8851;
	st.global.u32 	[%rd3+24], %r8850;
	st.global.u32 	[%rd3+28], %r8849;
	st.global.u32 	[%rd3+64], %r8853;

BB0_1557:
	ret;
}


  